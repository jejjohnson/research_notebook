{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0300f6b3-8ba1-4236-adec-bf46ec5e0e45",
   "metadata": {},
   "source": [
    "Demo - Air Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b55d00-e8d5-46da-999d-440e611b61a7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x} \\in \\mathbb{R}^{D}\n",
    "$$\n",
    "\n",
    "where `D = lat x lon x time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57429962-35f4-433a-bd64-f2cdb2c38de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import bayesnewton\n",
    "import objax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from convertbng.util import convert_bng\n",
    "import time\n",
    "import zipfile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc4077d-cc61-4774-b2a8-d494ab41ee94",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebd0da-5760-4d8d-b6a0-0f5f78b104bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://zenodo.org/record/4531304/files/data.zip?download=1f\"\n",
    "with open(\"./data_dl.zip\", \"wb\") as f:\n",
    "    f.write(urlopen(url).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98212f6-9b4e-42a5-bf0b-2d90b07f8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"./data_dl.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./downloaded_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b24ef-0c8d-4bf4-bf1b-512d69d5c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "train_data = pickle.load(\n",
    "    open(\n",
    "        \"./downloaded_data/data/air_quality/data/train_data_\" + str(ind) + \".pickle\",\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "pred_data = pickle.load(\n",
    "    open(\n",
    "        \"./downloaded_data/data/air_quality/data/pred_data_\" + str(ind) + \".pickle\",\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "\n",
    "X = train_data[\"X\"]\n",
    "Y = train_data[\"Y\"]\n",
    "\n",
    "X_t = pred_data[\"test\"][\"X\"]\n",
    "Y_t = pred_data[\"test\"][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ad21c-43ee-4f3d-8303-ee1f11df3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X: \", X.shape)\n",
    "\n",
    "num_z_space = 30\n",
    "\n",
    "grid = True\n",
    "print(Y.shape)\n",
    "print(\"num data points =\", Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dab640-49fa-4cdf-a89a-e23cc009d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"pm10\"\n",
    "\n",
    "raw_data = pd.read_csv(\"../downloaded_data/air_quality/aq_data.csv\")\n",
    "sites_df = pd.read_csv(\"../downloaded_data/air_quality/laqn_sites.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e992c-3925-42a1-ba45-2ba4cb0e8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0874d-3f9f-4e31-ab5e-e108aef80645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sequential approach:\n",
    "t = X[:, :1]\n",
    "R = X[:, 1:]\n",
    "t_t = X_t[:, :1]\n",
    "R_t = X_t[:, 1:]\n",
    "\n",
    "\n",
    "# Nt = t.shape[0]\n",
    "# print(\"num time steps =\", Nt)\n",
    "# Nr = R.shape[1]\n",
    "# print(\"num spatial points =\", Nr)\n",
    "# N = Y.shape[0] * Y.shape[1] * Y.shape[2]\n",
    "# print(\"num data points =\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792a794-ddcb-4834-8c59-f4798f81589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape, R_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3133bc1-b328-4d5f-be5e-f639a27da578",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(R[:, 0], R[:, 1], c=Y.squeeze())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac409b-369e-473e-b6cd-52c1e04e163f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadd4a7-ed9b-4a47-a3dd-3653ee122ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_to_epoch(datetime):\n",
    "    \"\"\"\n",
    "    Converts a datetime to a number\n",
    "    args:\n",
    "        datatime: is a pandas column\n",
    "    \"\"\"\n",
    "    return datetime.astype(\"int64\") // 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271bafb-9d51-4975-abc1-353861353153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter sites not in london\n",
    "london_box = [[51.279, 51.684], [-0.533, 0.208]]  # lat  # lon\n",
    "\n",
    "sites_df = sites_df[\n",
    "    (sites_df[\"Latitude\"] > london_box[0][0])\n",
    "    & (sites_df[\"Latitude\"] < london_box[0][1])\n",
    "]\n",
    "sites_df = sites_df[\n",
    "    (sites_df[\"Longitude\"] > london_box[1][0])\n",
    "    & (sites_df[\"Longitude\"] < london_box[1][1])\n",
    "]\n",
    "\n",
    "# merge spatial infomation to data\n",
    "raw_data = raw_data.merge(sites_df, left_on=\"site\", right_on=\"SiteCode\")\n",
    "\n",
    "# convert to datetimes\n",
    "raw_data[\"date\"] = pd.to_datetime(raw_data[\"date\"])\n",
    "raw_data[\"epoch\"] = datetime_to_epoch(raw_data[\"date\"])\n",
    "\n",
    "# get data in date range\n",
    "data_range_start = \"2019/02/18 00:00:00\"\n",
    "data_range_end = \"2019/02/25 23:59:59\"  # '2019/03/11 23:59:59', '2019/02/25 23:59:59', '2019/04/17 23:59:59'\n",
    "\n",
    "raw_data = raw_data[\n",
    "    (raw_data[\"date\"] >= data_range_start) & (raw_data[\"date\"] < data_range_end)\n",
    "]\n",
    "\n",
    "X = np.array(raw_data[[\"epoch\", \"Longitude\", \"Latitude\"]])\n",
    "Y = np.array(raw_data[[species]])\n",
    "\n",
    "# convert to easting and northings\n",
    "british_national_grid_coords = convert_bng(X[:, 1], X[:, 2])\n",
    "X = np.vstack(\n",
    "    [\n",
    "        X[:, 0],\n",
    "        np.array(british_national_grid_coords[0]),\n",
    "        np.array(british_national_grid_coords[1]),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "\n",
    "# normalise\n",
    "# X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "# Y = (Y - np.nanmean(Y, axis=0)) / np.nanstd(Y, axis=0)\n",
    "\n",
    "# standardise\n",
    "# X_scaler = StandardScaler().fit(X)\n",
    "R_scaler = StandardScaler().fit(X[:, 1:])\n",
    "Y_scaler = StandardScaler().fit(Y)\n",
    "# X = X_scaler.transform(X)\n",
    "X[:, 1:] = R_scaler.transform(X[:, 1:])\n",
    "X[:, 0] = (X[:, 0] - min(X[:, 0])) / (60 * 60)  # convert from seconds to hours\n",
    "Y = Y_scaler.transform(Y)\n",
    "\n",
    "grid = True\n",
    "print(Y.shape)\n",
    "print(\"num data points =\", Y.shape[0])\n",
    "\n",
    "\n",
    "test_ind = np.random.permutation(X.shape[0])[: X.shape[0] // 10]\n",
    "t_test = X[test_ind, :1]\n",
    "R_test = X[test_ind, 1:]\n",
    "Y_test = Y[test_ind, :]\n",
    "\n",
    "if grid:\n",
    "    # the gridded approach:\n",
    "    t, R, Y = bayesnewton.utils.create_spatiotemporal_grid(X, Y)\n",
    "else:\n",
    "    # the sequential approach:\n",
    "    t = X[:, :1]\n",
    "    R = X[:, 1:]\n",
    "Nt = t.shape[0]\n",
    "print(\"num time steps =\", Nt)\n",
    "N = Y.shape[0] * Y.shape[1] * Y.shape[2]\n",
    "print(\"num data points =\", N)\n",
    "\n",
    "# ttest = np.unique(X[:, 0])[:, None]\n",
    "\n",
    "N_test = 20  # 50\n",
    "\n",
    "# r1 = np.unique(X[:, 1])\n",
    "# r2 = np.unique(X[:, 2])\n",
    "X1range = max(X[:, 1]) - min(X[:, 1])\n",
    "X2range = max(X[:, 2]) - min(X[:, 2])\n",
    "r1 = np.linspace(min(X[:, 1]) - 0.1 * X1range, max(X[:, 1]) + 0.1 * X1range, num=N_test)\n",
    "r2 = np.linspace(\n",
    "    min(X[:, 2]) - 0.05 * X2range, max(X[:, 2]) + 0.05 * X2range, num=N_test\n",
    ")\n",
    "rA, rB = np.meshgrid(r1, r2)\n",
    "r = np.hstack(\n",
    "    (rA.reshape(-1, 1), rB.reshape(-1, 1))\n",
    ")  # Flattening grid for use in kernel functions\n",
    "Rplot = np.tile(r, [t.shape[0], 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f332864-68c6-4327-8b56-91daa913c59e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a259ed-b0a1-40da-9e11-4879ac27d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_y = 1.0\n",
    "var_f = 1.0\n",
    "len_time = 5  # step size = 1 (hour)\n",
    "len_space = 1  # spatial inputs normalised to around [-3, 3]\n",
    "\n",
    "sparse = True\n",
    "opt_z = True  # will be set to False if sparse=False\n",
    "\n",
    "if sparse:\n",
    "    z1 = np.linspace(np.min(X[:, 1]), np.max(X[:, 1]), num=7)\n",
    "    z2 = np.linspace(np.min(X[:, 2]), np.max(X[:, 2]), num=7)\n",
    "    zA, zB = np.meshgrid(z1, z2)  # Adding additional dimension to inducing points grid\n",
    "    z = np.hstack(\n",
    "        (zA.reshape(-1, 1), zB.reshape(-1, 1))\n",
    "    )  # Flattening grid for use in kernel functions\n",
    "    del z1, z2, zA, zB\n",
    "else:\n",
    "    z = R[0, ...]\n",
    "\n",
    "del raw_data, X, rA, rB, r, sites_df\n",
    "\n",
    "# kern = bayesnewton.kernels.SpatioTemporalMatern52(variance=var_f,\n",
    "#                                            lengthscale_time=len_time,\n",
    "#                                            lengthscale_space=[len_space, len_space],\n",
    "#                                            z=z,\n",
    "#                                            sparse=sparse,\n",
    "#                                            opt_z=opt_z,\n",
    "#                                            conditional='Full')\n",
    "\n",
    "kern_time = bayesnewton.kernels.Matern32(variance=var_f, lengthscale=len_time)\n",
    "kern_space0 = bayesnewton.kernels.Matern32(variance=var_f, lengthscale=len_space)\n",
    "kern_space1 = bayesnewton.kernels.Matern32(variance=var_f, lengthscale=len_space)\n",
    "kern_space = bayesnewton.kernels.Separable([kern_space0, kern_space1])\n",
    "\n",
    "kern = bayesnewton.kernels.SpatioTemporalKernel(\n",
    "    temporal_kernel=kern_time,\n",
    "    spatial_kernel=kern_space,\n",
    "    z=z,\n",
    "    sparse=sparse,\n",
    "    opt_z=opt_z,\n",
    "    conditional=\"Full\",\n",
    ")\n",
    "\n",
    "lik = bayesnewton.likelihoods.Gaussian(variance=var_y)\n",
    "# model = bayesnewton.models.VariationalGP(kernel=kern, likelihood=lik, X=X, Y=y)\n",
    "model = bayesnewton.models.MarkovVariationalGP(\n",
    "    kernel=kern, likelihood=lik, X=t, R=R, Y=Y\n",
    ")\n",
    "# model = bayesnewton.models.InfiniteHorizonVariationalGP(kernel=kern, likelihood=lik, X=t, R=R, Y=Y)\n",
    "# model = bayesnewton.models.MarkovVariationalGPMeanField(kernel=kern, likelihood=lik, X=t, R=R, Y=Y)\n",
    "\n",
    "# Mt = 700  # num inducing points in time\n",
    "# batch_size = Nt\n",
    "# Z = np.linspace(np.min(t), np.max(t), Mt)[:, None]\n",
    "\n",
    "# model = bayesnewton.models.SparseMarkovVariationalGP(kernel=kern, likelihood=lik, X=t, R=R, Y=Y, Z=Z)\n",
    "\n",
    "lr_adam = 0.05\n",
    "lr_newton = 0.5\n",
    "iters = 20\n",
    "opt_hypers = objax.optimizer.Adam(model.vars())\n",
    "energy = objax.GradValues(model.energy, model.vars())\n",
    "\n",
    "\n",
    "@objax.Function.with_vars(model.vars() + opt_hypers.vars())\n",
    "def train_op():\n",
    "    model.inference(lr=lr_newton)  # perform inference and update variational params\n",
    "    dE, E = energy()  # compute energy and its gradients w.r.t. hypers\n",
    "    opt_hypers(lr_adam, dE)\n",
    "    return E\n",
    "\n",
    "\n",
    "train_op = objax.Jit(train_op)\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(1, iters + 1):\n",
    "    loss = train_op()\n",
    "    print(\"iter %2d, energy: %1.4f\" % (i, loss[0]))\n",
    "t1 = time.time()\n",
    "print(\"optimisation time: %2.2f secs\" % (t1 - t0))\n",
    "\n",
    "# calculate posterior predictive distribution via filtering and smoothing at train & test locations:\n",
    "print(\"calculating the posterior predictive distribution ...\")\n",
    "t0 = time.time()\n",
    "posterior_mean, posterior_var = model.predict(X=t, R=Rplot)\n",
    "nlpd = model.negative_log_predictive_density(X=t_test, R=R_test, Y=Y_test)\n",
    "t1 = time.time()\n",
    "print(\"prediction time: %2.2f secs\" % (t1 - t0))\n",
    "print(\"nlpd: %2.3f\" % nlpd)\n",
    "\n",
    "z_opt = model.kernel.z.value\n",
    "mu = bayesnewton.utils.transpose(posterior_mean.reshape(-1, N_test, N_test))\n",
    "\n",
    "mu = Y_scaler.inverse_transform(mu)\n",
    "Y = Y_scaler.inverse_transform(Y)\n",
    "\n",
    "save_result = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421959c-7369-4fcd-85c7-357f38c85714",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c601d-0c87-4095-864f-0b97b3dfecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"plotting ...\")\n",
    "cmap = cm.viridis\n",
    "vmin = np.nanpercentile(Y, 1)\n",
    "vmax = np.nanpercentile(Y, 99)\n",
    "\n",
    "for time_step in range(t.shape[0]):\n",
    "    print(time_step)\n",
    "    f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={\"height_ratios\": [20, 1]})\n",
    "    f.set_figheight(8)\n",
    "    # f.set_figwidth(8)\n",
    "    im = a0.imshow(\n",
    "        mu[time_step].T,\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        extent=[r1[0], r1[-1], r2[0], r2[-1]],\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    a0.scatter(\n",
    "        R[time_step, :, 0],\n",
    "        R[time_step, :, 1],\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        c=np.squeeze(Y[time_step]),\n",
    "        s=50,\n",
    "        edgecolors=\"black\",\n",
    "    )\n",
    "    plt.colorbar(im, fraction=0.0348, pad=0.03, aspect=30, ax=a0)\n",
    "    if sparse:\n",
    "        a0.scatter(\n",
    "            z_opt[:, 0], z_opt[:, 1], c=\"r\", s=20, alpha=0.5\n",
    "        )  # plot inducing inputs\n",
    "    a0.set_xlim(r1[0], r1[-1])\n",
    "    a0.set_ylim(r2[0], r2[-1])\n",
    "    a0.set_xticks([], [])\n",
    "    a0.set_yticks([], [])\n",
    "    a0.set_title(species)\n",
    "    # a0.set_ylabel('Latitude')\n",
    "    # a0.set_xlabel('Longitude')\n",
    "    a0.set_xlabel(\"Easting\")\n",
    "    a0.set_ylabel(\"Northing\")\n",
    "    a1.vlines(t[time_step] / 24, -1, 1, \"r\")\n",
    "    a1.set_xlabel(\"time (days)\")\n",
    "    a1.set_yticks([], [])\n",
    "    a1.set_xlim(t[0] / 24, t[-1] / 24)\n",
    "    # a1.set_xticks([0, 7, 14, 21])\n",
    "    f.savefig(\"output/output_%04d.png\" % time_step)\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41478c7-3f0a-405d-a2fd-bd73c46849f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-jax_gp]",
   "language": "python",
   "name": "conda-env-miniconda3-jax_gp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
