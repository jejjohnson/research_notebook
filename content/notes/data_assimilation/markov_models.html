

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Markov Models &#8212; Research Notebook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/notes/data_assimilation/markov_models';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Gauss-Markov Models" href="gauss_markov.html" />
    <link rel="prev" title="Algorithms" href="algorithms.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/book_v2.jpeg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../resources/python/overview.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/ides.html">Integraded Development Environment (IDE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/stack.html">Standard Python Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/earthsci_stack.html">Earth Science Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/dl_stack.html">Deep Learning Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/scale_stack.html">Scaling Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/good_code.html">Good Code</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/jax_journey/overview.html">My JAX Journey</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">Ecosystem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/vmap.html">vmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/jit.html">Jit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/classes.html">Classes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">Bisection search</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/gfs_with_jax.html">Gaussianization Flows</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/twelve_steps_ns/overview.html">12 Steps to Navier-Stokes</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/twelve_steps_ns/1.1_linear_advection.html">1D Linear Convection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/remote/overview.html">Remote Computing</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/ssh.html">SSH Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/conda.html">Conda 4 Remote Servers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/jlab.html">Jupyter Lab 4 Remote Servers</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../gmt/overview.html">GMT of Learning</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gmt/hierarchical_rep.html">Hierarchical Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/functa.html">Functa</a></li>








<li class="toctree-l2"><a class="reference internal" href="../gmt/discretize_space.html">Spatial Discretization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/discretize_time.html">Temporal Discretization</a></li>


<li class="toctree-l2"><a class="reference internal" href="../gmt/learning.html">Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../concepts/uncertainty.html">Modeling Uncertainty</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bayesian/overview.html">Bayesian</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/intro.html">Language of Uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/models.html">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference.html">Inference Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/variational_inference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/cond_vi.html">Conditional Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/confidence_intervals.html">Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/regression.html">Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../concepts/overview.html">Sleeper Concepts</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../concepts/gaussian.html">Gaussian Distributions</a></li>

<li class="toctree-l2"><a class="reference internal" href="../concepts/change_of_variables.html">Change of Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/identity_trick.html">Identity Trick</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/inverse_function.html">Inverse Function Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/jensens.html">Jensens Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/lin_alg.html">Linear Algebra Tricks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kernels/overview.html">Kernel Methods</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../kernels/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/rv.html">RV Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/congruence_coeff.html">Congruence Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/hsic.html">HSIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/mmd.html">Maximum Mean Discrepancy (MMD)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gps/intro.html">Gaussian Processes</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gps/gps.html">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/literature.html">Literature Review</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/cg.html">Conjugate Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/sgps.html">Sparse Gaussian Processes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../gps/algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../gps/gpr_code.html">GP from Scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gps/sgp_code.html">Sparse GP From Scratch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../egps/overview.html">Input Uncertainty in GPs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../info_theory/similarity.html">Similarity</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../info_theory/overview.html">Information Theory</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/measures.html">Measures</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/information.html">Information Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/entropy.html">Entropy &amp; Relative Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/mutual_info.html">Mutual Information and Total Correlation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/estimators.html">Information Theory Measures</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/classic.html">Classic Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/histogram.html">Entropy Estimator - Histogram</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">Experiment - RBIG Sample Consistency</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../normalizing_flows/overview.html">Normalizing Flows</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/linear.html">Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/coupling_layers.html">Coupling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/conditional.html">Conditional Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/multiscale.html">Multiscale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/inverse.html">Minimization Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/losses.html">Losses</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_1_ig.html">Lecture I - Iterative Gaussianization</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.0_univariate_gauss.html">1.1 - Univariate Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.1_marginal_gauss.html">1.2 - Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.2_gaussianization.html">1.2 - Iterative Gaussianization</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_2_gf.html">Lecture II - Gaussianization Flows</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt1_mg.html">Parameterized Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt2_rot.html">Parameterized Rotations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt3_plane.html">Example - 2D Plane</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nerfs/overview.html">Neural Fields</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nerfs/formulation.html">Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nerfs/literature_review.html">Literature Review</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../nerfs/pinns.html">Physics-Informed Loss</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="overview.html">Data Assimilation</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dynamical_sys.html">Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="oi.html">Optimal Interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="interp.html">Interpolation Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="emu.html">Emulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="inv_problems.html">Inverse Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="projects.html">Projects</a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="algorithms.html">Algorithms</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="gauss_markov.html">Gauss-Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="kf.html">Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="nkf.html">Normalizing Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="enskf.html">Ensemble Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="4dvarnet.html">4DVarNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="markov_gp.html">Markovian Gaussian Processes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="nbs/notebooks.html">Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../misc/overview.html">Miscellaneous Notes</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../misc/generative_models.html">Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diffusion_models.html">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/fixed_point.html">Fixed-Point Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/bilevel_opt.html">Bi-Level Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diff_operators.html">Differential Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/qg.html">QG Formulations</a></li>


<li class="toctree-l2"><a class="reference internal" href="../misc/elliptical_pde_solver.html">Elliptical PDE Solvers</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cheat Sheets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/bash.html">Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/cli.html">Command Line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/python.html">Python</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/jejjohnson/research_notebook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/data_assimilation/markov_models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/notes/data_assimilation/markov_models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Markov Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-dimensionality">High Dimensionality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#time-dependencies">Time Dependencies</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#schematic">Schematic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-properties">Markov Properties</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#property-of-states">Property of States</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-independence-of-measurements">Conditional Independence of Measurements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-distribution">Joint Distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantities-of-interest">Quantities of Interest</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tldr">TLDR</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering">Filtering</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">Predict</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering-algorithm">Filtering Algorithm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#update">Update</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smoothing">Smoothing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">Predictions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-estimation">Likelihood Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-samples">Posterior Samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#marginal-likelihood">Marginal Likelihood</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity">Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#viz">Viz</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bars">Bars</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regression">Regression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cons">Cons</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiscale-time-dependencies">Multiscale Time Dependencies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#long-term">Long Term</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="markov-models">
<h1>Markov Models<a class="headerlink" href="#markov-models" title="Permalink to this heading">#</a></h1>
<blockquote>
<div><p>In these notes, we walk through a model for modeling time-dependent data. By enforcing the Markov chain properties, we only have a variable at time, <span class="math notranslate nohighlight">\(t\)</span>, depend on the variable at a previous time step, <span class="math notranslate nohighlight">\(t-1\)</span>. This results in very efficient directed graph which leads to inference of order <span class="math notranslate nohighlight">\(\mathcal{O}(T)\)</span>.</p>
</div></blockquote>
<p>The main source of inspiration for this is the lecture from the Probabilistic ML course from Tubingen <span id="id1">[<a class="reference internal" href="../info_theory/similarity.html#id38" title="Philipp Henning. Probabilistic ml - lecture 12 - gauss-markov models. 2020. URL: https://youtu.be/FydcrDtZroU (visited on 2021-10-10).">Henning, 2020</a>]</span>. Some of the details we taken from the probabilistic machine learning textbook from Kevin Murphy <span id="id2">[<a class="reference internal" href="../info_theory/similarity.html#id40" title="Kevin P. Murphy. Machine Learning: A Probabilistic Perspective. MIT Press, 2012. URL: probml.ai.">Murphy, 2012</a>]</span>.</p>
<hr class="docutils" />
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this heading">#</a></h2>
<p>Consider a large dimensional dataset, e.g. a data cube. This will be of size:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x} \in \mathbf{R}^D
\]</div>
<p>But letâ€™s assume that it is a spatio-temporal dataset. Then we can decompose the dimension, <span class="math notranslate nohighlight">\(D\)</span> into the following components.</p>
<div class="math notranslate nohighlight">
\[
D = [ \text{space} \times \text{T} \times \text{vars}]
\]</div>
<section id="high-dimensionality">
<h3>High Dimensionality<a class="headerlink" href="#high-dimensionality" title="Permalink to this heading">#</a></h3>
<p>This is a very high dimensional dataset. For example, if we have a very long time series like <span class="math notranslate nohighlight">\(1,000\)</span> time steps, then we will have a massive <span class="math notranslate nohighlight">\(D\)</span>-dimensional vector for the input variable.</p>
</section>
<section id="time-dependencies">
<h3>Time Dependencies<a class="headerlink" href="#time-dependencies" title="Permalink to this heading">#</a></h3>
<p>These time dependences are very difficult to model. They are highly correlated, especially at very near, e.g. <span class="math notranslate nohighlight">\(t-1\)</span>, <span class="math notranslate nohighlight">\(t\)</span>, and <span class="math notranslate nohighlight">\(t-1\)</span>.</p>
</section>
</section>
<hr class="docutils" />
<section id="schematic">
<h2>Schematic<a class="headerlink" href="#schematic" title="Permalink to this heading">#</a></h2>
<p>This method seeks to decouple time by enforcing the Markov assumption.</p>
<figure class="align-default" id="markov-chain-graph">
<a class="reference internal image-reference" href="../../../_images/markov_chain_graph.png"><img alt="../../../_images/markov_chain_graph.png" src="../../../_images/markov_chain_graph.png" style="height: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">A graphical model for the dependencies between the variables x and z. Notice how z only depends on the previous time step.</span><a class="headerlink" href="#markov-chain-graph" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The key is that by enforcing these Markovian assumptions, we have a directed graph structure that results in very efficient inference. This is all due to the Markov property due to the chain structure.</p>
</section>
<hr class="docutils" />
<section id="markov-properties">
<h2>Markov Properties<a class="headerlink" href="#markov-properties" title="Permalink to this heading">#</a></h2>
<section id="property-of-states">
<h3>Property of States<a class="headerlink" href="#property-of-states" title="Permalink to this heading">#</a></h3>
<p>Given <span class="math notranslate nohighlight">\(z_{t-1}\)</span>, <span class="math notranslate nohighlight">\(z_t\)</span> is independent of any other of the previous states, e.g. <span class="math notranslate nohighlight">\(z_{t-2}, z_{t-3}, \ldots\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-markov-prop-states">
<span class="eqno">(30)<a class="headerlink" href="#equation-markov-prop-states" title="Permalink to this equation">#</a></span>\[
p(z_t | z_{1:t-1}, x_{1:t-1}) = p(z_t|z_{t-1})
\]</div>
<p>This is enforcing some kind of <em>local memory</em> within our system. So even if we have the full system of observed variables, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>, and the posterior states, <span class="math notranslate nohighlight">\(z_{1:T}\)</span>, we still only have the dependencies on the previous time step.</p>
<div class="math notranslate nohighlight">
\[
p(z_{t-1}|z_{1:T}, x_{1:T}) = p(z_{t-1}|z_t)
\]</div>
<p>Bottom line: The past is independent of the future given the present.</p>
</section>
<section id="conditional-independence-of-measurements">
<h3>Conditional Independence of Measurements<a class="headerlink" href="#conditional-independence-of-measurements" title="Permalink to this heading">#</a></h3>
<p>We assume that the measurement, <span class="math notranslate nohighlight">\(x_t\)</span>, given the current state, <span class="math notranslate nohighlight">\(z_t\)</span>, is conditionally independent of the measurements and its histories.</p>
<div class="math notranslate nohighlight">
\[
p(x_t|z_{1:t}, x_{1:t-1}) = p(x_t|z_t)
\]</div>
<p>So as you can see, the measurement at time, <span class="math notranslate nohighlight">\(t\)</span>, is only dependent on the state, <span class="math notranslate nohighlight">\(z\)</span>, at time <span class="math notranslate nohighlight">\(t\)</span> state irregardless of how many other time steps have been observed.</p>
</section>
<hr class="docutils" />
<section id="joint-distribution">
<h3>Joint Distribution<a class="headerlink" href="#joint-distribution" title="Permalink to this heading">#</a></h3>
<p>While this may not be immediately useful, it is useful for certain other quantities of interest.</p>
<div class="math notranslate nohighlight">
\[
p(z_{1:T}, x_{1:T}) = p(x_{1:T}|z_{1:T})p(z_{1:T})
\]</div>
<p>Using the Markov local memory and conditioning principal, we can decompose these conditionals wrt to the time, <span class="math notranslate nohighlight">\(t\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-markov-joint">
<span class="eqno">(31)<a class="headerlink" href="#equation-markov-joint" title="Permalink to this equation">#</a></span>\[
p(z_{1:T}, x_{1:T}) = p(z_0)\prod_{t=2}^Tp(z_t|z_{t-1})\prod_{t=1}^T p(x_t|z_t)
\]</div>
<p>where we have all of the elements of the distribution.</p>
<ul class="simple">
<li><p><strong>Prior</strong>: <span class="math notranslate nohighlight">\(p(z_0)\)</span></p></li>
<li><p><strong>Transition Model</strong>: <span class="math notranslate nohighlight">\(p(z_t|z_{t-1})\)</span></p></li>
<li><p><strong>Observation Model</strong>: <span class="math notranslate nohighlight">\(p(x_t|z_t)\)</span></p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="quantities-of-interest">
<h2>Quantities of Interest<a class="headerlink" href="#quantities-of-interest" title="Permalink to this heading">#</a></h2>
<p>Once we have the model structure, now we are interested in the specific quantities. All of them really boil down to quantities from inference.</p>
<section id="tldr">
<h3>TLDR<a class="headerlink" href="#tldr" title="Permalink to this heading">#</a></h3>
<p><strong>Posterior</strong> - <span class="math notranslate nohighlight">\(p(z_t|x_{1:t})\)</span></p>
<blockquote>
<div><p>the probability of the state, <span class="math notranslate nohighlight">\(z_t\)</span> given the current and previous measurements, <span class="math notranslate nohighlight">\(x_{1:t}\)</span>.</p>
</div></blockquote>
<p><strong>Predict Step</strong> - <span class="math notranslate nohighlight">\(p(z_t|x_{1:t-1})=\int p(z_t|z_{t-1})p(z)\)</span></p>
<blockquote>
<div><p>The current state, <span class="math notranslate nohighlight">\(z_t\)</span>, given the past measurements, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>.</p>
</div></blockquote>
<p><strong>Measurement Step</strong> - <span class="math notranslate nohighlight">\(p(z_t|x_t, x_{1:t-1}) \propto p(x_t|z_t)p(z_t|x_{1:t-1})\)</span></p>
<blockquote>
<div><p>The current state, <span class="math notranslate nohighlight">\(z_t\)</span>, given the present measurement <span class="math notranslate nohighlight">\(x_t\)</span> and past measurements, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span></p>
</div></blockquote>
<p><strong>Marginal Likelihood</strong> - <span class="math notranslate nohighlight">\(p(x_{1:T}) = \sum_{t}^T p(x_t|x_{1:t-1})\)</span></p>
<blockquote>
<div><p>The likelihood of measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>, given the state, <span class="math notranslate nohighlight">\(z_{1:T}\)</span>.</p>
</div></blockquote>
<p><strong>Posterior Predictive</strong>: <span class="math notranslate nohighlight">\(p(x_t|x_{1:t-1}) = \int p(x_t|z_t)p(z_t|z_{t-1})dz_t\)</span></p>
<blockquote>
<div><p>The probability of the measurement, <span class="math notranslate nohighlight">\(x_t\)</span>, given the previous measurements, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>.</p>
</div></blockquote>
<p><strong>Posterior Samples</strong>: <span class="math notranslate nohighlight">\(z_{1:T} \sim p(z_t|x_{1:T})\)</span></p>
<blockquote>
<div><p>Trajectories for states, <span class="math notranslate nohighlight">\(z_{1:t}\)</span>, given the measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>.</p>
</div></blockquote>
<p><strong>Sampling (Measurements)</strong>: <span class="math notranslate nohighlight">\(x_t \sim p(x_t|x_{1:t-1})\)</span></p>
<blockquote>
<div><p>Trajectories for observations, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>, given the state space model, <span class="math notranslate nohighlight">\(z_{1:T}\)</span>.</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="filtering">
<h3>Filtering<a class="headerlink" href="#filtering" title="Permalink to this heading">#</a></h3>
<p>We are interested in computing the belief of our state, <span class="math notranslate nohighlight">\(z_t\)</span>. This is given by</p>
<div class="math notranslate nohighlight" id="equation-markov-filter">
<span class="eqno">(32)<a class="headerlink" href="#equation-markov-filter" title="Permalink to this equation">#</a></span>\[
p(z_t | x_{1:t})
\]</div>
<p>This equation is the posterior probability of <span class="math notranslate nohighlight">\(z_t\)</span> given the present measurement, <span class="math notranslate nohighlight">\(x_t\)</span>, and all of the past measurements, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>. We can compute this using the Bayes method (eq <a class="reference internal" href="../bayesian/intro.html#equation-bayes">(14)</a>) in a sequential way.</p>
<div class="proof remark admonition" id="filter-name">
<p class="admonition-title"><span class="caption-number">Remark 2 </span></p>
<section class="remark-content" id="proof-content">
<p>The term <em>filter</em> comes from the idea that we reduce the noise of current time step, <span class="math notranslate nohighlight">\(p(z_t|x_t)\)</span>, by taking into account the information within previous time steps, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>.</p>
</section>
</div><p>This is given by the predict-update equations.</p>
<section id="predict">
<h4>Predict<a class="headerlink" href="#predict" title="Permalink to this heading">#</a></h4>
<p>This quantity is given via the <em>Chapman-Kolmogrov</em> equation.</p>
<div class="math notranslate nohighlight" id="equation-chapman-kolmogrov">
<span class="eqno">(33)<a class="headerlink" href="#equation-chapman-kolmogrov" title="Permalink to this equation">#</a></span>\[
p(z_t|x_{1:t-1}) = \int p(z_t|z_{t-1})p(z_{t-1}|x_{1:t-1})dx_{t-1}
\]</div>
<p><strong>Term I</strong>: This is the posterior of <span class="math notranslate nohighlight">\(z_t\)</span> given all of the previous observations, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>.</p>
<p><strong>Term II</strong>: the transition distribution between time steps.</p>
<p><strong>Term III</strong>: the posterior distribution of the state, <span class="math notranslate nohighlight">\(z_{t-1}\)</span>, given all of the observations, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>.</p>
<p>Note: term III is the posterior distribution but at a previous time step.</p>
</section>
<hr class="docutils" />
<section id="filtering-algorithm">
<h4>Filtering Algorithm<a class="headerlink" href="#filtering-algorithm" title="Permalink to this heading">#</a></h4>
<p>The full form for filtering equation is given by an iterative process between the predict step and the update step.</p>
<p><strong>1. Predict the next hidden state</strong></p>
<ul class="simple">
<li><p>First you get the posterior of the previous state, <span class="math notranslate nohighlight">\(\mathbf{z}_{t-1}\)</span>, given all of the observations, <span class="math notranslate nohighlight">\(\mathbf{x}_{1:t-1}\)</span>.</p></li>
<li><p>Second, you get the posterior of the current state, <span class="math notranslate nohighlight">\(\mathbf{z}_t\)</span>, given all of the observations, <span class="math notranslate nohighlight">\(p(\mathbf{x}_{1:t-1})\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(\mathbf{z}_{t-1}|\mathbf{x}_{1:t-1}) \rightarrow p(\mathbf{z}_t|\mathbf{x}_{1:t-1})
\]</div>
<p><strong>2. Predict the observation</strong></p>
<ul class="simple">
<li><p>First, you take the state, <span class="math notranslate nohighlight">\(x_t\)</span>, given the previous measurements, <span class="math notranslate nohighlight">\(y_t\)</span>.</p></li>
<li><p>Second you predict the current measurement, <span class="math notranslate nohighlight">\(y_t\)</span>, given all previous measurements, <span class="math notranslate nohighlight">\(y_{1:t-1}\)</span>.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(x_t|y_{1:t-1}) \rightarrow p(y_t|y_{1:t-1})
\]</div>
<p><strong>3. Update the hidden state given the observation</strong></p>
<ul class="simple">
<li><p>First, you take the new observation, <span class="math notranslate nohighlight">\(y_t\)</span></p></li>
<li><p>Then, you do an update step to get the current state, <span class="math notranslate nohighlight">\(x_t\)</span>, given all previous measurements, <span class="math notranslate nohighlight">\(y_{1:t}\)</span>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="update">
<h4>Update<a class="headerlink" href="#update" title="Permalink to this heading">#</a></h4>
<div class="math notranslate nohighlight" id="equation-markov-update">
<span class="eqno">(34)<a class="headerlink" href="#equation-markov-update" title="Permalink to this equation">#</a></span>\[
p(z_t|x_{1:t}) =  \frac{p(x_t|z_t)p(z_t|x_{1:t-1})}{p(x_t)}
\]</div>
<p><strong>Term I</strong>: The posterior distribution of state, <span class="math notranslate nohighlight">\(z_t\)</span>, given the current <strong>and</strong> previous measurements, <span class="math notranslate nohighlight">\(x_{1:t}\)</span>.</p>
<p><strong>Term II</strong>: The observation model for the current measurement, <span class="math notranslate nohighlight">\(x_t\)</span>, given the current state, <span class="math notranslate nohighlight">\(z_t\)</span>.</p>
<p><strong>Term III</strong>: The posterior distribution of the current state, <span class="math notranslate nohighlight">\(z_t\)</span>, given all of the previous measurements, <span class="math notranslate nohighlight">\(x_{1:t-1}\)</span>.</p>
<p><strong>Term IV</strong>: The marginal distribution for the current measurement, <span class="math notranslate nohighlight">\(x_t\)</span>.</p>
</section>
</section>
<hr class="docutils" />
<section id="smoothing">
<h3>Smoothing<a class="headerlink" href="#smoothing" title="Permalink to this heading">#</a></h3>
<p>We compute the state, <span class="math notranslate nohighlight">\(z_t\)</span>, given all of the measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span> where <span class="math notranslate nohighlight">\(1 &lt; t &lt; T\)</span>.</p>
<div class="math notranslate nohighlight">
\[
p(z_t|x_{1:T})
\]</div>
<p>We condition on the past and the future to significantly reduce the uncertainty.</p>
<div class="proof remark admonition" id="hindsight">
<p class="admonition-title"><span class="caption-number">Remark 3 </span></p>
<section class="remark-content" id="proof-content">
<p>We can see parallels to our own lives. Take the quote â€œHindsight is 22â€. This implies that we can easily explain an action in our past once we have all of the information available. However, itâ€™s harder to explain our present action given only the past information.</p>
</section>
</div><p>This use case is very common when we want to <em>understand</em> and <em>learn</em> from data. In a practical sense, many reanalysis datasets take this into account.</p>
<div class="math notranslate nohighlight" id="equation-markov-smooth">
<span class="eqno">(35)<a class="headerlink" href="#equation-markov-smooth" title="Permalink to this equation">#</a></span>\[
p(z_t|x_{1:T}) = p(z_t|x_{1:t}) \int p(z_{t+1}|z_t) \frac{p(z_{t+1}|x_{1:T})}{p(z_{t+1}|x_{1:t})}dz_{t+1}
\]</div>
<p><strong>Term I</strong>: The current state, <span class="math notranslate nohighlight">\(z_t\)</span>, given all of the past, current and future measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span> (smoothing step)</p>
<p><strong>Term II</strong>: The current state, <span class="math notranslate nohighlight">\(z_t\)</span>, given all of the present and previous measurements, <span class="math notranslate nohighlight">\(x_{1:t}\)</span> (the predict step)</p>
<p><strong>Term III</strong>: The â€œfutureâ€ state, <span class="math notranslate nohighlight">\(z_{t+1}\)</span>, given the previous state, <span class="math notranslate nohighlight">\(z_t\)</span> (transition prob)</p>
<p><strong>Term IV</strong>: The â€œfutureâ€ state, <span class="math notranslate nohighlight">\(z_{t+1}\)</span>, given all of the measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>.</p>
<p><strong>Term V</strong>: The â€œfutureâ€ state, <span class="math notranslate nohighlight">\(z_{t+1}\)</span>, given all of the current and past measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>.</p>
</section>
<hr class="docutils" />
<section id="predictions">
<h3>Predictions<a class="headerlink" href="#predictions" title="Permalink to this heading">#</a></h3>
<p>We want to predict the future state, <span class="math notranslate nohighlight">\(z_{T+\tau}\)</span>, given the past measurements, $x_{}.</p>
<div class="math notranslate nohighlight">
\[
p(z_{T+\tau}|x_{1:T})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\tau &gt; 0\)</span>. <span class="math notranslate nohighlight">\(\tau\)</span> is the <em>horizon</em> of our forecasting, i.e. it is how far ahead of <span class="math notranslate nohighlight">\(T\)</span> we are trying to predict. So we can expand this to write that we are interested in the future hidden states, <span class="math notranslate nohighlight">\(z_{T+\tau}\)</span>, given all of the past measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
p(z_{T+\tau}|x_{1:T}) = \sum_{z_{T+\tau}} \sum_{z_T} p(z_{T+\tau}|z_T) p(z_T|x_{1:T})
\]</div>
<p>We could also want to get predictions for what we observe</p>
<div class="math notranslate nohighlight">
\[
p(x_{T+\tau}|x_{1:t}) = \sum p(x_{T+\tau}|z_{T+\tau})p(z_{T+\tau}|x_{1:T})
\]</div>
<p>This is known as the <em>posterior predictive density</em>.</p>
<p>This is often the most common use case in applications, e.g. weather predictions and climate model projections. The nice thing is that we will have this as a by-product of our model.</p>
</section>
<section id="likelihood-estimation">
<h3>Likelihood Estimation<a class="headerlink" href="#likelihood-estimation" title="Permalink to this heading">#</a></h3>
<p>For learning, we need to calculate the most probable state-space that matches the given observations. This assumes that we have access to all of the measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{NLL} = \operatorname*{argmax}_{z_{1:T}} p(z_{1:T}|x_{1:T})
\]</div>
<p><strong>Note</strong>: This is a non-probabilistic approach to maximizing the likelihood. However, this could be very useful for some applications. Smoothing would be better but we still need to find the best parameters.</p>
</section>
<section id="posterior-samples">
<h3>Posterior Samples<a class="headerlink" href="#posterior-samples" title="Permalink to this heading">#</a></h3>
<p>We are interested in generating possible states and state trajectories. In this case, we want the likelihood of a state trajectory, <span class="math notranslate nohighlight">\(z_{1:T}\)</span>, given some measurements, <span class="math notranslate nohighlight">\(x_{1:T}\)</span>. This is given by:</p>
<div class="math notranslate nohighlight">
\[
z_{1:T} \sim p(z_{1:T}|x_{1:T})
\]</div>
<p>This is very informative because it can show us plausible interpretations of possible state spaces that could fit the measurements.</p>
<div class="proof remark admonition" id="markov_useful">
<p class="admonition-title"><span class="caption-number">Remark 4 </span></p>
<section class="remark-content" id="proof-content">
<p>In terms of information, we can show the following relationship.</p>
<div class="math notranslate nohighlight">
\[
\text{MAP} &lt;&lt; \text{Smoothing} &lt;&lt; \text{Posterior Samples}
\]</div>
</section>
</div></section>
<section id="marginal-likelihood">
<h3>Marginal Likelihood<a class="headerlink" href="#marginal-likelihood" title="Permalink to this heading">#</a></h3>
<p>This is the probability of the evidence, i.e., the marginal probability of the measurements. This may be useful as an evaluation of the density of given measurements. We could write this as the joint probabilty</p>
<div class="math notranslate nohighlight">
\[
p(x_{1:T}) = \sum_{z_{1:T}} p(z_{1:T}, x_{1:T})
\]</div>
<p>We can decompose this using the conditional probability. This gives us</p>
<div class="math notranslate nohighlight">
\[
p(x_{1:T}) = \sum_{z_{1:T}} p(x_{1:T}|z_{1:T})p(z_{1:T})
\]</div>
<p>As shown by the above function, this is done by summing all of the hidden paths.</p>
<p>This can be useful if we want to use the learned model to classify sequences, perform clustering, or possibly anomaly detection.</p>
<p>Note: We can use the log version of this equation to deal with instabilities.</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = \log p(x_{1:T}) = \sum_{z_{1:T}} \log p(z_{1:T},x_{1:T})
\]</div>
</section>
<section id="complexity">
<h3>Complexity<a class="headerlink" href="#complexity" title="Permalink to this heading">#</a></h3>
<p>This is the biggest reason why one would do a Markov assumptions aside from the simplicity. Let <span class="math notranslate nohighlight">\(D\)</span> be the dimensionality of the state space, <span class="math notranslate nohighlight">\(z\)</span> and <span class="math notranslate nohighlight">\(T\)</span> be the number of time steps given by the measurements. We can give the computational complexity for each of the quantities listed above.</p>
<p><strong>Filter-Predict</strong></p>
<p>This is of order <span class="math notranslate nohighlight">\(\mathcal{O}(D^2T)\)</span></p>
<p>If we assume sparsity in the methods, then we can reduce this to <span class="math notranslate nohighlight">\(\mathcal{O}(DT)\)</span>.</p>
<p>We can reduce the complexity even further by assuming some special matrices within the functions to give us a complexity of <span class="math notranslate nohighlight">\(\mathcal{O}(T D \log D)\)</span>.</p>
<p>If we do a parallel computation, we can even have a really low computational complexity of <span class="math notranslate nohighlight">\(\mathcal{O}(D \log T)\)</span>.</p>
<p>Overall: the bottleneck of this method is not the computational speed, itâ€™s the memory required to do all of the computations cheaply.</p>
</section>
<hr class="docutils" />
<section id="viz">
<h3>Viz<a class="headerlink" href="#viz" title="Permalink to this heading">#</a></h3>
<section id="bars">
<h4>Bars<a class="headerlink" href="#bars" title="Permalink to this heading">#</a></h4>
</section>
<section id="regression">
<h4>Regression<a class="headerlink" href="#regression" title="Permalink to this heading">#</a></h4>
</section>
</section>
</section>
<hr class="docutils" />
<section id="cons">
<h2>Cons<a class="headerlink" href="#cons" title="Permalink to this heading">#</a></h2>
<p>While we managed to reduce the dimensionality of our dataset, this might not be the optimal model to choose. We assume that <span class="math notranslate nohighlight">\(z_t\)</span> only depends on the previous time step, <span class="math notranslate nohighlight">\(z_{t-t}\)</span>. But it could be the case that <span class="math notranslate nohighlight">\(z_t\)</span> could depend on previous time steps, e.g. <span class="math notranslate nohighlight">\(p(z_t | z_{t-1}, z_{t-2}, z_{t-2}, \ldots)\)</span>. There is no reason to assume that</p>
<section id="multiscale-time-dependencies">
<h3>Multiscale Time Dependencies<a class="headerlink" href="#multiscale-time-dependencies" title="Permalink to this heading">#</a></h3>
<p>One way to overcome this is to assume</p>
</section>
<section id="long-term">
<h3>Long Term<a class="headerlink" href="#long-term" title="Permalink to this heading">#</a></h3>
<hr class="docutils" />
<div class="docutils container" id="id3">
<div class="citation" id="id16" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">Hen20</a><span class="fn-bracket">]</span></span>
<p>Philipp Henning. Probabilistic ml - lecture 12 - gauss-markov models. 2020. URL: <a class="reference external" href="https://youtu.be/FydcrDtZroU">https://youtu.be/FydcrDtZroU</a> (visited on 2021-10-10).</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">Mur12</a><span class="fn-bracket">]</span></span>
<p>KevinÂ P. Murphy. <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press, 2012. URL: <a class="reference external" href="probml.ai">probml.ai</a>.</p>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/notes/data_assimilation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="algorithms.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Algorithms</p>
      </div>
    </a>
    <a class="right-next"
       href="gauss_markov.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gauss-Markov Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#high-dimensionality">High Dimensionality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#time-dependencies">Time Dependencies</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#schematic">Schematic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-properties">Markov Properties</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#property-of-states">Property of States</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-independence-of-measurements">Conditional Independence of Measurements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-distribution">Joint Distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantities-of-interest">Quantities of Interest</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tldr">TLDR</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering">Filtering</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">Predict</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering-algorithm">Filtering Algorithm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#update">Update</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smoothing">Smoothing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions">Predictions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-estimation">Likelihood Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-samples">Posterior Samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#marginal-likelihood">Marginal Likelihood</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity">Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#viz">Viz</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bars">Bars</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regression">Regression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cons">Cons</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiscale-time-dependencies">Multiscale Time Dependencies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#long-term">Long Term</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By J. Emmanuel Johnson
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>