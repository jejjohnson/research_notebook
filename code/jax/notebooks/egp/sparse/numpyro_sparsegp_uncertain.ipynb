{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jejjohnson/gp_model_zoo/blob/master/code/numpyro/numpyro_sparsegp_uncertain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hecnCJD1trHy"
   },
   "source": [
    "# Sparse Gaussian Process w/ Numpyro\n",
    "\n",
    "My starting notebook where I install all of the necessary libraries and load some easy 1D/2D Regression data to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgSMWFaNtnjB"
   },
   "outputs": [],
   "source": [
    "# @title Install Packages\n",
    "%%capture\n",
    "!pip install jax jaxlib chex optax loguru\n",
    "!pip install \"git+https://github.com/pyro-ppl/numpyro.git#egg=numpyro\"\n",
    "!pip uninstall tensorflow -y -q\n",
    "!pip install -Uq tfp-nightly[jax] > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5TKBjGbumu6"
   },
   "outputs": [],
   "source": [
    "# @title Load Packages\n",
    "# TYPE HINTS\n",
    "from typing import Tuple, Optional, Dict, Callable, Union\n",
    "\n",
    "# JAX SETTINGS\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "\n",
    "\n",
    "# JAX UTILITY LIBRARIES\n",
    "import chex\n",
    "\n",
    "# NUMPYRO SETTINGS\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer.autoguide import AutoDiagonalNormal\n",
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "# NUMPY SETTINGS\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# MATPLOTLIB Settings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# SEABORN SETTINGS\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "# PANDAS SETTINGS\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# LOGGING SETTINGS\n",
    "import loguru\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXa_nHwb3NLL"
   },
   "source": [
    "## Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLMCRQ03w-O-"
   },
   "outputs": [],
   "source": [
    "def GP(X, y):\n",
    "    # Set informative log-normal priors on kernel hyperparameters.\n",
    "    # η = pm.HalfCauchy(\"η\", beta=5)\n",
    "    # η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.))\n",
    "    # ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2., 1.))\n",
    "    # σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.))\n",
    "\n",
    "    η = numpyro.param(\n",
    "        \"kernel_var\", init_value=1.0, constraints=dist.constraints.positive\n",
    "    )\n",
    "    ℓ = numpyro.param(\n",
    "        \"kernel_length\", init_value=0.1, constraints=dist.constraints.positive\n",
    "    )\n",
    "    σ = numpyro.param(\"sigma\", init_value=0.01, onstraints=dist.constraints.positive)\n",
    "\n",
    "    # Compute kernel\n",
    "    K = rbf_kernel(X, X, η, ℓ)\n",
    "    K += jnp.eye(X.shape[0]) * jnp.power(σ, 2)\n",
    "\n",
    "    Lff = jnp.linalg.cholesky(K)\n",
    "\n",
    "    # Sample y according to the standard gaussian process formula\n",
    "    return numpyro.sample(\n",
    "        \"y\",\n",
    "        dist.MultivariateNormal(loc=jnp.zeros(X.shape[0]), scale_tril=Lff)\n",
    "        .expand_by(y.shape[:-1])\n",
    "        .to_event(y.ndim - 1),\n",
    "        obs=y,\n",
    "    )\n",
    "\n",
    "\n",
    "def empty_guide(X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmJrGlYS3TuD"
   },
   "outputs": [],
   "source": [
    "K = rbf_kernel(x, x, 1.0, 1.0)\n",
    "\n",
    "# check shape\n",
    "chex.assert_shape(K, (x.shape[0], x.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBOZgRAk1qE3"
   },
   "source": [
    "## Exact GP - Maximum Marginal Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZaEHxshPGAn"
   },
   "outputs": [],
   "source": [
    "from numpyro.infer.autoguide import (\n",
    "    AutoDelta,\n",
    ")  # AutoDiagonalNormal, AutoIAFNormal, AutoLaplaceApproximation, AutoMultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yd1suJfUKgTi",
    "outputId": "7bb6d895-427b-47c4-b782-f23ecb331cc6"
   },
   "outputs": [],
   "source": [
    "type(x), type(y), y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCkOnVvbQWIF"
   },
   "outputs": [],
   "source": [
    "with numpyro.handlers.seed(rng_seed=123):\n",
    "    t = GP(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ExuqdMYNQeUi",
    "outputId": "bb9a433d-df02-4b87-de9a-7b14ea26e481"
   },
   "outputs": [],
   "source": [
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJsm0nCN69Nd",
    "outputId": "c67c9911-4ffa-43e7-b984-973dcd19dbac"
   },
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "gp_model = GP\n",
    "\n",
    "# Setup\n",
    "# guide = numpyro.infer.autoguide.AutoDelta(GP)\n",
    "optimizer = numpyro.optim.Adam(step_size=0.01)\n",
    "# optimizer = numpyro.optim.Minimize()\n",
    "# optimizer = optax.adamw(learning_rate=0.1)\n",
    "svi = SVI(gp_model, empty_guide, optimizer, loss=Trace_ELBO())\n",
    "svi_results = svi.run(random.PRNGKey(1), 1_000, x, y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "76vAkN08OeLr",
    "outputId": "441d830c-0b59-4617-f876-54f04981c7a8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(svi_results.losses)\n",
    "ax.set(title=\"Loss\", xlabel=\"Iterations\", ylabel=\"Negative ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJ8UTKuBMJx4"
   },
   "source": [
    "### Extracting the Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSOYGadfMLPf",
    "outputId": "10177286-c6dd-48a9-fedb-61062150c908"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Take them directly\n",
    "learned_params = svi_results.params\n",
    "pprint(learned_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxXJaN-oJ6av"
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPz3jhYOJ9Wk"
   },
   "outputs": [],
   "source": [
    "def cholesky_factorization(K: np.ndarray, Y: np.ndarray) -> Tuple[np.ndarray, bool]:\n",
    "    \"\"\"Cholesky Factorization\"\"\"\n",
    "    # cho factor the cholesky\n",
    "    L = jax.scipy.linalg.cho_factor(K, lower=True)\n",
    "\n",
    "    # weights\n",
    "    weights = jax.scipy.linalg.cho_solve(L, Y)\n",
    "\n",
    "    return L, weights\n",
    "\n",
    "\n",
    "# Predictive Mean and Variance\n",
    "def predict(X, Y, X_test, variance, length_scale, noise):\n",
    "\n",
    "    K = rbf_kernel(X, X, variance, length_scale)\n",
    "    L, alpha = cholesky_factorization(K + noise * np.eye(K.shape[0]), Y)\n",
    "\n",
    "    # Calculate the Mean\n",
    "    K_x = rbf_kernel(X_test, X, variance, length_scale)\n",
    "    mu_y = np.dot(K_x, alpha)\n",
    "\n",
    "    # Calculate the variance\n",
    "    v = jax.scipy.linalg.cho_solve(L, K_x.T)\n",
    "\n",
    "    # Calculate kernel matrix for inputs\n",
    "    K_xx = rbf_kernel(X_test, X_test, variance, length_scale)\n",
    "\n",
    "    cov_y = K_xx - jnp.dot(K_x, v)\n",
    "    return mu_y, cov_y\n",
    "\n",
    "\n",
    "# Summarize function posterior.\n",
    "def posterior(rng_key, X, Y, X_test, variance, length_scale, noise):\n",
    "    m, cov = predict(X, Y, X_test, variance, length_scale, noise)\n",
    "\n",
    "    return random.multivariate_normal(rng_key, mean=m, cov=cov)\n",
    "\n",
    "\n",
    "def summarize_posterior(preds, ci=96):\n",
    "    ci_lower = (100 - ci) / 2\n",
    "    ci_upper = (100 + ci) / 2\n",
    "    preds_mean = preds.mean(0)\n",
    "    preds_lower = jnp.percentile(preds, ci_lower, axis=0)\n",
    "    preds_upper = jnp.percentile(preds, ci_upper, axis=0)\n",
    "    return preds_mean, preds_lower, preds_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0plBDZxzoOD"
   },
   "outputs": [],
   "source": [
    "y_pred, y_cov = predict(\n",
    "    x,\n",
    "    y.squeeze(),\n",
    "    xtest,\n",
    "    variance=learned_params[\"kernel_var\"],\n",
    "    length_scale=learned_params[\"kernel_length\"],\n",
    "    noise=learned_params[\"sigma\"],\n",
    ")\n",
    "\n",
    "y_var = jnp.diagonal(y_cov)\n",
    "y_std = jnp.sqrt(y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "bHhVFQBoFJow",
    "outputId": "bae1b639-2a14-4454-cb40-26ffbb4a8fd5"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "ax.scatter(x, y, label=\"Training Data\", color=\"red\")\n",
    "ax.plot(xtest, y_pred, label=\"Predictive Mean\", color=\"black\", linewidth=3)\n",
    "ax.fill_between(\n",
    "    xtest.squeeze(),\n",
    "    y_pred - y_std,\n",
    "    y_pred + y_std,\n",
    "    label=\"Confidence Interval\",\n",
    "    alpha=0.3,\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyooid0DSdxr"
   },
   "source": [
    "## Sparse GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgqQ4KJnS5vK"
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "key = jax.random.PRNGKey(seed=seed)\n",
    "\n",
    "N = 1_000\n",
    "Ninducing = 50\n",
    "Nfeatures = 1\n",
    "Ntest = 1_000\n",
    "noise = 0.2\n",
    "\n",
    "\n",
    "# x = jax.random.uniform(key=key, minval=-3.0, maxval=3.0, shape=(N,)).sort().reshape(-1, 1)\n",
    "# f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "# signal = f(x)\n",
    "# y = signal + jax.random.normal(key, shape=signal.shape) * noise\n",
    "\n",
    "# xtest = jnp.linspace(-3.5, 3.5, Ntest).reshape(-1, 1)\n",
    "# ytest = f(xtest)\n",
    "\n",
    "\n",
    "# x = jax.random.uniform(key=key, minval=-3.0, maxval=3.0, shape=(N,)).sort().reshape(-1, 1)\n",
    "# f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "# signal = f(x)\n",
    "# y = signal + jax.random.normal(key, shape=signal.shape) * noise\n",
    "\n",
    "# x = jax.random.uniform(key=key, minval=0.0, maxval=5.0, shape=(N,)).sort().reshape(-1, 1)\n",
    "# f = lambda x: 0.5 * jnp.sin(3.0 * x)\n",
    "# signal = f(x)\n",
    "# y = signal + noise * jax.random.normal(key, shape=signal.shape)\n",
    "\n",
    "# rng.rand(N, 1) * 2 - 1\n",
    "x = jnp.linspace(-1.0, 1.0, 1_000).reshape(-1, 1)  # * 2.0 - 1.0\n",
    "f = (\n",
    "    lambda x: jnp.sin(x * 3 * 3.14)\n",
    "    + 0.3 * jnp.cos(x * 9 * 3.14)\n",
    "    + 0.5 * jnp.sin(x * 7 * 3.14)\n",
    ")\n",
    "\n",
    "signal = f(x)\n",
    "y = signal + noise * jax.random.normal(key, shape=signal.shape)\n",
    "\n",
    "\n",
    "xtest = jnp.linspace(-1.1, 1.1, 1_000).reshape(-1, 1)\n",
    "ytest = f(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkLu8bOO2qK5",
    "outputId": "18cdf5d7-0633-410d-b0fe-8ea51c5c5ff6"
   },
   "outputs": [],
   "source": [
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "a4DqFYT0S_qH",
    "outputId": "850a3296-984a-424c-be32-fd4c8e43d5dd"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(x, y, \"o\", label=\"Observations\", color=\"tab:orange\", alpha=0.5)\n",
    "ax.plot(xtest, ytest, label=\"Latent function\", color=\"tab:blue\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTZRTOttT-0A"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFegle9GIc_q"
   },
   "source": [
    "#### Inducing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7Il_BBYHZnZ"
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "\n",
    "def init_inducing_kmeans(x: chex.Array, n_inducing: int) -> chex.Array:\n",
    "    # conver to numpy array\n",
    "    x = np.array(x)\n",
    "\n",
    "    # calculate k-means\n",
    "    x_u_init = kmeans2(x, n_inducing, minit=\"points\")[0]\n",
    "\n",
    "    # convert to jax array\n",
    "    x_u_init = jnp.array(x_u_init)\n",
    "\n",
    "    return x_u_init\n",
    "\n",
    "\n",
    "def init_inducing_subsample(key, x: chex.Array, n_inducing: int) -> chex.Array:\n",
    "\n",
    "    # random permutation and subsample\n",
    "    x_u_init = jax.random.permutation(key, x)[:n_inducing]\n",
    "\n",
    "    return x_u_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUcu7nDcJZHM",
    "outputId": "b2d89e03-eca8-47c6-bc3b-d57d79bf1528"
   },
   "outputs": [],
   "source": [
    "Ninducing = 20\n",
    "\n",
    "\n",
    "x_u_init = init_inducing_kmeans(x, Ninducing)\n",
    "print(x_u_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DwsAo20NesO"
   },
   "outputs": [],
   "source": [
    "# squared euclidean distance\n",
    "def sqeuclidean_distance(x: np.array, y: np.array) -> float:\n",
    "    return jnp.sum((x - y) ** 2)\n",
    "\n",
    "\n",
    "# distance matrix\n",
    "def cross_covariance(func: Callable, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"distance matrix\"\"\"\n",
    "    return jax.vmap(lambda x1: jax.vmap(lambda y1: func(x1, y1))(y))(x)\n",
    "\n",
    "\n",
    "# kernel function\n",
    "def rbf_kernel(X, Y, variance, length_scale):\n",
    "    # distance formula\n",
    "    deltaXsq = cross_covariance(\n",
    "        sqeuclidean_distance, X / length_scale, Y / length_scale\n",
    "    )\n",
    "\n",
    "    # rbf function\n",
    "    K = variance * jnp.exp(-0.5 * deltaXsq)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aNYlYxSSfHh"
   },
   "outputs": [],
   "source": [
    "def SparseGP(X, y):\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    # Set informative log-normal priors on kernel hyperparameters.\n",
    "    # η = pm.HalfCauchy(\"η\", beta=5)\n",
    "    η = numpyro.sample(\"kernel_var\", dist.HalfCauchy(scale=5.0))\n",
    "    ℓ = numpyro.sample(\"kernel_length\", dist.Gamma(2.0, 1.0))\n",
    "    σ = numpyro.sample(\"sigma\", dist.HalfCauchy(scale=5.0))\n",
    "\n",
    "    x_u = numpyro.param(\"x_u\", init_value=x_u_init)\n",
    "\n",
    "    # η = numpyro.param(\"kernel_var\", init_value=1.0, constraints=dist.constraints.positive)\n",
    "    # ℓ = numpyro.param(\"kernel_length\", init_value=1.0,  constraints=dist.constraints.positive)\n",
    "    # σ = numpyro.param(\"sigma\", init_value=1.0, onstraints=dist.constraints.positive)\n",
    "\n",
    "    # ================================\n",
    "    # Qff Term\n",
    "    # ================================\n",
    "    # W   = (inv(Luu) @ Kuf).T\n",
    "    # Qff = Kfu @ inv(Kuu) @ Kuf\n",
    "    # Qff = W @ W.T\n",
    "    # ================================\n",
    "    Kuu = rbf_kernel(x_u, x_u, η, ℓ)\n",
    "    Kuf = rbf_kernel(x_u, X, η, ℓ)\n",
    "    Kuu += jnp.eye(Ninducing) * 1e-5  # jax.ops.index_add(Kuu, Ninducing, 1e-5)\n",
    "    # print(Kuu.min(), Kuu.max())\n",
    "    Luu = jnp.linalg.cholesky(Kuu)\n",
    "    # print(Luu.min(), Luu.max())\n",
    "    # print(Luu.shape)\n",
    "    W = jax.scipy.linalg.solve_triangular(Luu, Kuf, lower=True).T\n",
    "\n",
    "    # print(W.shape)\n",
    "\n",
    "    # Luu = jax.scipy.linalg.cho_factor(Kuu, lower=True)\n",
    "    # W = jax.scipy.linalg.cho_solve(Luu, Kuf).T\n",
    "\n",
    "    # ================================\n",
    "    # Likelihood Noise Term\n",
    "    # ================================\n",
    "    # D = noise\n",
    "    # ================================\n",
    "    D = jnp.ones(n_samples) * σ\n",
    "\n",
    "    # ================================\n",
    "    # trace term\n",
    "    # ================================\n",
    "    # t = tr(Kff - Qff) / noise\n",
    "    # t = - t / 2.0\n",
    "    # ================================\n",
    "    Kffdiag = jnp.diag(rbf_kernel(X, X, η, ℓ))\n",
    "    # print(Kffdiag.min(), Kffdiag.max())\n",
    "    Qffdiag = jnp.power(W, 2).sum(axis=1)\n",
    "    # print(Qffdiag.min(), Qffdiag.max())\n",
    "    trace_term = (Kffdiag - Qffdiag).sum() / σ\n",
    "    trace_term = jnp.clip(trace_term, a_min=0.0)  # numerical errors\n",
    "    # print(trace_term)\n",
    "    numpyro.factor(\"trace_term\", -trace_term / 2.0)\n",
    "\n",
    "    # ================================\n",
    "    # Mean Function\n",
    "    # ================================\n",
    "    f_loc = np.zeros(n_samples)\n",
    "\n",
    "    # Sample y according SGP\n",
    "    return numpyro.sample(\n",
    "        \"y\",\n",
    "        dist.LowRankMultivariateNormal(loc=f_loc, cov_factor=W, cov_diag=D)\n",
    "        .expand_by(y.shape[:-1])\n",
    "        .to_event(y.ndim - 1),\n",
    "        obs=y,\n",
    "    )\n",
    "\n",
    "\n",
    "def empty_guide(X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXSndHGEavHa",
    "outputId": "a4e9a590-6c23-45a5-c847-c9c6ec16e9bf"
   },
   "outputs": [],
   "source": [
    "with numpyro.handlers.seed(rng_seed=123):\n",
    "    t = SparseGP(x, y.T)\n",
    "\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4y6abAH7XJN5"
   },
   "outputs": [],
   "source": [
    "from numpyro.infer.autoguide import AutoDelta\n",
    "\n",
    "sgp_model = SparseGP\n",
    "guide = AutoDelta(sgp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCBbF1tSpvHT",
    "outputId": "b576812d-0210-414b-e7db-c4feea55f06f"
   },
   "outputs": [],
   "source": [
    "y.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgadI3B2akAi",
    "outputId": "4b9935f7-738a-499d-ae78-8a66832b83d3"
   },
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "\n",
    "n_epochs = 2_500\n",
    "\n",
    "# Setup\n",
    "optimizer = numpyro.optim.Adam(step_size=0.005)\n",
    "# optimizer = numpyro.optim.Minimize()\n",
    "\n",
    "svi = SVI(sgp_model, guide, optimizer, loss=Trace_ELBO())\n",
    "svi_results = svi.run(random.PRNGKey(1), n_epochs, x, y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "NkVKUDkRakZi",
    "outputId": "719b04f2-3364-424f-ecda-a01b8a2bcdc4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(svi_results.losses)\n",
    "ax.set(title=\"Loss\", xlabel=\"Iterations\", ylabel=\"Negative ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njYu5gjjKZFZ"
   },
   "outputs": [],
   "source": [
    "def concat_dictionaries(a: dict, b: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Append one dictionary below another. If duplicate keys exist, then the key-value pair of the second supplied\n",
    "    dictionary will be used.\n",
    "    \"\"\"\n",
    "    return {**a, **b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJjxXuP-Uc-L",
    "outputId": "a53ee971-e840-437e-a734-1929e66fece0"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Take them directly\n",
    "learned_params = svi_results.params\n",
    "pprint(learned_params)\n",
    "\n",
    "# Take them directly\n",
    "median_params = guide.median(learned_params)\n",
    "learned_params = concat_dictionaries(learned_params, median_params)\n",
    "pprint(learned_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_xquuK7SMTI"
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN-Vkci0SNui"
   },
   "outputs": [],
   "source": [
    "from chex import Array\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def sparse_cholesky_factorization(\n",
    "    learned_params: dict, x: Array, y: Array, jitter: 1e-5\n",
    ") -> dict:\n",
    "\n",
    "    params = deepcopy(learned_params)\n",
    "    n_samples = x.shape[0]\n",
    "    m_samples = learned_params[\"x_u\"].shape[0]\n",
    "    jitter = 1e-5\n",
    "\n",
    "    # calculate the cholesky factorization\n",
    "    Kuu = rbf_kernel(\n",
    "        params[\"x_u\"], params[\"x_u\"], params[\"kernel_var\"], params[\"kernel_length\"]\n",
    "    )\n",
    "    Kuu += np.eye(m_samples) * jitter\n",
    "    Luu = jnp.linalg.cholesky(Kuu)\n",
    "\n",
    "    Kuf = rbf_kernel(params[\"x_u\"], x, params[\"kernel_var\"], params[\"kernel_length\"])\n",
    "\n",
    "    W = jax.scipy.linalg.solve_triangular(Luu, Kuf, lower=True)\n",
    "    D = np.ones(n_samples) * params[\"sigma\"]\n",
    "\n",
    "    W_Dinv = W / D\n",
    "    K = W_Dinv @ W.T\n",
    "    K = jax.ops.index_add(K, Ninducing, 1.0)\n",
    "\n",
    "    L = jnp.linalg.cholesky(K)\n",
    "\n",
    "    # mean function\n",
    "    y_residual = y  # mean function\n",
    "    y_2D = y_residual.reshape(-1, n_samples).T\n",
    "    W_Dinv_y = W_Dinv @ y_2D\n",
    "\n",
    "    params[\"Luu\"] = Luu\n",
    "    params[\"W_Dinv_y\"] = W_Dinv_y\n",
    "    params[\"L\"] = L\n",
    "    params[\"y_shape\"] = y.shape[:-1]\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eu36i2chcYGB"
   },
   "outputs": [],
   "source": [
    "params = sparse_cholesky_factorization(learned_params, x, y.T, jitter=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRbvsyVNel6r"
   },
   "outputs": [],
   "source": [
    "def _pred_factorize(params, xtest):\n",
    "\n",
    "    Kux = rbf_kernel(\n",
    "        params[\"x_u\"], xtest, params[\"kernel_var\"], params[\"kernel_length\"]\n",
    "    )\n",
    "    Ws = jax.scipy.linalg.solve_triangular(params[\"Luu\"], Kux, lower=True)\n",
    "    # pack\n",
    "    pack = jnp.concatenate([params[\"W_Dinv_y\"], Ws], axis=1)\n",
    "    Linv_pack = jax.scipy.linalg.solve_triangular(params[\"L\"], pack, lower=True)\n",
    "    # unpack\n",
    "    Linv_W_Dinv_y = Linv_pack[:, : params[\"W_Dinv_y\"].shape[1]]\n",
    "    Linv_Ws = Linv_pack[:, params[\"W_Dinv_y\"].shape[1] :]\n",
    "\n",
    "    return Ws, Linv_W_Dinv_y, Linv_Ws\n",
    "\n",
    "\n",
    "def sparse_predict_mean(params: dict, xtest: Array) -> Array:\n",
    "    n_test_samples = xtest.shape[0]\n",
    "    _, Linv_W_Dinv_y, Linv_Ws = _pred_factorize(params, xtest)\n",
    "\n",
    "    loc_shape = params[\"y_shape\"] + (n_test_samples,)\n",
    "    loc = (Linv_W_Dinv_y.T @ Linv_Ws).reshape(loc_shape)\n",
    "\n",
    "    return loc.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akYB82gV8BNT"
   },
   "outputs": [],
   "source": [
    "mu = sparse_predict_mean(params, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRZE3DLHsTn3"
   },
   "outputs": [],
   "source": [
    "def sparse_predict_covariance(\n",
    "    params: dict, xtest: Array, noiseless: bool = False\n",
    ") -> Array:\n",
    "\n",
    "    n_test_samples = xtest.shape[0]\n",
    "\n",
    "    Ws, Linv_W_Dinv_y, Linv_Ws = _pred_factorize(params, xtest)\n",
    "\n",
    "    Kxx = rbf_kernel(xtest, xtest, params[\"kernel_var\"], params[\"kernel_length\"])\n",
    "\n",
    "    if not noiseless:\n",
    "        Kxx += (\n",
    "            jnp.eye(n_test_samples) * params[\"sigma\"]\n",
    "        )  # jax.ops.index_add(Kxx, n_test_samples, params[\"sigma\"])\n",
    "\n",
    "    Qss = Ws.T @ Ws\n",
    "\n",
    "    cov = Kxx - Qss + Linv_Ws.T @ Linv_Ws\n",
    "\n",
    "    cov_shape = params[\"y_shape\"] + (n_test_samples, n_test_samples)\n",
    "    cov = np.reshape(cov, cov_shape)\n",
    "\n",
    "    return cov\n",
    "\n",
    "\n",
    "def sparse_predict_variance(\n",
    "    params: dict, xtest: Array, noiseless: bool = False\n",
    ") -> Array:\n",
    "\n",
    "    n_test_samples = xtest.shape[0]\n",
    "    Ws, Linv_W_Dinv_y, Linv_Ws = _pred_factorize(params, xtest)\n",
    "    # TODO: have the kernel function have this property\n",
    "    Kxxdiag = jnp.diag(\n",
    "        rbf_kernel(xtest, xtest, params[\"kernel_var\"], params[\"kernel_length\"])\n",
    "    )\n",
    "    if not noiseless:\n",
    "        Kxxdiag += (\n",
    "            jnp.ones(n_test_samples) * params[\"sigma\"]\n",
    "        )  # jax.ops.index_add(Kxxdiag, n_test_samples, params[\"sigma\"])\n",
    "\n",
    "    Qssdiag = jnp.power(Ws, 2).sum(axis=0)\n",
    "\n",
    "    var = Kxxdiag - Qssdiag + jnp.power(Linv_Ws, 2).sum(axis=0)\n",
    "\n",
    "    var_shape = params[\"y_shape\"] + (n_test_samples,)\n",
    "    var = np.reshape(var, var_shape)\n",
    "\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzM6Er0De55y"
   },
   "outputs": [],
   "source": [
    "mu = sparse_predict_mean(params, xtest)\n",
    "cov = sparse_predict_covariance(params, xtest, noiseless=False)\n",
    "var = sparse_predict_variance(params, xtest, noiseless=False)\n",
    "\n",
    "one_stddev = 1.96 * jnp.sqrt(np.diag(cov.squeeze()))\n",
    "one_stddev_ = 1.96 * jnp.sqrt(var.squeeze())\n",
    "# chex.assert_tree_all_close(one_stddev, one_stddev_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "fo0Uq1fBr5Kf",
    "outputId": "d332c639-8da4-4464-b1bb-5bff1272befc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(x, y.squeeze(), \"o\", color=\"tab:orange\")\n",
    "ax.plot(xtest, mu.ravel(), color=\"tab:blue\")\n",
    "ax.fill_between(\n",
    "    xtest.ravel(),\n",
    "    mu.ravel() - one_stddev,\n",
    "    mu.ravel() + one_stddev,\n",
    "    alpha=0.4,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "plt.scatter(\n",
    "    learned_params[\"x_u\"],\n",
    "    np.zeros(Ninducing),\n",
    "    label=\"Inducing Points\",\n",
    "    color=\"black\",\n",
    "    marker=\"x\",\n",
    "    zorder=3,\n",
    ")\n",
    "ax.plot(xtest, mu.ravel() - one_stddev_, linestyle=\"--\", color=\"tab:blue\")\n",
    "ax.plot(xtest, mu.ravel() + one_stddev_, linestyle=\"--\", color=\"tab:blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIeyhmXY9N75"
   },
   "source": [
    "### Uncertain Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqBYWL39xOF"
   },
   "outputs": [],
   "source": [
    "input_var = jnp.array([0.001])\n",
    "input_cov = input_var.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r-wQPLx_AuV"
   },
   "outputs": [],
   "source": [
    "xtest = jnp.linspace(-1.1, 1.1, 1_000).reshape(-1, 1)\n",
    "ytest = f(xtest)\n",
    "\n",
    "xtest_noise = xtest + input_var * jax.random.normal(key, shape=xtest.shape)\n",
    "xtest_noise = np.sort(xtest_noise)\n",
    "ytest_noise = f(xtest_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "8SGFsSJF-3Zp",
    "outputId": "e765fb3d-0425-49fa-c58c-f8e49bf4115a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(x, y, \"o\", label=\"Observations\", color=\"tab:orange\", alpha=0.5)\n",
    "ax.plot(xtest_noise, ytest, label=\"Latent function\", color=\"tab:blue\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueSSUFoe9PXe"
   },
   "outputs": [],
   "source": [
    "mu = sparse_predict_mean(params, xtest)\n",
    "var = sparse_predict_variance(params, xtest, noiseless=False)\n",
    "\n",
    "# gradient predictive mean\n",
    "sparse_predict_mean_grad = jax.vmap(\n",
    "    jax.grad(sparse_predict_mean, argnums=1), in_axes=(None, 0)\n",
    ")\n",
    "\n",
    "# predictive mean\n",
    "dmu = sparse_predict_mean_grad(params, xtest)\n",
    "\n",
    "# predictive variance\n",
    "var_to1 = jnp.diag(dmu @ input_cov @ dmu.T)\n",
    "one_stddev_to1 = 1.96 * jnp.sqrt(var.squeeze() + var_to1.squeeze())\n",
    "# cov = sparse_predict_covariance(params, xtest, noiseless=False)\n",
    "# var = sparse_predict_variance(params, xtest, noiseless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "9LkIKa66-A9N",
    "outputId": "934155c3-abdb-48dc-9b6b-3cdd6fc35031"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(x, y.squeeze(), \"o\", color=\"tab:orange\")\n",
    "ax.plot(xtest, mu.ravel(), color=\"tab:blue\")\n",
    "ax.fill_between(\n",
    "    xtest.ravel(),\n",
    "    mu.ravel() - one_stddev_to1,\n",
    "    mu.ravel() + one_stddev_to1,\n",
    "    alpha=0.4,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "plt.scatter(\n",
    "    learned_params[\"x_u\"],\n",
    "    np.zeros(Ninducing),\n",
    "    label=\"Inducing Points\",\n",
    "    color=\"black\",\n",
    "    zorder=3,\n",
    ")\n",
    "ax.plot(xtest, mu.ravel() - one_stddev_to1, linestyle=\"--\", color=\"tab:blue\")\n",
    "ax.plot(xtest, mu.ravel() + one_stddev_to1, linestyle=\"--\", color=\"tab:blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2tnqIKN-UWz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPVhyjAtkYmEsgYSbH9nQNi",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "numpyro_sparsegp_uncertain.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
