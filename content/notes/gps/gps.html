
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Basics &#8212; Research Notebook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Literature Review" href="literature.html" />
    <link rel="prev" title="Gaussian Processes" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/book_v2.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Notebook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../resources/python/overview.html">
   Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/ides.html">
     Integraded Development Environment (IDE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/stack.html">
     Standard Python Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/earthsci_stack.html">
     Earth Science Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/dl_stack.html">
     Deep Learning Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/scale_stack.html">
     Scaling Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/good_code.html">
     Good Code
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/jax_journey/overview.html">
   My JAX Journey
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">
     Ecosystem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/vmap.html">
     vmap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/jit.html">
     Jit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/classes.html">
     Classes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">
       Bisection search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">
       Kernel Derivatives
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/gfs_with_jax.html">
       Gaussianization Flows
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/remote/overview.html">
   Remote Computing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/ssh.html">
     SSH Configuration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/conda.html">
     Conda 4 Remote Servers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/jlab.html">
     Jupyter Lab 4 Remote Servers
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/notation.html">
   Notation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/quotes.html">
   Quotes
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data/overview.html">
   Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data/representation.html">
     Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data/models.html">
     Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/uncertainty.html">
   Modeling Uncertainty
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../bayesian/overview.html">
   Bayesian
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/intro.html">
     Language of Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/inference.html">
     Inference Schemes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/inference/variational_inference.html">
     Variational Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/confidence_intervals.html">
     Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/regression.html">
     Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../concepts/overview.html">
   Sleeper Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/gaussian.html">
     Gaussian Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/change_of_variables.html">
     Change of Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/identity_trick.html">
     Identity Trick
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/inverse_function.html">
     Inverse Function Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/jensens.html">
     Jensens Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/lin_alg.html">
     Linear Algebra Tricks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../kernels/overview.html">
   Kernel Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernels/kernel_derivatives.html">
     Kernel Derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernels/rv.html">
     RV Coefficient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernels/congruence_coeff.html">
     Congruence Coefficient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernels/hsic.html">
     HSIC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernels/mmd.html">
     Maximum Mean Discrepancy (MMD)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Gaussian Processes
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="literature.html">
     Literature Review
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cg.html">
     Conjugate Gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sgps.html">
     Sparse Gaussian Processes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="algorithms.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="gpr_code.html">
       GP from Scratch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="sgp_code.html">
       Sparse GP From Scratch
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/overview.html">
     Input Uncertainty in GPs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../info_theory/similarity.html">
   Similarity
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../info_theory/overview.html">
   Information Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../info_theory/measures.html">
     Measures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/information.html">
       Information Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/entropy.html">
       Entropy &amp; Relative Entropy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/mutual_info.html">
       Mutual Information and Total Correlation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../info_theory/estimators.html">
     Information Theory Measures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/classic.html">
       Classic Methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/histogram.html">
       Entropy Estimator - Histogram
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">
       Experiment - RBIG Sample Consistency
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../normalizing_flows/overview.html">
   Normalizing Flows
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/linear.html">
     Linear Layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/coupling_layers.html">
     Coupling Layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/conditional.html">
     Conditional Normalizing Flows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/multiscale.html">
     Multiscale
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../normalizing_flows/lecture_1_ig.html">
     Lecture I - Iterative Gaussianization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/1.0_univariate_gauss.html">
       1.1 - Univariate Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/1.1_marginal_gauss.html">
       1.2 - Marginal Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/1.2_gaussianization.html">
       1.2 - Iterative Gaussianization
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../normalizing_flows/lecture_2_gf.html">
     Lecture II - Gaussianization Flows
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt1_mg.html">
       Parameterized Marginal Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt2_rot.html">
       Parameterized Rotations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt3_plane.html">
       Example - 2D Plane
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../inr/overview.html">
   Implicit Neural Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../inr/formulation.html">
     Formulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inr/literature_review.html">
     Literature Review
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data_assimilation/overview.html">
   Data Assimilation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/dynamical_sys.html">
     Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/oi.html">
     Optimal Interpolation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/interp.html">
     Interpolation Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/emu.html">
     Emulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/inv_problems.html">
     Inverse Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/projects.html">
     Projects
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../data_assimilation/algorithms.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/markov_models.html">
       Markov Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/gauss_markov.html">
       Gauss-Markov Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/kf.html">
       Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/nkf.html">
       Normalizing Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/enskf.html">
       Ensemble Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/dmm.html">
       Deep Markov Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/4dvarnet.html">
       4DVarNet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/markov_gp.html">
       Markovian Gaussian Processes
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../misc/overview.html">
   Miscellaneous Notes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../misc/generative_models.html">
     Generative Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../misc/diffusion_models.html">
     Diffusion Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../misc/fixed_point.html">
     Fixed-Point Methods
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Cheat Sheets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../cheatsheets/bash.html">
   Bash
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cheatsheets/cli.html">
   Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cheatsheets/python.html">
   Python
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jejjohnson/research_notebook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/gps/gps.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/content/notes/gps/gps.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference">
   Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gp-training">
   GP Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#drawbacks">
   Drawbacks
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Basics</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference">
   Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gp-training">
   GP Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#drawbacks">
   Drawbacks
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="basics">
<h1>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">#</a></h1>
<p>Consider the regression setting where we assume the following model:
$<span class="math notranslate nohighlight">\(
 y = \boldsymbol{f}(\mathbf{x}) + \epsilon
\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is a discriminate vector of inputs, <span class="math notranslate nohighlight">\(\mathbf{f}(\cdot)=\left[f_1, \ldots, f_N \right]\)</span> is a latent GP function, and <span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N} (0, \sigma_y^2)\)</span> is a independently, identically distributed (i.i.d.) Gaussian noise parameter. We place a GP <span class="math notranslate nohighlight">\(\textbf{prior}\)</span> for <span class="math notranslate nohighlight">\(p(\boldsymbol{f})\)</span> s.t.</p>
<div class="math notranslate nohighlight">
\[
p (\boldsymbol{f}|\mathbf{X}, \boldsymbol{\theta}) \sim \mathcal{GP} \left(\mathbf{m}_{\boldsymbol\psi}, \mathbf{K}_{\boldsymbol\phi}\right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu_\mathcal{GP}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{K}_\mathcal{GP}\)</span> are the mean and covariance matrix for the GP, <span class="math notranslate nohighlight">\(\boldsymbol{\theta} = \left\{ \boldsymbol{\psi,\phi}\right\}\)</span> are the parameters of the model and <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is the data. Combining this prior with the regression problem model from the previous equation, we assume a <strong>likelihood</strong> function:</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
    p (y | \boldsymbol{f}, \mathbf{X}) \sim \mathcal{N} (y | \boldsymbol{f} (\mathbf{x}), \sigma_y^2 \mathbf{I})
\end{equation}
\]</div>
<p>We can invoke Bayes rule giving us the joint posterior distribution:
$<span class="math notranslate nohighlight">\(
\begin{equation}
    p (\boldsymbol{f}, \boldsymbol{f}_* | y) = \frac{p(\boldsymbol{f}, \boldsymbol{f}_*)p(y|\boldsymbol{f})}{p(y)}
\end{equation}
\)</span><span class="math notranslate nohighlight">\(
where \)</span>p(y)<span class="math notranslate nohighlight">\( is the marginal likelihood which we can obtain by integrating out the latent variables \)</span>\boldsymbol{f}<span class="math notranslate nohighlight">\(:
\)</span><span class="math notranslate nohighlight">\(
\begin{aligned}
    p(y) &amp;= \int_{\boldsymbol{f}} p(y,\boldsymbol{f})d\boldsymbol{f} \\
    &amp;= \mathcal{N} (y | \boldsymbol{\mu}_\mathcal{GP}, \mathbf{K} + \sigma^2\mathbf{I}) \\
    &amp;= \mathcal{N} (y | \boldsymbol{\mu}_\mathcal{GP}, \mathbf{K}_{\mathcal{GP}})
\end{aligned}
\)</span><span class="math notranslate nohighlight">\(
In a regression setting, we are more interested in predictions; given some parameters and some data, what is the predictive function \)</span>\boldsymbol{f}$? This is known as  the {posterior} distribution:</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
    p( \boldsymbol{f} |  y, \mathbf{X}, \boldsymbol{\theta}) \sim \mathcal{N} (\boldsymbol{\mu}_{\mathcal{GP}} , \boldsymbol{\nu}^2_{GP})
\end{equation}
\]</div>
<hr class="docutils" />
<section id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">#</a></h2>
<p>First, given the joint distribution of <span class="math notranslate nohighlight">\(\boldsymbol{f}, \boldsymbol{f}_*\)</span> conditioned on <span class="math notranslate nohighlight">\(\mathbf{X,X_*}\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation} 
p(\boldsymbol{f}, \boldsymbol{f}_*|\mathbf{x}, \mathbf{x}_*)=\mathcal{N}\left( 
    \begin{bmatrix}  
    \boldsymbol{f} \\ \boldsymbol{f}_*
    \end{bmatrix}; 
    \begin{bmatrix}
    \boldsymbol{m}(\mathbf{x}) \\ \boldsymbol{m}(\mathbf{x}_*)
    \end{bmatrix},
    \begin{bmatrix}
    \mathbf{K} &amp; \mathbf{K}_* \\
    \mathbf{K}_* &amp; \mathbf{K}_{**}
    \end{bmatrix} \right)
\end{equation}
\end{split}\]</div>
<p>If we condition on our training inputs <span class="math notranslate nohighlight">\(D=(\mathbf{X}, y)\)</span>, we can come up with a <strong>predictive distribution</strong> for test points <span class="math notranslate nohighlight">\(\mathbf{x}_*\)</span> via</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
    p(\boldsymbol{f}_* | \boldsymbol{f}) = \mathcal{N} (\boldsymbol{\mu}_{\mathcal{GP}*} , \boldsymbol{\nu}^2_{\mathcal{GP}**})
\end{equation}
\]</div>
<p>and we can give the GP predictive mean and variance functions as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    \boldsymbol{\mu}_{\mathcal{GP}} &amp;= \underbrace{m (\mathbf{x}_*)}_{\text{Prior Mean}} + \underbrace{\boldsymbol{k}_{*} \mathbf{K}^{-1}}_{\text{Kalman Gain}}\underbrace{(y- m (\mathbf{X}))}_{\text{Error}}\\
    \boldsymbol{\nu}^2_{\mathcal{GP}} &amp;= k_{**} - \boldsymbol{k}_{*} \mathbf{K}^{-1}\boldsymbol{k}_{*}^{\top}.
\end{aligned}
\end{split}\]</div>
<p>If we integrate out the <span class="math notranslate nohighlight">\(\boldsymbol{f}\)</span> (or just take the conditional distribution of the joint PDF), then we get:
$<span class="math notranslate nohighlight">\(
\begin{aligned}
    p(\boldsymbol{f}_*|\mathbf{x}_*, \mathbf{x}, y) &amp;= \int_{\boldsymbol{f}} p(\boldsymbol{f}|\mathbf{x}, y) p(\boldsymbol{f}_*|\mathbf{x}_*,y)d\boldsymbol{f} \\
    &amp;= \mathcal{N}(\boldsymbol{f}_*|\mu_*, \Sigma_*)
\end{aligned}
\)</span><span class="math notranslate nohighlight">\(
and the joint distribution of \)</span>\boldsymbol{f}<em>*<span class="math notranslate nohighlight">\( and unobserved \)</span>y<span class="math notranslate nohighlight">\(:
\)</span><span class="math notranslate nohighlight">\(
\begin{equation} 
p(y, \boldsymbol{f}_*|\mathbf{x}, \mathbf{x}_*)=\mathcal{N}\left( 
    \begin{bmatrix}  
    \boldsymbol{f} \\ \boldsymbol{f}_*
    \end{bmatrix}; 
    \begin{bmatrix}
    \mathcal{GP}M(\mathbf{x}) \\ \mathcal{GP}M(\mathbf{x}_*)
    \end{bmatrix},
    \begin{bmatrix}
    \mathcal{GP}K(\mathbf{x}, \mathbf{x}) + \sigma^2\mathbf{I} &amp; \mathcal{GP}K(\mathbf{x}, \mathbf{x}_*) \\
    \mathcal{GP}K(\mathbf{x}, \mathbf{x}_*) &amp; \mathcal{GP}K(\mathbf{x}_*, \mathbf{x}_*)
    \end{bmatrix} \right)
\end{equation}
\)</span><span class="math notranslate nohighlight">\(
which gives us the mean predictions and the variance in our predictions:
\)</span><span class="math notranslate nohighlight">\(
\begin{align}
    \boldsymbol{\mu}_{\mathcal{GP}} &amp;= \underbrace{ \boldsymbol{m}(\mathbf{x}_*)}_{\text{Prior Mean}} + \underbrace{\mathbf{k}_{*} \mathbf{K}^{-1}}_{\text{Kalman Gain}}\underbrace{(y- \boldsymbol{m}(\mathbf{X}))}_{\text{Error}}= \boldsymbol{m}(\mathbf{x}_*) + \mathbf{K}_{*} \alpha \\
    \boldsymbol{\nu}^2_{\mathcal{GP}} &amp;= \underbrace{k_{**}}_{\text{Prior Variance}} - \mathbf{k}_{*} \mathbf{K}_{\mathcal{GP}}^{-1}\mathbf{k}_{*}^{\top}
\end{align}
\)</span><span class="math notranslate nohighlight">\(
where \)</span>\alpha = \mathbf{K}^{-1}(y-m(\mathbf{X}))<span class="math notranslate nohighlight">\( and \)</span>\mathbf{K}</em>\mathcal{GP}=\mathbf{K}<em>\theta(\mathbf{X,X})+\sigma^2\mathbf{I}<span class="math notranslate nohighlight">\(. This is the typical formulation~\ref{fig:intro-probabilistic} which assumes that the output of \)</span>\mathbf{x}<span class="math notranslate nohighlight">\( (and \)</span>\mathbf{x}</em><em><span class="math notranslate nohighlight">\() is deterministic. In section~\ref{chapter3:egp}, we will look at the case where \)</span>\mathbf{x}_</em>$ is stochastic.</p>
</section>
<section id="gp-training">
<h2>GP Training<a class="headerlink" href="#gp-training" title="Permalink to this headline">#</a></h2>
<p>In GP model inference, one maximizes the likelihood of the data <span class="math notranslate nohighlight">\(D\)</span> given the hyper-parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}, \boldsymbol{\sigma}_y^2\)</span>. The marginal likelihood is given by:</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
    p (y | \mathbf{X}, \theta) = \mathcal{N} \left( y | \mathcal{GP}M, \mathcal{GP}K + \sigma_y^2\mathbf{I} \right)
\end{equation}
\]</div>
<p>We can find the hyper-parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> by maximizing the marginal log-likelihood. So fully expanding of the eq: \ref{eq:gp_ml}, we get:
$<span class="math notranslate nohighlight">\(
\begin{equation}
    \log p (y | \mathbf{X}, \theta) = -\underbrace{\frac{1}{2}(y - \mathcal{GP}M)^{\top} \mathbf{K}_{\mathcal{GP}}^{-1} (y - \mathcal{GP}M)}_{\text{Data-Fit}}  - \underbrace{\frac{1}{2} \log \left| \mathbf{K}_{GP} \right|}_{\text{Complexity}} - \frac{N}{2}\log 2\pi
\end{equation}
\)</span>$</p>
<p>This maximization automatically embodies Occam’s razor which does a trade-off between model complexity and overfitting. This is closed form for all GPs but these days, we typically use automatic differentiation toolboxes to alleviate some of the burden.  Irregardless, the two most expensive calculations are within this procedure as the inversion of <span class="math notranslate nohighlight">\(\matinv{\mathbf{K}}_{\mathcal{GP}}\)</span> and the <span class="math notranslate nohighlight">\(\Det{\mathbf{K}_{\mathcal{GP}}}\)</span>; since <span class="math notranslate nohighlight">\(\mathbf{K} \in \Real^{N \times N}\)</span>, then these calculations are <span class="math notranslate nohighlight">\(\bigO (N^3)\)</span> in operations and <span class="math notranslate nohighlight">\(\bigO (N^2)\)</span> in memory costs. The kernel function is one of the most important aspects within the GP training regime. Once the kernel has been chosen to best reflect the problem at hand it has been found in \cite{GPPRIOR2018} that any prior over the hyper-parameters does not provide significant improvements in GP predictions. However, note that the community is notorious for using the isotropic RBF kernel by default when conducting research. This kernel is the most flexible among the kernel family but not necessarily the most expressive~\cite{AUTOGP2017}.</p>
</section>
<section id="drawbacks">
<h2>Drawbacks<a class="headerlink" href="#drawbacks" title="Permalink to this headline">#</a></h2>
<p>\begin{displayquote}
“\textit{It is important to keep in mind that Gaussian processes are not appropriate priors for all problems.}” \
– Neal, 1998
\end{displayquote}</p>
<p>It is important to note that although the GP algorithm is one of the most trusted and reliable algorithms, it is not always the best algorithm to use for all problems. Below we mention a few drawbacks that the standard GP algorithm has along with some of the standard approaches to overcoming these drawbacks.</p>
<p>\vspace{2mm} \noindent \textbf{Gaussian Marginals}. GPs have problems modeling heavy-tailed, asymmetric or multi-modal marginal distributions. There are some methods that change the likelihood so that it is heavy tailed~\citep{GPTSTUDENT2011,GPTSTUDENT2014} but this would remove the conjugacy of the likelihood term which would incur difficulties during fitting. Deep GPs and latent covariate models are an improvement to this limitation. A very popular approach is to construct a fully Bayesian model. This entails hyperpriors over the kernel parameters and Monte carlo sampling methods such as Gibbs sampling~\citep{GPGIBBS08}, slice sampling~\citep{GPSLICE2010}, Hamiltonian Monte Carlo~\citep{GPHMC2018}, and Sequential Monte Carlo~\citep{GPSMC15}. These techniques will capture more complex distributions. With the advent of better software~\citep{PYMC16,NUMPYRO2019} and more advanced sampling techniques like a differentiable iterative NUTS implementation~\citep{NUMPYRO2019}, the usefulness of MC schemes is resurfacing.</p>
<p>\vspace{2mm} \noindent \textbf{Limited Number of Moments}. This is related to the previous limitation: the idea that an entire function can be captured in terms of two moments: a mean and a covariance. There are some relationships which are difficult to capture without an adequate description, e.g. discontinuities~\citep{Neal96} and non-stationary processes, and thus is a limitation of the GP priors we choose. The advent of warping the inputs or outputs of a GP has becoming a very popular technique to deal with the limited expressivity of kernels. Input warping is popular in methods such as deep kernel learning whereby a Neural network is used to capture the features and are used as inputs to the kernel function output warping is common in chained~\citep{GPCHAINED2016} and heteroscedastic methods where the function output is warped by another GP to capture the noise model of the data. Deep Gaussian processes~\citep{Damianou2015} can be thought of input and output warping methods due the multi-layer composition of function inputs and outputs.</p>
<p>\vspace{2mm} \noindent \textbf{Linearity of Predictive Mean}. The predictive mean of a GP is linear to the observations, i.e. <span class="math notranslate nohighlight">\(\mu_{GP}=\mathbf{K}\alpha\)</span>. This essentially is a smoother which can be very powerful but also will miss key features. If there is some complex structured embedded within the dataset, then a GP model can never really capture this irregardless of the covariance function found.</p>
<p>\vspace{2mm} \noindent \textbf{Predictive Covariance}. The GP predictive variance is a function of the training inputs and it is independent of the observed inputs. This is important if the input data has some information which could be used to help determine the regions of uncertainty, e.g. the gradient. An example would be data on a spatial grid whereby some regions points would have more certainty than others which could be obtained by knowing the input location and not necessarily the expected output.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/notes/gps"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Gaussian Processes</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="literature.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Literature Review</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By J. Emmanuel Johnson<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>