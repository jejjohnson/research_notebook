{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jejjohnson/gp_model_zoo/blob/master/code/numpyro/numpyro_gpr_delta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hecnCJD1trHy"
   },
   "source": [
    "# Numpyro Jax PlayGround\n",
    "\n",
    "My starting notebook where I install all of the necessary libraries and load some easy 1D/2D Regression data to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgSMWFaNtnjB"
   },
   "outputs": [],
   "source": [
    "# @title Install Packages\n",
    "%%capture\n",
    "!pip install jax jaxlib flax chex optax objax\n",
    "!pip install \"git+https://github.com/deepmind/dm-haiku\"\n",
    "!pip install \"git+https://github.com/pyro-ppl/numpyro.git#egg=numpyro\"\n",
    "!pip uninstall tensorflow -y -q\n",
    "!pip install -Uq tfp-nightly[jax] > /dev/null\n",
    "!python -m pip install -U prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "c5TKBjGbumu6"
   },
   "outputs": [],
   "source": [
    "# @title Load Packages\n",
    "# TYPE HINTS\n",
    "from typing import Tuple, Optional, Dict, Callable, Union\n",
    "\n",
    "# JAX SETTINGS\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "\n",
    "\n",
    "# JAX UTILITY LIBRARIES\n",
    "import chex\n",
    "\n",
    "# NUMPYRO SETTINGS\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer.autoguide import AutoDiagonalNormal\n",
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "# NUMPY SETTINGS\n",
    "import numpy as onp\n",
    "\n",
    "onp.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# MATPLOTLIB Settings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# SEABORN SETTINGS\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "# PANDAS SETTINGS\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# LOGGING SETTINGS\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "RSMP8Vr6x51L"
   },
   "outputs": [],
   "source": [
    "# @title Data\n",
    "def get_data(\n",
    "    n_train: int = 30,\n",
    "    input_noise: float = 0.15,\n",
    "    output_noise: float = 0.15,\n",
    "    n_test: int = 400,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, None]:\n",
    "    onp.random.seed(0)\n",
    "    X = np.linspace(-1, 1, n_train)\n",
    "    Y = X + 0.2 * np.power(X, 3.0) + 0.5 * np.power(0.5 + X, 2.0) * np.sin(4.0 * X)\n",
    "    Y += output_noise * onp.random.randn(n_train)\n",
    "    Y -= np.mean(Y)\n",
    "    Y /= np.std(Y)\n",
    "\n",
    "    X += input_noise * onp.random.randn(n_train)\n",
    "\n",
    "    assert X.shape == (n_train,)\n",
    "    assert Y.shape == (n_train,)\n",
    "\n",
    "    X_test = np.linspace(-1.2, 1.2, n_test)\n",
    "\n",
    "    return X[:, None], Y[:, None], X_test[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "cDm66m0g_jL4",
    "outputId": "9d7e2e32-0fe2-4c2e-d9e9-a27141eb762a"
   },
   "outputs": [],
   "source": [
    "n_train = 60\n",
    "input_noise = 0.0\n",
    "output_noise = 0.1\n",
    "n_test = 100\n",
    "\n",
    "X, Y, Xtest = get_data(\n",
    "    n_train=n_train, input_noise=0.0, output_noise=output_noise, n_test=n_test\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXa_nHwb3NLL"
   },
   "source": [
    "## Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLMCRQ03w-O-"
   },
   "outputs": [],
   "source": [
    "import objax\n",
    "\n",
    "\n",
    "# squared euclidean distance\n",
    "def sqeuclidean_distance(x: np.array, y: np.array) -> float:\n",
    "    return np.sum((x - y) ** 2)\n",
    "\n",
    "\n",
    "# distance matrix\n",
    "def distmat(func: Callable, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"distance matrix\"\"\"\n",
    "    return jax.vmap(lambda x1: jax.vmap(lambda y1: func(x1, y1))(y))(x)\n",
    "\n",
    "\n",
    "# 1D covariance matrix\n",
    "def rbf_kernel(X, Y, variance, length_scale):\n",
    "    # distance formula\n",
    "    deltaXsq = distmat(sqeuclidean_distance, X / length_scale, Y / length_scale)\n",
    "\n",
    "    # rbf function\n",
    "    K = variance * np.exp(-0.5 * deltaXsq)\n",
    "    return K\n",
    "\n",
    "\n",
    "class ExactGP(objax.Module):\n",
    "    def __init__(self):\n",
    "        self.var = numpyro.param(\n",
    "            \"kernel_var\", init_value=1.0, constraints=dist.constraints.positive\n",
    "        )\n",
    "        self.scale = numpyro.param(\n",
    "            \"kernel_length\", init_value=0.1, constraints=dist.constraints.positive\n",
    "        )\n",
    "        self.sigma = numpyro.param(\n",
    "            \"sigma\", init_value=0.01, onstraints=dist.constraints.positive\n",
    "        )\n",
    "\n",
    "    def model2(self, X, y=None):\n",
    "        # η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.))\n",
    "        # ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2., 1.))\n",
    "        # σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.))\n",
    "\n",
    "        # Compute kernel\n",
    "        K = rbf_kernel(X, X, self.var, self.scale)\n",
    "        K += np.eye(X.shape[0]) * np.power(self.sigma, 2)\n",
    "\n",
    "        # Sample y according to the standard gaussian process formula\n",
    "        return numpyro.sample(\n",
    "            \"y\",\n",
    "            dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "            obs=y,\n",
    "        )\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def model(self, X, y=None):\n",
    "        # η = numpyro.param(\"kernel_var\", init_value=1.0, constraints=dist.constraints.positive)\n",
    "        # ℓ = numpyro.param(\"kernel_length\", init_value=0.1,  constraints=dist.constraints.positive)\n",
    "        # σ = numpyro.param(\"sigma\", init_value=0.01, onstraints=dist.constraints.positive)\n",
    "\n",
    "        η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.0))\n",
    "        ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2.0, 1.0))\n",
    "        σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.0))\n",
    "\n",
    "        # Compute kernel\n",
    "        K = rbf_kernel(X, X, η, ℓ)\n",
    "        K += np.eye(X.shape[0]) * np.power(σ, 2)\n",
    "\n",
    "        # Sample y according to the standard gaussian process formula\n",
    "        return numpyro.sample(\n",
    "            \"y\",\n",
    "            dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "            obs=y,\n",
    "        )\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        pass\n",
    "\n",
    "    # Predictive Mean and Variance\n",
    "    def predict(X, Y, X_test, variance, length_scale, noise):\n",
    "\n",
    "        K = rbf_kernel(X, X, variance, length_scale)\n",
    "        L, alpha = cholesky_factorization(K + noise * np.eye(K.shape[0]), Y)\n",
    "\n",
    "        # Calculate the Mean\n",
    "        K_x = rbf_kernel(X_test, X, variance, length_scale)\n",
    "        mu_y = np.dot(K_x, alpha)\n",
    "\n",
    "        # Calculate the variance\n",
    "        v = jax.scipy.linalg.cho_solve(L, K_x.T)\n",
    "\n",
    "        # Calculate kernel matrix for inputs\n",
    "        K_xx = rbf_kernel(X_test, X_test, variance, length_scale)\n",
    "\n",
    "        cov_y = K_xx - np.dot(K_x, v)\n",
    "        return mu_y, cov_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOyp6OHQy0m5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8BV-rAL3PKG"
   },
   "outputs": [],
   "source": [
    "# GP model.\n",
    "def GP(X, y):\n",
    "    # Set informative log-normal priors on kernel hyperparameters.\n",
    "    # η = pm.HalfCauchy(\"η\", beta=5)\n",
    "    # η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.))\n",
    "    # ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2., 1.))\n",
    "    # σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.))\n",
    "\n",
    "    η = numpyro.param(\n",
    "        \"kernel_var\", init_value=1.0, constraints=dist.constraints.positive\n",
    "    )\n",
    "    ℓ = numpyro.param(\n",
    "        \"kernel_length\", init_value=0.1, constraints=dist.constraints.positive\n",
    "    )\n",
    "    σ = numpyro.param(\"sigma\", init_value=0.01, onstraints=dist.constraints.positive)\n",
    "\n",
    "    # Compute kernel\n",
    "    K = rbf_kernel(X, X, η, ℓ)\n",
    "    K += np.eye(X.shape[0]) * np.power(σ, 2)\n",
    "\n",
    "    # Sample y according to the standard gaussian process formula\n",
    "    return numpyro.sample(\n",
    "        \"y\",\n",
    "        dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "        obs=y,\n",
    "    )\n",
    "\n",
    "\n",
    "def empty_guide(X, y):\n",
    "    pass\n",
    "\n",
    "\n",
    "def cholesky_factorization(K: np.ndarray, Y: np.ndarray) -> Tuple[np.ndarray, bool]:\n",
    "    \"\"\"Cholesky Factorization\"\"\"\n",
    "    # cho factor the cholesky\n",
    "    L = jax.scipy.linalg.cho_factor(K, lower=True)\n",
    "\n",
    "    # weights\n",
    "    weights = jax.scipy.linalg.cho_solve(L, Y)\n",
    "\n",
    "    return L, weights\n",
    "\n",
    "\n",
    "# Predictive Mean and Variance\n",
    "def predict(X, Y, X_test, variance, length_scale, noise):\n",
    "\n",
    "    K = rbf_kernel(X, X, variance, length_scale)\n",
    "    L, alpha = cholesky_factorization(K + noise * np.eye(K.shape[0]), Y)\n",
    "\n",
    "    # Calculate the Mean\n",
    "    K_x = rbf_kernel(X_test, X, variance, length_scale)\n",
    "    mu_y = np.dot(K_x, alpha)\n",
    "\n",
    "    # Calculate the variance\n",
    "    v = jax.scipy.linalg.cho_solve(L, K_x.T)\n",
    "\n",
    "    # Calculate kernel matrix for inputs\n",
    "    K_xx = rbf_kernel(X_test, X_test, variance, length_scale)\n",
    "\n",
    "    cov_y = K_xx - np.dot(K_x, v)\n",
    "    return mu_y, cov_y\n",
    "\n",
    "\n",
    "# Summarize function posterior.\n",
    "def posterior(rng_key, X, Y, X_test, variance, length_scale, noise):\n",
    "    m, cov = predict(X, Y, X_test, variance, length_scale, noise)\n",
    "\n",
    "    return random.multivariate_normal(rng_key, mean=m, cov=cov)\n",
    "\n",
    "\n",
    "def summarize_posterior(preds, ci=96):\n",
    "    ci_lower = (100 - ci) / 2\n",
    "    ci_upper = (100 + ci) / 2\n",
    "    preds_mean = preds.mean(0)\n",
    "    preds_lower = np.percentile(preds, ci_lower, axis=0)\n",
    "    preds_upper = np.percentile(preds, ci_upper, axis=0)\n",
    "    return preds_mean, preds_lower, preds_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmJrGlYS3TuD"
   },
   "outputs": [],
   "source": [
    "K = rbf_kernel(X, X, 1.0, 1.0)\n",
    "\n",
    "# check shape\n",
    "chex.assert_shape(K, (n_train, n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvOFOYbme8Jx"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "final_params = PrettyTable()\n",
    "\n",
    "final_params.field_names = [\n",
    "    \"Method\",\n",
    "    \"Kernel Variance\",\n",
    "    \"Kernel Length Scale\",\n",
    "    \"Likelihood Noise\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBOZgRAk1qE3"
   },
   "source": [
    "## Exact GP - Delta (i.e. MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZaEHxshPGAn"
   },
   "outputs": [],
   "source": [
    "from numpyro.infer.autoguide import (\n",
    "    AutoDelta,\n",
    ")  # AutoDiagonalNormal, AutoIAFNormal, AutoLaplaceApproximation, AutoMultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJsm0nCN69Nd",
    "outputId": "64a10bf7-720d-418c-cd55-b9f3377c1e2f"
   },
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "gp_model = ExactGP()\n",
    "\n",
    "# Setup\n",
    "guide = numpyro.infer.autoguide.AutoDelta(gp_model.model)\n",
    "optimizer = numpyro.optim.Adam(step_size=0.01)\n",
    "# optimizer = numpyro.optim.Minimize()\n",
    "# optimizer = optax.adamw(learning_rate=0.1)\n",
    "svi = SVI(gp_model.model, guide, optimizer, loss=Trace_ELBO())\n",
    "svi_results = svi.run(random.PRNGKey(1), 1_000, X, Y.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1z2LnUMec5EU"
   },
   "source": [
    "##### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "76vAkN08OeLr",
    "outputId": "0ffbb568-7fec-4a8e-c0b7-5ad5f3e32885"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(svi_results.losses)\n",
    "ax.set(title=\"Loss\", xlabel=\"Iterations\", ylabel=\"Negative ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UY4sERudCE0",
    "outputId": "5c883cf3-b6d3-493f-fa7a-c3b623bdc4dc"
   },
   "outputs": [],
   "source": [
    "params = svi_results.params\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUBZqMPWdO4y"
   },
   "source": [
    "##### Median Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-JVd2d6dQKu",
    "outputId": "c7838be3-d6e5-4116-b289-be1576e2969e"
   },
   "outputs": [],
   "source": [
    "median = guide.median(params)\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKRLkO-5fAhw"
   },
   "outputs": [],
   "source": [
    "final_params.add_row(\n",
    "    [\"VI Delta (MAP)\", median[\"variance\"], median[\"length_scale\"], median[\"noise\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLTEM5cefNoX",
    "outputId": "dd0d5a43-f0ed-4ff7-ef3e-189b8b730df3"
   },
   "outputs": [],
   "source": [
    "print(final_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRKF06Dkd5Yg"
   },
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0plBDZxzoOD"
   },
   "outputs": [],
   "source": [
    "y_pred, y_cov = predict(\n",
    "    X,\n",
    "    Y.squeeze(),\n",
    "    Xtest,\n",
    "    variance=median[\"variance\"],\n",
    "    length_scale=median[\"length_scale\"],\n",
    "    noise=median[\"noise\"],\n",
    ")\n",
    "\n",
    "y_var = np.diagonal(y_cov)\n",
    "y_std = np.sqrt(y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "bHhVFQBoFJow",
    "outputId": "3e5a7d9b-1b94-4a51-df54-f7e76cad949e"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "ax.scatter(X, Y, label=\"Training Data\", color=\"red\")\n",
    "ax.plot(Xtest, y_pred, label=\"Predictive Mean\", color=\"black\", linewidth=3)\n",
    "ax.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    y_pred - y_std,\n",
    "    y_pred + y_std,\n",
    "    label=\"Confidence Interval\",\n",
    "    alpha=0.3,\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDfX7FM1cqIf"
   },
   "source": [
    "## Inference - MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGrMLgQQcuYt"
   },
   "outputs": [],
   "source": [
    "class ExactGP(objax.Module):\n",
    "    def __init__(self):\n",
    "        self.var = numpyro.param(\n",
    "            \"kernel_var\", init_value=1.0, constraints=dist.constraints.positive\n",
    "        )\n",
    "        self.scale = numpyro.param(\n",
    "            \"kernel_length\", init_value=0.1, constraints=dist.constraints.positive\n",
    "        )\n",
    "        self.sigma = numpyro.param(\n",
    "            \"sigma\", init_value=0.01, onstraints=dist.constraints.positive\n",
    "        )\n",
    "\n",
    "    def model2(self, X, y=None):\n",
    "        # η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.))\n",
    "        # ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2., 1.))\n",
    "        # σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.))\n",
    "\n",
    "        # Compute kernel\n",
    "        K = rbf_kernel(X, X, self.var, self.scale)\n",
    "        K += np.eye(X.shape[0]) * np.power(self.sigma, 2)\n",
    "\n",
    "        # Sample y according to the standard gaussian process formula\n",
    "        return numpyro.sample(\n",
    "            \"y\",\n",
    "            dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "            obs=y,\n",
    "        )\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def model(self, X, y=None):\n",
    "        η = numpyro.param(\n",
    "            \"kernel_var\", init_value=1.0, constraints=dist.constraints.positive\n",
    "        )\n",
    "        ℓ = numpyro.param(\n",
    "            \"kernel_length\", init_value=0.1, constraints=dist.constraints.positive\n",
    "        )\n",
    "        σ = numpyro.param(\n",
    "            \"sigma\", init_value=0.01, onstraints=dist.constraints.positive\n",
    "        )\n",
    "\n",
    "        # η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.))\n",
    "        # ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2., 1.))\n",
    "        # σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.))\n",
    "\n",
    "        # Compute kernel\n",
    "        K = rbf_kernel(X, X, η, ℓ)\n",
    "        K += np.eye(X.shape[0]) * np.power(σ, 2)\n",
    "\n",
    "        # Sample y according to the standard gaussian process formula\n",
    "        return numpyro.sample(\n",
    "            \"y\",\n",
    "            dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "            obs=y,\n",
    "        )\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        pass\n",
    "\n",
    "    # Predictive Mean and Variance\n",
    "    def predict(X, Y, X_test, variance, length_scale, noise):\n",
    "\n",
    "        K = rbf_kernel(X, X, variance, length_scale)\n",
    "        L, alpha = cholesky_factorization(K + noise * np.eye(K.shape[0]), Y)\n",
    "\n",
    "        # Calculate the Mean\n",
    "        K_x = rbf_kernel(X_test, X, variance, length_scale)\n",
    "        mu_y = np.dot(K_x, alpha)\n",
    "\n",
    "        # Calculate the variance\n",
    "        v = jax.scipy.linalg.cho_solve(L, K_x.T)\n",
    "\n",
    "        # Calculate kernel matrix for inputs\n",
    "        K_xx = rbf_kernel(X_test, X_test, variance, length_scale)\n",
    "\n",
    "        cov_y = K_xx - np.dot(K_x, v)\n",
    "        return mu_y, cov_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zmm5tvlqdcAO",
    "outputId": "fb70e69d-c7e6-4749-f8d2-438a56235411"
   },
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "gp_model = ExactGP()\n",
    "\n",
    "# Setup\n",
    "# guide = numpyro.infer.autoguide.AutoDelta(gp_model.model)\n",
    "optimizer = numpyro.optim.Adam(step_size=0.01)\n",
    "# optimizer = numpyro.optim.Minimize()\n",
    "# optimizer = optax.adamw(learning_rate=0.1)\n",
    "svi = SVI(gp_model.model, gp_model.guide, optimizer, loss=Trace_ELBO())\n",
    "svi_results = svi.run(random.PRNGKey(1), 1_000, X, Y.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6SdAFgRdiYB"
   },
   "source": [
    "##### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "XJ2t2tccdjXF",
    "outputId": "930ca814-7075-4da3-822c-65518e894341"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(svi_results.losses)\n",
    "ax.set(title=\"Loss\", xlabel=\"Iterations\", ylabel=\"Negative ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfYI51TrdkTo"
   },
   "source": [
    "##### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0liv6SNdjfN",
    "outputId": "f08ee1d7-d971-4bdc-ce5a-e2062bdef9b2"
   },
   "outputs": [],
   "source": [
    "params = svi_results.params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uG6Hy6QhfRcu"
   },
   "outputs": [],
   "source": [
    "final_params.add_row(\n",
    "    [\"MLE\", params[\"kernel_var\"], params[\"kernel_length\"], params[\"sigma\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nrGj19dmZX"
   },
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcKZN0X8dgNE"
   },
   "outputs": [],
   "source": [
    "y_pred, y_cov = predict(\n",
    "    X,\n",
    "    Y.squeeze(),\n",
    "    Xtest,\n",
    "    variance=median[\"variance\"],\n",
    "    length_scale=median[\"length_scale\"],\n",
    "    noise=median[\"noise\"],\n",
    ")\n",
    "\n",
    "y_var = np.diagonal(y_cov)\n",
    "y_std = np.sqrt(y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "dxTBowFEeEEz",
    "outputId": "abd923e0-aa69-4b33-c935-7e88cda0c60b"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "ax.scatter(X, Y, label=\"Training Data\", color=\"red\")\n",
    "ax.plot(Xtest, y_pred, label=\"Predictive Mean\", color=\"black\", linewidth=3)\n",
    "ax.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    y_pred - y_std,\n",
    "    y_pred + y_std,\n",
    "    label=\"Confidence Interval\",\n",
    "    alpha=0.3,\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3MtYHcXeSLG"
   },
   "source": [
    "#### Compare Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H65oKVDmettN",
    "outputId": "c7ad7110-7553-454a-e7d5-874bee775d18"
   },
   "outputs": [],
   "source": [
    "print(final_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOCa9M3A7bt0dgaeEvVGSEc",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "numpyro_gpr_delta.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
