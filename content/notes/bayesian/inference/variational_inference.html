
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Variational Inference &#8212; Research Notebook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Confidence Intervals" href="../confidence_intervals.html" />
    <link rel="prev" title="Inference Schemes" href="../inference.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/book_v2.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Notebook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../resources/python/overview.html">
   Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../resources/python/ides.html">
     Integraded Development Environment (IDE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../resources/python/stack.html">
     Standard Python Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../resources/python/earthsci_stack.html">
     Earth Science Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../resources/python/dl_stack.html">
     Deep Learning Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../resources/python/scale_stack.html">
     Scaling Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../resources/python/good_code.html">
     Good Code
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../tutorials/jax_journey/overview.html">
   My JAX Journey
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/jax_journey/ecosystem.html">
     Ecosystem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/jax_journey/vmap.html">
     vmap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/jax_journey/jit.html">
     Jit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/jax_journey/classes.html">
     Classes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../tutorials/jax_journey/algorithms/overview.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../tutorials/jax_journey/algorithms/bisection.html">
       Bisection search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../tutorials/jax_journey/algorithms/kernel_derivatives.html">
       Kernel Derivatives
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../tutorials/jax_journey/gfs_with_jax.html">
       Gaussianization Flows
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../tutorials/remote/overview.html">
   Remote Computing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/remote/ssh.html">
     SSH Configuration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/remote/conda.html">
     Conda 4 Remote Servers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/remote/jlab.html">
     Jupyter Lab 4 Remote Servers
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../concepts/uncertainty.html">
   Modeling Uncertainty
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../overview.html">
   Bayesian
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro.html">
     Language of Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inference.html">
     Inference Schemes
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Variational Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../confidence_intervals.html">
     Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression.html">
     Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../concepts/overview.html">
   Sleeper Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../concepts/gaussian.html">
     Gaussian Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../concepts/change_of_variables.html">
     Change of Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../concepts/identity_trick.html">
     Identity Trick
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../concepts/inverse_function.html">
     Inverse Function Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../concepts/jensens.html">
     Jensens Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../concepts/lin_alg.html">
     Linear Algebra Tricks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../kernels/overview.html">
   Kernel Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../kernels/kernel_derivatives.html">
     Kernel Derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../kernels/rv.html">
     RV Coefficient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../kernels/congruence_coeff.html">
     Congruence Coefficient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../kernels/hsic.html">
     HSIC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../kernels/mmd.html">
     Maximum Mean Discrepancy (MMD)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../gps/intro.html">
   Gaussian Processes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gps/gps.html">
     Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gps/literature.html">
     Literature Review
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gps/cg.html">
     Conjugate Gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gps/sgps.html">
     Sparse Gaussian Processes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../gps/algorithms.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../gps/gpr_code.html">
       GP from Scratch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../gps/sgp_code.html">
       Sparse GP From Scratch
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../egps/overview.html">
     Input Uncertainty in GPs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../info_theory/similarity.html">
   Similarity
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../info_theory/overview.html">
   Information Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../info_theory/measures.html">
     Measures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../info_theory/information.html">
       Information Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../info_theory/entropy.html">
       Entropy &amp; Relative Entropy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../info_theory/mutual_info.html">
       Mutual Information and Total Correlation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../info_theory/estimators.html">
     Information Theory Measures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../info_theory/classic.html">
       Classic Methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../info_theory/histogram.html">
       Entropy Estimator - Histogram
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../info_theory/experiments/rbig_sample_consistency.html">
       Experiment - RBIG Sample Consistency
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../normalizing_flows/overview.html">
   Normalizing Flows
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../normalizing_flows/linear.html">
     Linear Layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../normalizing_flows/coupling_layers.html">
     Coupling Layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../normalizing_flows/conditional.html">
     Conditional Normalizing Flows
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../normalizing_flows/lecture_1_ig.html">
     Lecture I - Iterative Gaussianization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../normalizing_flows/1.0_univariate_gauss.html">
       1.1 - Univariate Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../normalizing_flows/1.1_marginal_gauss.html">
       1.2 - Marginal Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../normalizing_flows/1.2_gaussianization.html">
       1.2 - Iterative Gaussianization
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../normalizing_flows/lecture_2_gf.html">
     Lecture II - Gaussianization Flows
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../normalizing_flows/lecture_3_gfs_pt1_mg.html">
       Parameterized Marginal Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../normalizing_flows/lecture_3_gfs_pt2_rot.html">
       Parameterized Rotations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../normalizing_flows/lecture_3_gfs_pt3_plane.html">
       Example - 2D Plane
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../inr/overview.html">
   Implicit Neural Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../inr/formulation.html">
     Formulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../inr/literature_review.html">
     Literature Review
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_assimilation/overview.html">
   Data Assimilation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_assimilation/dynamical_sys.html">
     Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_assimilation/oi.html">
     Optimal Interpolation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_assimilation/interp.html">
     Interpolation Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_assimilation/emu.html">
     Emulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_assimilation/inv_problems.html">
     Inverse Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_assimilation/projects.html">
     Projects
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../data_assimilation/algorithms.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/markov_models.html">
       Markov Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/gauss_markov.html">
       Gauss-Markov Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/kf.html">
       Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/nkf.html">
       Normalizing Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/enskf.html">
       Ensemble Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/dmm.html">
       Deep Markov Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/4dvarnet.html">
       4DVarNet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data_assimilation/markov_gp.html">
       Markovian Gaussian Processes
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../misc/overview.html">
   Miscellaneous Notes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../misc/generative_models.html">
     Generative Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../misc/diffusion_models.html">
     Diffusion Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../misc/fixed_point.html">
     Fixed-Point Methods
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jejjohnson/research_notebook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/bayesian/inference/variational_inference.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../../_sources/content/notes/bayesian/inference/variational_inference.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivations">
   Motivations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#elbo-derivation">
   ELBO - Derivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comments-on-q-x">
     Comments on
     <span class="math notranslate nohighlight">
      \(q(x)\)
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons">
   Pros and Cons
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-variational-inference">
     Why Variational Inference?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-not-variational-inference">
     Why Not Variational Inference?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#from-scratch">
     From Scratch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Variational Inference
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Variational Inference</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivations">
   Motivations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#elbo-derivation">
   ELBO - Derivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comments-on-q-x">
     Comments on
     <span class="math notranslate nohighlight">
      \(q(x)\)
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons">
   Pros and Cons
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-variational-inference">
     Why Variational Inference?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-not-variational-inference">
     Why Not Variational Inference?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#from-scratch">
     From Scratch
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Variational Inference
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="variational-inference">
<h1>Variational Inference<a class="headerlink" href="#variational-inference" title="Permalink to this headline">#</a></h1>
<hr class="docutils" />
<section id="motivations">
<h2>Motivations<a class="headerlink" href="#motivations" title="Permalink to this headline">#</a></h2>
<p>Variational inference is the most scalable inference method the machine learning community has (as of 2019).</p>
<p><strong>Tutorials</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.ritchievink.com/blog/2019/06/10/bayesian-inference-how-we-are-able-to-chase-the-posterior/">https://www.ritchievink.com/blog/2019/06/10/bayesian-inference-how-we-are-able-to-chase-the-posterior/</a></p></li>
<li><p><a class="reference external" href="https://www.ritchievink.com/blog/2019/09/16/variational-inference-from-scratch/">https://www.ritchievink.com/blog/2019/09/16/variational-inference-from-scratch/</a></p></li>
<li></li>
<li><ul>
<li></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="elbo-derivation">
<h2>ELBO - Derivation<a class="headerlink" href="#elbo-derivation" title="Permalink to this headline">#</a></h2>
<p>Let’s start with the marginal likelihood function.</p>
<div class="math notranslate nohighlight">
\[\mathcal{P}(y| \theta)=\int_\mathcal{X} \mathcal{P}(y|\mathbf x, \theta) \cdot \mathcal{P}(\mathbf x) \cdot d\mathbf{x}\]</div>
<p>where we have effectively marginalized out the <span class="math notranslate nohighlight">\(f\)</span>’s. We already know that it’s difficult to propagate the <span class="math notranslate nohighlight">\(\mathbf x\)</span>’s through the nonlinear functions <span class="math notranslate nohighlight">\(\mathbf K^{-1}\)</span> and <span class="math notranslate nohighlight">\(|\)</span>det <span class="math notranslate nohighlight">\(\mathbf K|\)</span> (see previous doc for examples). So using the VI strategy, we introduce a new variational distribution <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span> to approximate the posterior distribution <span class="math notranslate nohighlight">\(\mathcal{P}(\mathbf x| y)\)</span>. The distribution is normally chosen to be Gaussian:</p>
<div class="math notranslate nohighlight">
\[q(\mathbf x) = \prod_{i=1}^{N}\mathcal{N}(\mathbf x|\mathbf \mu_z, \mathbf \Sigma_z)\]</div>
<p>So at this point, we aree interested in trying to find a way to measure the difference between the approximate distribution <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span> and the true posterior distribution <span class="math notranslate nohighlight">\(\mathcal{P} (\mathbf x)\)</span>. Using some algebra, let’s take the log of the marginal likelihood (evidence):</p>
<div class="math notranslate nohighlight">
\[\log \mathcal{P}(y|\theta) = \log \int_\mathcal{X} \mathcal{P}(y|\mathbf x, \theta) \cdot \mathcal{P}(\mathbf x) \cdot d\mathbf x\]</div>
<p>So now we are going to use the some tricks that you see within almost every derivation of the VI framework. The first one consists of using the Identity trick. This allows us to change the expectation to incorporate the new variational distribution <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span>. We get the following equation:</p>
<div class="math notranslate nohighlight">
\[\log \mathcal{P}(y|\theta) = \log \int_\mathcal{X} \mathcal{P}(y|\mathbf x, \theta) \cdot \mathcal{P}(\mathbf x) \cdot \frac{q(\mathbf x)}{q(\mathbf x)} \cdot d\mathbf x\]</div>
<p>Now that we have introduced our new variational distribution, we can regroup and reweight our expectation. Because I know what I want, I get the following:</p>
<div class="math notranslate nohighlight">
\[\log \mathcal{P}(y|\theta) = \log \int_\mathcal{X} \mathcal{P}(y|\mathbf x, \theta) \cdot  q(\mathbf x) \cdot \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)} \cdot d\mathbf x\]</div>
<p>Now with Jensen’s inequality, we have the relationship <span class="math notranslate nohighlight">\(f(\mathbb{E}[x]) \leq \mathbb{E} [f(x)]\)</span>. We would like to put the <span class="math notranslate nohighlight">\(\log\)</span> function inside of the integral. Jensen’s inequality allows us to do this. If we let <span class="math notranslate nohighlight">\(f(\cdot)= \log(\cdot)\)</span> then we get the Jensen’s equality for a concave function, <span class="math notranslate nohighlight">\(f(\mathbb{E}[x]) \geq \mathbb{E} [f(x)]\)</span>. In this case if we match the terms to each component to the inequality, we have</p>
<div class="math notranslate nohighlight">
\[\log \cdot \mathbb{E}_\mathcal{q(\mathbf x)} \left[ \mathcal{P}(y|\mathbf x, \theta) \cdot  \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)} \right] 
\geq  
\mathbb{E}_\mathcal{q(\mathbf x)} \left[\log  \mathcal{P}(y|\mathbf x, \theta) \cdot \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)} \right]\]</div>
<p>So now finally we have both terms in the inequality. Summarizing everything we have the following relationship:</p>
<div class="math notranslate nohighlight">
\[log \mathcal{P}(y|\theta) = \log \int_\mathcal{X} \mathcal{P}(y|\mathbf x, \theta) \cdot  q(\mathbf x) \cdot \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)} \cdot d\mathbf x \]</div>
<div class="math notranslate nohighlight">
\[
\log \mathcal{P}(y|\theta) \geq  \int_\mathcal{X} \left[\log  \mathcal{P}(y|\mathbf x, \theta) \cdot \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)} \right] q(\mathbf x) \cdot d\mathbf x
\]</div>
<p>I’m going to switch up the terminology just to make it easier aesthetically. I’m going to let <span class="math notranslate nohighlight">\(\mathcal{L}(\theta)\)</span> be <span class="math notranslate nohighlight">\(\log \mathcal{P}(y|\theta)\)</span> and <span class="math notranslate nohighlight">\(\mathcal{F}(q, \theta) \leq \mathcal{L}(\theta)\)</span>. So basically:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\theta) =\log \mathcal{P}(y|\theta) \geq  \int_\mathcal{X} \left[\log  \mathcal{P}(y|\mathbf x, \theta) \cdot \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)} \right] q(\mathbf x) \cdot d\mathbf x = \mathcal{F}(q, \theta)
\]</div>
<p>With this simple change I can talk about each of the parts individually. Now using log rules we can break apart the likelihood and the quotient. The quotient will be needed for the KL divergence.</p>
<div class="math notranslate nohighlight">
\[
\mathcal{F}(q) =
\underbrace{\int_\mathcal{X} q(\mathbf x) \cdot \log  \mathcal{P}(y|\mathbf x, \theta) \cdot d\mathbf x}_{\mathbb{E}_{q(\mathbf{x})}} +
\underbrace{\int_\mathcal{X} q(\mathbf x) \log  \frac{\mathcal{P}(\mathbf x)}{q(\mathbf x)}   \cdot d\mathbf x}_{\text{KL}}
\]</div>
<p>The punchline of this (after many calculated manipulations), is that we obtain an optimization equation <span class="math notranslate nohighlight">\(\mathcal{F}(\theta)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}(q)=\mathbb{E}_{q(\mathbf x)}\left[ \log \mathcal{P}(y|\mathbf x, \theta) \right] - \text{D}_\text{KL}\left[ q(\mathbf x) || \mathcal{P}(\mathbf x) \right]\]</div>
<p>where:</p>
<ul class="simple">
<li><p>Approximate posterior distribution: <span class="math notranslate nohighlight">\(q(x)\)</span></p>
<ul>
<li><p>The best match to the true posterior <span class="math notranslate nohighlight">\(\mathcal{P}(y|\mathbf x, \theta)\)</span>. This is what we want to calculate.</p></li>
</ul>
</li>
<li><p>Reconstruction Cost: <span class="math notranslate nohighlight">\(\mathbb{E}_{q(\mathbf x)}\left[ \log \mathcal{P}(y|\mathbf x, \theta) \right]\)</span></p>
<ul>
<li><p>The expected log-likelihood measure of how well the samples from <span class="math notranslate nohighlight">\(q(x)\)</span> are able to explain the data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
</li>
<li><p>Penalty: <span class="math notranslate nohighlight">\(\text{D}_\text{KL}\left[ q(\mathbf x) || \mathcal{P}(\mathbf x) \right]\)</span></p>
<ul>
<li><p>Ensures that the explanation of the data <span class="math notranslate nohighlight">\(q(x)\)</span> doesn’t deviate too far from your beliefs <span class="math notranslate nohighlight">\(\mathcal{P}(x)\)</span>. (Okham’s razor constraint)</p></li>
</ul>
</li>
</ul>
<p><strong>Source</strong>: <a class="reference external" href="https://www.shakirm.com/papers/VITutorial.pdf">VI Tutorial</a> - Shakir Mohamed</p>
<p>If we optimize <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> with respect to <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span>, the KL is minimized and we just get the likelihood. As we’ve seen before, the likelihood term is still problematic as it still has the nonlinear portion to propagate the <span class="math notranslate nohighlight">\(\mathbf x\)</span>’s through. So that’s nothing new and we’ve done nothing useful. If we introduce some special structure in <span class="math notranslate nohighlight">\(q(f)\)</span> by introducing sparsity, then we can achieve something useful with this formulation.
But through augmentation of the variable space with <span class="math notranslate nohighlight">\(\mathbf u\)</span> and <span class="math notranslate nohighlight">\(\mathbf Z\)</span> we can bypass this problem. The second term is simple to calculate because they’re both chosen to be Gaussian.</p>
<section id="comments-on-q-x">
<h3>Comments on <span class="math notranslate nohighlight">\(q(x)\)</span><a class="headerlink" href="#comments-on-q-x" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>We have now transformed our problem from an integration problem to an optimization problem where we optimize for <span class="math notranslate nohighlight">\(q(x)\)</span> directly.</p></li>
<li><p>Many people tend to simplify <span class="math notranslate nohighlight">\(q\)</span> but we could easily write some dependencies on the data for example <span class="math notranslate nohighlight">\(q(x|\mathcal{D})\)</span>.</p></li>
<li><p>We can easily see the convergence as we just have to wait until the loss (free energy) reaches convergence.</p></li>
<li><p>Typically <span class="math notranslate nohighlight">\(q(x)\)</span> is a Gaussian whereby the variational parameters are the mean and the variance. Practically speaking, we could freeze or unfreeze any of these parameters if we have some prior knowledge about our problem.</p></li>
<li><p>Many people say ‘tighten the bound’ but they really just mean optimization: modifying the hyperparameters so that we get as close as possible to the true marginal likelihood.</p></li>
</ul>
</section>
</section>
<section id="pros-and-cons">
<h2>Pros and Cons<a class="headerlink" href="#pros-and-cons" title="Permalink to this headline">#</a></h2>
<section id="why-variational-inference">
<h3>Why Variational Inference?<a class="headerlink" href="#why-variational-inference" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Applicable to all probabilistic models</p></li>
<li><p>Transforms a problem from integration to one of optimization</p></li>
<li><p>Convergence assessment</p></li>
<li><p>Principled and Scalable approach to model selection</p></li>
<li><p>Compact representation of posterior distribution</p></li>
<li><p>Faster to converge</p></li>
<li><p>Numerically stable</p></li>
<li><p>Modern Computing Architectures (GPUs)</p></li>
</ul>
</section>
<section id="why-not-variational-inference">
<h3>Why Not Variational Inference?<a class="headerlink" href="#why-not-variational-inference" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Approximate posterior only</p></li>
<li><p>Difficulty in optimization due to local minima</p></li>
<li><p>Under-estimates the variance of posterior</p></li>
<li><p>Limited theory and guarantees for variational mehtods</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Tutorial Series - <a class="reference external" href="https://chrisorm.github.io/VI-Why.html">Why?</a> | <a class="reference external" href="https://chrisorm.github.io/VI-ELBO.html">ELBO</a> | <a class="reference external" href="https://chrisorm.github.io/VI-MC.html">MC ELBO</a> | <a class="reference external" href="https://chrisorm.github.io/VI-reparam.html">Reparameterization</a> | <a class="reference external" href="https://chrisorm.github.io/VI-ELBO-MC-approx.html">MC ELBO unBias</a> | <a class="reference external" href="https://chrisorm.github.io/VI-MC-PYT.html">MC ELBO PyTorch</a> | <a class="reference external" href="https://chrisorm.github.io/pydata-2018.html">Talk</a></p></li>
<li><p>Blog Posts: Neural Variational Inference</p>
<ul>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2016-07-01-neural-variational-inference-classical-theory.html">Classical Theory</a></p></li>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2016-07-04-neural-variational-inference-stochastic-variational-inference.html">Scaling Up</a></p></li>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2016-07-05-neural-variational-inference-blackbox.html">BlackBox Mode</a></p></li>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2016-07-11-neural-variational-inference-variational-autoencoders-and-Helmholtz-machines.html">VAEs and Helmholtz Machines</a></p></li>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2016-07-14-neural-variational-importance-weighted-autoencoders.html">Importance Weighted AEs</a></p></li>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2019-04-26-neural-samplers-and-hierarchical-variational-inference.html">Neural Samplers and Hierarchical VI</a></p></li>
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2019-05-10-importance-weighted-hierarchical-variational-inference.html">Importance Weighted Hierarchical VI</a> | <a class="reference external" href="https://www.youtube.com/watch?v=pdSu7XfGhHw&amp;feature=youtu.be">Video</a></p></li>
</ul>
</li>
<li><p>Normal Approximation to the Posterior Distribution - <a class="reference external" href="http://bjlkeng.github.io/posts/normal-approximations-to-the-posterior-distribution/">blog</a></p></li>
</ul>
<p><strong>Lower Bound</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="http://legacydirs.umiacs.umd.edu/~xyang35/files/understanding-variational-lower.pdf">Understaing the Variational Lower Bound</a></p></li>
<li><p><a class="reference external" href="http://paulrubenstein.co.uk/deriving-the-variational-lower-bound/">Deriving the Variational Lower Bound</a></p></li>
</ul>
<p><strong>Summaries</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1711.05597.pdf">Advances in Variational Inference</a></p></li>
</ul>
<p><strong>Presentations</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.shakirm.com/papers/VITutorial.pdf">VI Shakir</a></p></li>
<li><p>Deisenroth - <a class="reference external" href="https://drive.google.com/file/d/1sAIF0rqgNbVbp7ZbuiS7kh96Yns04k1i/view">VI</a> | <a class="reference external" href="https://drive.google.com/open?id=14WOcbwn011rJbFFsSbeoeuSxY4sMG4KY">IT</a></p></li>
<li><p><a class="reference external" href="https://www.doc.ic.ac.uk/~mpd37/teaching/ml_tutorials/2017-11-22-Ek-BNP-and-priors-over-functions.pdf">Bayesian Non-Parametrics and Priors over functions</a></p></li>
<li><p><a class="reference external" href="https://filebox.ece.vt.edu/~s14ece6504/slides/Moran_I_ECE_6504_VB.pdf">here</a></p></li>
</ul>
<p><strong>Reviews</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="http://krasserm.github.io/2018/04/03/variational-inference/">From EM to SVI</a></p></li>
<li><p><a class="reference external" href="https://ermongroup.github.io/cs228-notes/inference/variational/">Variational Inference</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1601.00670.pdf">VI- Review for Statisticians</a></p></li>
<li><p><a class="reference external" href="http://www.robots.ox.ac.uk/~sjrob/Pubs/vbTutorialFinal.pdf">Tutorial on VI</a></p></li>
<li><p><a class="reference external" href="https://zhiyzuo.github.io/VI/">VI w/ Code</a></p></li>
<li><p><a class="reference external" href="https://blog.evjang.com/2016/08/variational-bayes.html">VI - Mean Field</a></p></li>
<li><p><a class="reference external" href="https://github.com/philschulz/VITutorial">VI Tutorial</a></p></li>
<li><p>GMM</p>
<ul>
<li><p><a class="reference external" href="https://github.com/bertini36/GMM">VI in GMM</a></p></li>
<li><p><a class="reference external" href="https://mattdickenson.com/2018/11/18/gmm-python-pyro/">GMM Pyro</a> | <a class="reference external" href="http://pyro.ai/examples/gmm.html">Pyro</a></p></li>
<li><p><a class="reference external" href="https://github.com/ldeecke/gmm-torch">GMM PyTorch</a> | <a class="reference external" href="https://angusturner.github.io/generative_models/2017/11/03/pytorch-gaussian-mixture-model.html">PyTorch</a> | <a class="reference external" href="https://github.com/RomainSabathe/dagmm/blob/master/gmm.py">PyTorchy</a></p></li>
</ul>
</li>
</ul>
<p><strong>Code</strong></p>
<p><strong>Extensions</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="http://artem.sobolev.name/posts/2019-04-26-neural-samplers-and-hierarchical-variational-inference.html">Neural Samplers and Hierarchical Variational Inference</a></p></li>
</ul>
<section id="from-scratch">
<h3>From Scratch<a class="headerlink" href="#from-scratch" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Programming a Neural Network from Scratch - Ritchie Vink (2017) - <a class="reference external" href="https://www.ritchievink.com/blog/2017/07/10/programming-a-neural-network-from-scratch/">blog</a></p></li>
<li><p>An Introduction to Probability and Computational Bayesian Statistcs - Eric Ma 0<a class="reference external" href="https://ericmjl.github.io/essays-on-data-science/machine-learning/computational-bayesian-stats/">Blog</a></p></li>
<li><p>Variational Inference from Scratch - Ritchie Vink (2019) - <a class="reference external" href="https://www.ritchievink.com/blog/2019/09/16/variational-inference-from-scratch/">blog</a></p></li>
<li><p>Bayesian inference; How we are able to chase the Posterior - Ritchie Vink (2019) - [blog](Bayesian inference; How we are able to chase the Posterior)</p></li>
<li><p>Algorithm Breakdown: Expectation Maximization - <a class="reference external" href="https://www.ritchievink.com/blog/2019/05/24/algorithm-breakdown-expectation-maximization/">blog</a></p></li>
</ul>
</section>
</section>
<section id="id1">
<h2>Variational Inference<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Variational Bayes and The Mean-Field Approximation - Keng (2017) - <a class="reference external" href="http://bjlkeng.github.io/posts/variational-bayes-and-the-mean-field-approximation/">blog</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/notes/bayesian/inference"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../inference.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Inference Schemes</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../confidence_intervals.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Confidence Intervals</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By J. Emmanuel Johnson<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>