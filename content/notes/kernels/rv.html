

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>RV Coefficient &#8212; Research Notebook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/notes/kernels/rv';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Congruence Coefficient" href="congruence_coeff.html" />
    <link rel="prev" title="Kernel Derivatives" href="kernel_derivatives.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/book_v2.jpeg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../resources/python/overview.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/ides.html">Integraded Development Environment (IDE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/stack.html">Standard Python Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/earthsci_stack.html">Earth Science Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/dl_stack.html">Deep Learning Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/scale_stack.html">Scaling Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/good_code.html">Good Code</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/jax_journey/overview.html">My JAX Journey</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">Ecosystem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/vmap.html">vmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/jit.html">Jit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/classes.html">Classes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">Bisection search</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/gfs_with_jax.html">Gaussianization Flows</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/twelve_steps_ns/overview.html">12 Steps to Navier-Stokes</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/twelve_steps_ns/1.1_linear_advection.html">Linear Convection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/remote/overview.html">Remote Computing</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/ssh.html">SSH Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/conda.html">Conda 4 Remote Servers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/jlab.html">Jupyter Lab 4 Remote Servers</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../gmt/overview.html">GMT of Learning</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gmt/hierarchical_rep.html">Hierarchical Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/functa.html">Functa</a></li>








<li class="toctree-l2"><a class="reference internal" href="../gmt/discretize_space.html">Spatial Discretization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/discretize_time.html">Temporal Discretization</a></li>


<li class="toctree-l2"><a class="reference internal" href="../gmt/learning.html">Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../concepts/uncertainty.html">Modeling Uncertainty</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bayesian/overview.html">Bayesian</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/intro.html">Language of Uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/models.html">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference.html">Inference Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/variational_inference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/cond_vi.html">Conditional Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/confidence_intervals.html">Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/regression.html">Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../concepts/overview.html">Sleeper Concepts</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../concepts/gaussian.html">Gaussian Distributions</a></li>

<li class="toctree-l2"><a class="reference internal" href="../concepts/change_of_variables.html">Change of Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/identity_trick.html">Identity Trick</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/inverse_function.html">Inverse Function Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/jensens.html">Jensens Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/lin_alg.html">Linear Algebra Tricks</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="overview.html">Kernel Methods</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">RV Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="congruence_coeff.html">Congruence Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="hsic.html">HSIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="mmd.html">Maximum Mean Discrepancy (MMD)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gps/intro.html">Gaussian Processes</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gps/gps.html">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/literature.html">Literature Review</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/cg.html">Conjugate Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/sgps.html">Sparse Gaussian Processes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../gps/algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../gps/gpr_code.html">GP from Scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gps/sgp_code.html">Sparse GP From Scratch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../egps/overview.html">Input Uncertainty in GPs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../info_theory/similarity.html">Similarity</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../info_theory/overview.html">Information Theory</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/measures.html">Measures</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/information.html">Information Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/entropy.html">Entropy &amp; Relative Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/mutual_info.html">Mutual Information and Total Correlation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/estimators.html">Information Theory Measures</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/classic.html">Classic Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/histogram.html">Entropy Estimator - Histogram</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">Experiment - RBIG Sample Consistency</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../normalizing_flows/overview.html">Normalizing Flows</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/linear.html">Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/coupling_layers.html">Coupling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/conditional.html">Conditional Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/multiscale.html">Multiscale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/inverse.html">Minimization Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/losses.html">Losses</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_1_ig.html">Lecture I - Iterative Gaussianization</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.0_univariate_gauss.html">1.1 - Univariate Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.1_marginal_gauss.html">1.2 - Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.2_gaussianization.html">1.2 - Iterative Gaussianization</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_2_gf.html">Lecture II - Gaussianization Flows</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt1_mg.html">Parameterized Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt2_rot.html">Parameterized Rotations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt3_plane.html">Example - 2D Plane</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nerfs/overview.html">Neural Fields</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nerfs/formulation.html">Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nerfs/literature_review.html">Literature Review</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../nerfs/pinns.html">Physics-Informed Loss</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_assimilation/overview.html">Data Assimilation</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/dynamical_sys.html">Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/oi.html">Optimal Interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/interp.html">Interpolation Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/emu.html">Emulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/inv_problems.html">Inverse Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/projects.html">Projects</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../data_assimilation/algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/markov_models.html">Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/gauss_markov.html">Gauss-Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/kf.html">Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/nkf.html">Normalizing Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/enskf.html">Ensemble Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/dmm.html">Deep Markov Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/4dvarnet.html">4DVarNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/markov_gp.html">Markovian Gaussian Processes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../data_assimilation/nbs/notebooks.html">Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../misc/overview.html">Miscellaneous Notes</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../misc/generative_models.html">Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diffusion_models.html">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/fixed_point.html">Fixed-Point Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/bilevel_opt.html">Bi-Level Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diff_operators.html">Differential Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/qg.html">QG Formulations</a></li>


<li class="toctree-l2"><a class="reference internal" href="../misc/elliptical_pde_solver.html">Elliptical PDE Solvers</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cheat Sheets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/bash.html">Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/cli.html">Command Line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/python.html">Python</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/jejjohnson/research_notebook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/kernels/rv.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/notes/kernels/rv.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>RV Coefficient</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#single-variables">Single Variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-and-variance">Mean and Variance</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#empirical-estimate">Empirical Estimate</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance">Covariance</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Empirical Estimate</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation">Correlation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Empirical Estimate</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-error">Root Mean Squared Error</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-dimensional">Multi-Dimensional</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-per-dimension">Correlation per Dimension</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-covariance">Self-Covariance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#empirical-estimation">Empirical Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-covariance">Cross-Covariance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Empirical Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-vector-difference">Root Mean Squared Vector Difference</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summarizing-multi-dimensional-information">Summarizing Multi-Dimensional Information</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#congruence-coefficient">Congruence Coefficient</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">rV Coefficient</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Empirical Estimation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#equivalence">Equivalence</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extensions">Extensions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-information">Mutual Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supplementary">Supplementary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#equivalences">Equivalences</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="rv-coefficient">
<h1>RV Coefficient<a class="headerlink" href="#rv-coefficient" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Lab: <a class="reference external" href="https://colab.research.google.com/drive/19bJd_KNTSThZcxP1vnQOVjTLTOFLS9VG">Colab Notebook</a></p></li>
</ul>
<hr class="docutils" />
<hr class="docutils" />
<section id="single-variables">
<h2>Single Variables<a class="headerlink" href="#single-variables" title="Permalink to this heading">#</a></h2>
<p>Let’s consider a single variable <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{N \times 1}\)</span> which represents a set of samples of a single feature.</p>
<section id="mean-and-variance">
<h3>Mean and Variance<a class="headerlink" href="#mean-and-variance" title="Permalink to this heading">#</a></h3>
<p>The first order measurement is the mean. This is the expected/average value that we would expect from a r.v.. This results in a scalar value.</p>
<div class="math notranslate nohighlight">
\[
\mu(x)=\frac{1}{N}\sum_{i=1}x_i
\]</div>
<p>The second measure we need to consider is the variance. This is a measure of spread.</p>
<section id="empirical-estimate">
<h4>Empirical Estimate<a class="headerlink" href="#empirical-estimate" title="Permalink to this heading">#</a></h4>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\sigma_x^2
&amp;= \frac{1}{n-1} \sum_{i=1}^N(x_i-x_\mu)^2
\end{aligned}
\]</div>
<p>We can expand the terms in the parenthesis like normally. Then we take the expectation of each of the terms individually.</p>
<details>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># remove mean from data</span>
<span class="n">X_mu</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># ensure it is 1D</span>
<span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mu</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mu</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>

</pre></div>
</div>
</details>
</section>
</section>
<hr class="docutils" />
<section id="covariance">
<h3>Covariance<a class="headerlink" href="#covariance" title="Permalink to this heading">#</a></h3>
<p>The first measure we need to consider is the covariance. This can be used for a single variable <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{N \times 1}\)</span> which represents a set of samples of a single feature. We can compare the r.v. <span class="math notranslate nohighlight">\(X\)</span> with another r.v. <span class="math notranslate nohighlight">\(Y \in \mathbb{R}^{N \times 1}\)</span>. the covariance, or the cross-covariance between multiple variables <span class="math notranslate nohighlight">\(X,Y\)</span>. This results in a scalar value , <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. We can write this as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\text{cov}(\mathbf{x,y})
&amp;= \mathbb{E}\left[(\mathbf{x}-\mu_\mathbf{x})(\mathbf{y}-\mu_\mathbf{y}) \right] \\
&amp;= \mathbb{E}[\mathbf{xy}] - \mu_\mathbf{x}\mu_\mathbf{y}
\end{aligned}\end{split}\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<p>We can expand the terms in the parenthesis like normally. Then we take the expectation of each of the terms individually.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{cov}(\mathbf{x,y})
&amp;= \mathbb{E}\left((\mathbf{x}-\mu_\mathbf{x})(\mathbf{y}-\mu_\mathbf{y}) \right) \\
&amp;= \mathbb{E}\left[\mathbf{xy} - \mu_\mathbf{x} Y - \mathbf{x}\mu_\mathbf{y} + \mu_\mathbf{x}\mu_y \right] \\
&amp;= \mathbb{E}[\mathbf{xy}] - \mu_\mathbf{x} \mathbb{E}[\mathbf{x}] - \mu_y\mathbb{E}[\mathbf{y}] + \mu_\mathbf{x}\mu_y \\
&amp;= \mathbb{E}[\mathbf{xy}] - \mu_\mathbf{x}\mu_y \\
\end{aligned}
\end{split}\]</div>
</div>
<p>This will result in a scalar value <span class="math notranslate nohighlight">\(\mathbb{R}^+\)</span> that ranges from <span class="math notranslate nohighlight">\((-\infty, \infty)\)</span>. This number is affected by scale so we can different values depending upon the scale of our data, i.e.  where <span class="math notranslate nohighlight">\(\alpha, \beta \in \mathbb{R}^{+}\)</span></p>
<div class="math notranslate nohighlight">
\[
\text{cov}(\mathbf{x,y}) \neq \text{cov}(\alpha \mathbf{x}, \beta \mathbf{x})
\]</div>
<section id="id1">
<h4>Empirical Estimate<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<p>We can compare the r.v. <span class="math notranslate nohighlight">\(X\)</span> with another r.v. <span class="math notranslate nohighlight">\(Y \in \mathbb{R}^{N \times 1}\)</span>. the covariance, or the cross-covariance between multiple variables <span class="math notranslate nohighlight">\(X,Y\)</span>. We can write this as:</p>
<div class="math notranslate nohighlight">
\[\text{cov}(\mathbf{x,y}) = \frac{1}{n-1} \sum_{i=1}^N (x_i - x_\mu)(y_i - y_\mu)\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">c_xy</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Y</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="correlation">
<h3>Correlation<a class="headerlink" href="#correlation" title="Permalink to this heading">#</a></h3>
<p>This is the normalized version of the covariance measured mentioned above. This is done by dividing the covariance by the product of the standard deviation of the two samples X and Y.</p>
<div class="math notranslate nohighlight">
\[
\rho(\mathbf{x,y})=\frac{\text{cov}(\mathbf{x,y}) }{\sigma_x \sigma_y}
\]</div>
<p>This results in a scalar value <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> that lies in between <span class="math notranslate nohighlight">\([-1, 1]\)</span>. When <span class="math notranslate nohighlight">\(\rho=-1\)</span>, there is a negative correlation and when <span class="math notranslate nohighlight">\(\rho=1\)</span>, there is a positive correlation. When <span class="math notranslate nohighlight">\(\rho=0\)</span> there is no correlation.</p>
<section id="id2">
<h4>Empirical Estimate<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h4>
<p>So the formulation is:</p>
<div class="math notranslate nohighlight">
\[
\rho(\mathbf{x,y}) = \frac{\text{cov}(\mathbf{x,y}) }{\sigma_x \sigma_y}
\]</div>
<p>With this normalization, we now have a measure that is bounded between -1 and 1. This makes it much more interpretable and also invariant to isotropic scaling, <span class="math notranslate nohighlight">\(\rho(X,Y)=\rho(\alpha X, \beta Y)\)</span> where <span class="math notranslate nohighlight">\(\alpha, \beta \in \mathbb{R}^{+}\)</span>.</p>
</section>
</section>
<hr class="docutils" />
<section id="root-mean-squared-error">
<h3>Root Mean Squared Error<a class="headerlink" href="#root-mean-squared-error" title="Permalink to this heading">#</a></h3>
<p>This is a popular measure for measuring the errors between two datasets. More or less, it is a covariance measure that penalizes higher deviations between the datasets.</p>
<div class="math notranslate nohighlight">
\[
\text{RMSE}(X,Y)=\sqrt{\frac{1}{N}\sum_{i=1}^N \left((x_i - \mu_x)-(y_i - \mu_i)\right)^2}
\]</div>
</section>
</section>
<hr class="docutils" />
<section id="multi-dimensional">
<h2>Multi-Dimensional<a class="headerlink" href="#multi-dimensional" title="Permalink to this heading">#</a></h2>
<p>For all of these measures, we have been under the assumption that <span class="math notranslate nohighlight">\(\mathbf{x,y} \in \mathbb{R}^{N \times 1}\)</span>. However, we may have the case where we have multivariate datasets in <span class="math notranslate nohighlight">\(\mathbb{R}^{N \times D}\)</span>. In this case, we need methods that can handle multivariate inputs because the Pearson correlation coefficient cannot be applied directly to multivariate methods.</p>
<section id="correlation-per-dimension">
<h3>Correlation per Dimension<a class="headerlink" href="#correlation-per-dimension" title="Permalink to this heading">#</a></h3>
<p>One way to overcome this is to calculate the Pearson Correlation Coefficient <strong>per dimensions</strong>. This results in a score</p>
<div class="math notranslate nohighlight">
\[
\rho_\text{d-sub} = \frac{1}{D}\sum_{d=1}^D \rho(\mathbf{X}^d, \mathbf{Y}^d)^2
\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">p_sub</span> <span class="o">=</span> <span class="p">[</span><span class="n">pearson</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="n">iy</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">)]</span>
<span class="n">p_sub</span> <span class="o">/=</span> <span class="n">n_features</span>
</pre></div>
</div>
<p>This works and it’s a nice an simple way to deal with multi-dimensional datasets. However, it handles every feature independently which is not always what we want. We need a method that enables us to take into account all dimensions together.</p>
</section>
<hr class="docutils" />
<section id="self-covariance">
<h3>Self-Covariance<a class="headerlink" href="#self-covariance" title="Permalink to this heading">#</a></h3>
<p>So now we are considering the case when we have multidimensional vectors. If we think of a variable <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{N \times D}\)</span> which represents a set of samples with multiple features. First let’s consider the variance for a multidimensional variable. This is also known as the covariance because we are actually finding the cross-covariance between itself.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{Var}(X)
&amp;= \mathbb{E}\left[(X-\mu_x)^2 \right] \\
\end{aligned}
\end{split}\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<p>We can expand the terms in the parenthesis like normally. Then we take the expectation of each of the terms individually.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{Var}(X) &amp;= \mathbb{E}\left((X-\mu_x)(X-\mu_y) \right) \\
&amp;= \mathbb{E}\left(XX - \mu_XX - X\mu_X + \mu_X\mu_X \right) \\
&amp;= \mathbb{E}(XX) - \mu_x \mathbb{E}(X) - \mathbb{E}(X)\mu_X + \mu_x\mu_X \\
&amp;= \mathbb{E}(X^2) - \mu_X^2
\end{aligned}
\end{split}\]</div>
</div>
<p>To simplify the notation, we can write this as:</p>
<div class="math notranslate nohighlight">
\[\Sigma_\mathbf{x} = \text{cov}(\mathbf{x,x})\]</div>
<ul class="simple">
<li><p>A completely diagonal linear kernel (Gram) matrix means that all examples are uncorrelated (orthogonal to each other).</p></li>
<li><p>Diagonal kernels are useless for learning: no structure found in the data.</p></li>
</ul>
</section>
<section id="empirical-estimation">
<h3>Empirical Estimation<a class="headerlink" href="#empirical-estimation" title="Permalink to this heading">#</a></h3>
<p>This shows the joint variation of all pairs of random variables.</p>
<div class="math notranslate nohighlight">
\[
\Sigma_\mathbf{x} = \mathbf{x}^\top \mathbf{x}
\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">c_xy</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cross-covariance">
<h3>Cross-Covariance<a class="headerlink" href="#cross-covariance" title="Permalink to this heading">#</a></h3>
<p>We can compare the r.v. <span class="math notranslate nohighlight">\(X\)</span> with another r.v. <span class="math notranslate nohighlight">\(Y \in \mathbb{R}^{N \times 1}\)</span>. the covariance, or the cross-covariance between multiple variables <span class="math notranslate nohighlight">\(X,Y\)</span>. We can write this as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\text{cov}(\mathbf{x,y}) &amp;= \mathbb{E}\left[(\mathbf{x}-\mu_\mathbf{x})(\mathbf{y}-\mu_\mathbf{y}) \right] \\
&amp;= \mathbb{E}[\mathbf{xy}] - \mu_\mathbf{x}\mu_\mathbf{y}
\end{aligned}\end{split}\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<p>We can expand the terms in the parenthesis like normally. Then we take the expectation of each of the terms individually.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
C(X,Y) &amp;= \mathbb{E}\left((X-\mu_x)(Y-\mu_y) \right) \\
&amp;= \mathbb{E}\left(XY - \mu_xY - X\mu_y + \mu_x\mu_y \right) \\
&amp;= \mathbb{E}(XY) - \mu_x \mathbb{E}(X) - \mathbb{E}(X)\mu_y + \mu_x\mu_y \\
&amp;= \mathbb{E}(XY) - \mu_x\mu_y
\end{aligned}
\end{split}\]</div>
</div>
<p>This results in a scalar value which represents the similarity between the samples. There are some key observations of this measure.</p>
</section>
<section id="id3">
<h3>Empirical Estimation<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>This shows the joint variation of all pairs of random variables.</p>
<div class="math notranslate nohighlight">
\[
\Sigma_\mathbf{xy} = \mathbf{x}^\top \mathbf{y}
\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">c_xy</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span>
</pre></div>
</div>
<p><strong>Observations</strong></p>
<ul class="simple">
<li><p>A completely diagonal covariance matrix means that all features are uncorrelated (orthogonal to each other).</p></li>
<li><p>Diagonal covariances are useful for learning, they mean non-redundant features!</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="root-mean-squared-vector-difference">
<h3>Root Mean Squared Vector Difference<a class="headerlink" href="#root-mean-squared-vector-difference" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.geosci-model-dev.net/9/4365/2016/gmd-9-4365-2016.pdf">A diagram for evaluating multiple aspects of model performance insimulating vector fields</a> - Xu et. al. (2016)</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="summarizing-multi-dimensional-information">
<h2>Summarizing Multi-Dimensional Information<a class="headerlink" href="#summarizing-multi-dimensional-information" title="Permalink to this heading">#</a></h2>
<p>Recall that we now have self-covariance matrices <span class="math notranslate nohighlight">\(\Sigma_\mathbf{x}\)</span> and cross-covariance matrices <span class="math notranslate nohighlight">\(\Sigma_\mathbf{xy}\)</span> which are <span class="math notranslate nohighlight">\(\mathbb{R}^{D \times D}\)</span>. This is very useful as it captures the structure of the overall data. However, if we want to summarize the statistics, then we need some methods to do so. The matrix norm, in particular the Frobenius Norm (aka the Hilbert-Schmidt Norm) to effectively summarize content within this covariance matrix. It’s defined as:</p>
<div class="math notranslate nohighlight">
\[||\Sigma_\mathbf{xy}||_{\mathcal{F}}^2 = \sum_i \lambda_i^2 = \text{tr}\left( \Sigma_\mathbf{xy}^\top \Sigma_\mathbf{xy} \right)\]</div>
<p>Essentially this is a measure of the covariance matrix power or “essence” through its eigenvalue decomposition. Note that this term is zero iff <span class="math notranslate nohighlight">\(\mathbf{x,y}\)</span> are independent and greater than zero otherwise. Since the covariance matrix is a second-order measure of the relations, we can only summarize the the second order relation information. But at the very least, we now have a scalar value in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> that summarizes the structure of our data.</p>
<hr class="docutils" />
<section id="congruence-coefficient">
<h3>Congruence Coefficient<a class="headerlink" href="#congruence-coefficient" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>A measure of similarity between two multivariate datasets.</p>
</div></blockquote>
<p>This was a term introduced by Burt (1948) with the name “unadjusted correlation”. It’s a measure of similarity between two multivariate datasets. Later the term “congruence coefficient” was coined by Tucker (1951) and Harman (1976).</p>
<p>In the context of matrices, let’s take summarize the cross-covariance matrix and then normalize this value by the self-covariance matrices. This results in:</p>
<div class="math notranslate nohighlight">
\[\varphi (\mathbf{x,y}) = \frac{\text{Tr}\left( XY^\top\right)}{||XX^\top||_F \; || YY^\top||_F} \]</div>
<p>This results in the Congruence-Coefficient <span class="math notranslate nohighlight">\(\varphi\)</span> which is analogous to the Pearson correlation coefficient <span class="math notranslate nohighlight">\(\rho\)</span> as a measure of similarity but it’s in the sample space not the feature space. We assume that the data is column centered (aka we have removed the mean from the features). HS-norm of the covariance only detects second order relationships. More complex (higher-order, nonlinear) relations still cannot be captured as this is still a linear method.</p>
</section>
<hr class="docutils" />
<section id="id4">
<h3>rV Coefficient<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>A similarity measure between two squared symmetric matrices (positive semi-definite matrices) used to analyize multivariate datasets; the cosine between matrices.</p>
</div></blockquote>
<p>This term was introduced by Escoufier (1973) and Robert &amp; Escoufier (1976).</p>
<!-- Let's add $N$ independent realizations to the samples. This gives us a vector for each of the observations. So, let $\mathbf{X} \in \mathbb{R}^{N \times D_x}$ and $\mathbf{Y} \in \mathbb{R}^{N \times D_y}$. We assume that they are column-centered (aka remove the mean from the features). So, we can write the $S_{\mathbf{XY}}= \frac{1}{n-1}\mathbf{X^\top Y}$

$$\begin{aligned}
\rho\text{V}(\mathbf{X,Y})
&=
\frac{tr\left( S_{\mathbf{XY}}S_{\mathbf{XY}} \right)}{\sqrt{tr\left( S_{\mathbf{XX}}^2 \right) tr\left( S_{\mathbf{YY}}^2 \right)}}
\end{aligned}$$

### Sample Space -->
<p>We can also consider the case where the correlations can be measured between samples and not between features. So we can create cross product matrices: <span class="math notranslate nohighlight">\(\mathbf{W}\mathbf{X}=\mathbf{XX}^\top \in \mathbb{R}^{N \times N}\)</span> **and <em><span class="math notranslate nohighlight">\(\mathbf{W}\mathbf{Y}=\mathbf{YY}^\top \in \mathbb{R}^{N \times N}\)</span></em>. Just like the feature space, we can use the Hilbert-Schmidt (HS) norm,  <span class="math notranslate nohighlight">\(||\cdot||_{F}\)</span> to measure proximity.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\langle {W}\mathbf{x}, {W}\mathbf{y} \rangle
&amp;=
tr \left( \mathbf{xx}^\top \mathbf{yy}^\top \right) \\
&amp;=
\sum_{i=1}^{D_x} \sum_{j=1}^{D_y} cov^2(\mathbf{x}{d_i}, \mathbf{y}{d_j})
\end{aligned}\end{split}\]</div>
<p>And like the above mentioned , we can also calculate a correlation measure using the sample space.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\rho V(\mathbf{x,y})
&amp;=
\frac{\langle \mathbf{W_x, W_y}\rangle_F}{||\mathbf{W_x}||_F \; ||\mathbf{W_y}||_F} \\
&amp;= \frac{\text{Tr}\left( \mathbf{xx}^\top \mathbf{yy}^\top \right)}{\sqrt{\text{Tr}\left( \mathbf{xx}^\top \right)^2 \text{Tr}\left( \mathbf{yy}^\top \right)^2}}
\end{aligned}
\end{split}\]</div>
<section id="id5">
<h4>Empirical Estimation<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<p>This is very easy to compute in practice. One just needs to calculate the Frobenius Norm (Hilbert-Schmidt Norm) of a covariance matrix This boils down to computing the trace of the matrix multiplication of two matrices: <span class="math notranslate nohighlight">\(tr(C_{xy}^\top C_{xy})\)</span>. So in algorithmically that is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hsic_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">C_xy</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">C_xy</span><span class="p">))</span>

</pre></div>
</div>
<p>We can make this faster by using the <code class="docutils literal notranslate"><span class="pre">sum</span></code> operation</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Numpy</span>
<span class="n">hsic_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C_xy</span> <span class="o">*</span> <span class="n">C_xy</span><span class="p">))</span>
<span class="c1"># PyTorch</span>
<span class="n">hsic_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">C_xy</span> <span class="o">*</span> <span class="n">C_xy</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

</pre></div>
</div>
<p><strong>Refactor</strong></p>
<p>There is a built-in function to be able to to speed up this calculation by a magnitude.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hs_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C_xy</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">)</span>

</pre></div>
</div>
<p>and in PyTorch</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hs_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C_xy</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;fro)</span>
</pre></div>
</div>
</section>
</section>
<section id="equivalence">
<h3>Equivalence<a class="headerlink" href="#equivalence" title="Permalink to this heading">#</a></h3>
<p>It turns out, for the linear case, when using the Frobenius norm to summarize the pairwise comparisons, comparing features is the same as comparing samples. For example, the norm of the covariance operator for the features and samples are equivalent:</p>
<div class="math notranslate nohighlight">
\[||\Sigma_{\mathbf{xy}}||_F^2 =
\langle \mathbf{W_x,W_y} \rangle_F\]</div>
<p>We get the same for the <span class="math notranslate nohighlight">\(\rho V\)</span> case.</p>
<div class="math notranslate nohighlight">
\[\frac{ ||\Sigma_{\mathbf{xy}}||F^2}{||\Sigma\mathbf{x}||F ||\Sigma\mathbf{y}||_F} =
\frac{ \langle \mathbf{W_x,W_y} \rangle_F}{||\mathbf{W_x}||_F ||\mathbf{W_y}||_F}\]</div>
<p>So what does this mean? Well, either method is fine. But you should probably choose one depending upon the computational resources available. For example, if you have more samples than features, then choose the feature space representation. On the other hand, if you have more features than samples, then choose the sample space representation.</p>
<p><strong>Linear Only</strong> This method only works for the linear case. There are some nonlinear transformations (called kernels) that one can use, but those will yield different values between feature space and sample space.</p>
</section>
</section>
<section id="extensions">
<h2>Extensions<a class="headerlink" href="#extensions" title="Permalink to this heading">#</a></h2>
<p>Many frameworks is a generalization of this as they attempt to maximize these quantities with some sort of constraint.</p>
<ul class="simple">
<li><p>PCA - maximum variance</p></li>
<li><p>CCA - …</p></li>
<li><p>Multivariate Regression - minimum MSE</p></li>
<li><p>Linear Discrimination - …</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="mutual-information">
<h2>Mutual Information<a class="headerlink" href="#mutual-information" title="Permalink to this heading">#</a></h2>
<p>There is a mutual information interpretation. This measurement only captures the 1st and 2nd order moments of the distribution. This is as if we were approximating as a Gaussian distribution which can be described by its first and second moments. The mutual information can be calculated directly if the cross covariance and the self-covariance matrices are known.</p>
<div class="math notranslate nohighlight">
\[I(X,Y) = - \frac{1}{2} \log \left( \frac{|C|}{|C_{xx}||C_{yy}||} \right)\]</div>
<p>As we showed above, the term inside the log is simply the Pearson correlation coefficient <span class="math notranslate nohighlight">\(\rho\)</span>.</p>
<div class="math notranslate nohighlight">
\[I(X,Y) = - \frac{1}{2} \log (1- \rho^2)\]</div>
</section>
<hr class="docutils" />
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>RV Coefficient and Congruence Coefficient <a class="reference external" href="https://wwwpub.utdallas.edu/~herve/Abdi-RV2007-pretty.pdf">PDF</a> - Abdi (2007)</p>
<blockquote>
<div><p>A great document that really breaks down the differences between the RV coefficient and the Congruence coefficient.</p>
</div></blockquote>
</li>
<li><p>Tucker’s Congruence Coefficient as a Meaningful Index of Factor Similarity <a class="reference external" href="https://openpsych.net/forum/attachment.php?aid=364">PDF</a> - Lorenzo-Seva &amp; Berge (2006) - Methodology</p>
<blockquote>
<div><p>More details relating to the Congruences coefficient and some reasoning as why one would use it.</p>
</div></blockquote>
</li>
<li><p>Measuring Multivariate Association and Beyond <a class="reference external" href="https://projecteuclid.org/download/pdfview_1/euclid.ssu/1479351622">PDF</a> - Josse &amp; Holmes (2016) - Statistics Surveys</p>
<blockquote>
<div><p>An Excellent review for how we can get <span class="math notranslate nohighlight">\(\rho\)</span>V-Coefficients and some of the modified versions. They also go into some other distance measures like the Graph, Mantel, Kernel and other.</p>
</div></blockquote>
</li>
<li><p>Average Distance of Random Points in a Unit Hypercube [<a class="reference external" href="https://martin-thoma.com/curse-of-dimensionality/">Blog</a>] - Martin Thoma</p>
<blockquote>
<div><p>A really nice blog post showing some empirical evidence for how these distance measures fail in high-dimensions.</p>
</div></blockquote>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="supplementary">
<h2>Supplementary<a class="headerlink" href="#supplementary" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Common Statistical Tests are Linear Models (or: How to Teach Stats) - Jonas Kristoffer Lindelov - <a class="reference external" href="https://eigenfoo.xyz/tests-as-linear/">notebook</a> | <a class="reference external" href="https://lindeloev.github.io/tests-as-linear/">rmarkdown</a></p></li>
<li><p>Correlation vs Regression - Asim Jana - <a class="reference external" href="https://www.datasciencecentral.com/profiles/blogs/difference-between-correlation-and-regression-in-statistics">blog</a></p></li>
<li><p>RealPython</p>
<ul>
<li><p>Numpy, SciPy and Pandas: Correlation with Python - <a class="reference external" href="https://realpython.com/numpy-scipy-pandas-correlation-python/">blog</a></p></li>
</ul>
</li>
<li><p>Correlation and Lag for Signals - <a class="reference external" href="https://currents.soest.hawaii.edu/ocn_data_analysis/_static/SEM_EDOF.html">notebook</a></p></li>
<li><p><a class="reference external" href="https://datascienceplus.com/understanding-the-covariance-matrix/">Understanding the Covariance Matrix</a></p></li>
<li><p><a class="reference external" href="https://stackoverflow.com/questions/34235452/numpy-vectorised-method-for-computing-covariance-with-population-means-for-surv">Numpy Vectorized method for computing covariance with population means</a></p></li>
<li><p>Eric Marsden</p>
<ul>
<li><p><a class="reference external" href="https://www.slideshare.net/EricMarsden1/modelling-correlations-using-python">Modeling Correlations in Python</a></p></li>
<li><p><a class="reference external" href="https://www.slideshare.net/EricMarsden1/regression-analysis-using-python">Regression Analysis in Python</a></p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="equivalences">
<h2>Equivalences<a class="headerlink" href="#equivalences" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Using Summations</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\rho V(X,Y) =
\frac{\sum_{i,j} \mathbf{x}_{i,j} \mathbf{y}_{i,j}}{\sqrt{\sum_{i,j} \mathbf{x}_{i,j}^2}\sqrt{\sum_{i,j} \mathbf{y}_{i,j}^2}}\]</div>
<ol class="arabic simple">
<li><p>Using Trace notation</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\rho V(X,Y) =
\frac{\text{Tr} \left( XY^\top\right)}{\text{Tr} \left( XX^\top\right)\text{Tr} \left( YY^\top\right)}\]</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/notes/kernels"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="kernel_derivatives.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Kernel Derivatives</p>
      </div>
    </a>
    <a class="right-next"
       href="congruence_coeff.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Congruence Coefficient</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#single-variables">Single Variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-and-variance">Mean and Variance</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#empirical-estimate">Empirical Estimate</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance">Covariance</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Empirical Estimate</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation">Correlation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Empirical Estimate</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-error">Root Mean Squared Error</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-dimensional">Multi-Dimensional</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-per-dimension">Correlation per Dimension</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-covariance">Self-Covariance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#empirical-estimation">Empirical Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-covariance">Cross-Covariance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Empirical Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-vector-difference">Root Mean Squared Vector Difference</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summarizing-multi-dimensional-information">Summarizing Multi-Dimensional Information</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#congruence-coefficient">Congruence Coefficient</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">rV Coefficient</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Empirical Estimation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#equivalence">Equivalence</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extensions">Extensions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-information">Mutual Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supplementary">Supplementary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#equivalences">Equivalences</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By J. Emmanuel Johnson
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>