{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jejjohnson/gp_model_zoo/blob/master/code/numpyro/numpyro_gpr_laplace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hecnCJD1trHy"
   },
   "source": [
    "# Numpyro Jax PlayGround\n",
    "\n",
    "My starting notebook where I install all of the necessary libraries and load some easy 1D/2D Regression data to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IgSMWFaNtnjB"
   },
   "outputs": [],
   "source": [
    "# @title Install Packages\n",
    "%%capture\n",
    "!pip install jax jaxlib flax chex optax objax\n",
    "!pip install \"git+https://github.com/deepmind/dm-haiku\"\n",
    "!pip install \"git+https://github.com/pyro-ppl/numpyro.git#egg=numpyro\"\n",
    "!pip uninstall tensorflow -y -q\n",
    "!pip install -Uq tfp-nightly[jax] > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "c5TKBjGbumu6"
   },
   "outputs": [],
   "source": [
    "# @title Load Packages\n",
    "# TYPE HINTS\n",
    "from typing import Tuple, Optional, Dict, Callable, Union\n",
    "\n",
    "# JAX SETTINGS\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "\n",
    "\n",
    "# JAX UTILITY LIBRARIES\n",
    "import chex\n",
    "\n",
    "# NUMPYRO SETTINGS\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer.autoguide import AutoDiagonalNormal\n",
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "# NUMPY SETTINGS\n",
    "import numpy as onp\n",
    "\n",
    "onp.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# MATPLOTLIB Settings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# SEABORN SETTINGS\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "# PANDAS SETTINGS\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# LOGGING SETTINGS\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "RSMP8Vr6x51L"
   },
   "outputs": [],
   "source": [
    "# @title Data\n",
    "def get_data(\n",
    "    n_train: int = 30,\n",
    "    input_noise: float = 0.15,\n",
    "    output_noise: float = 0.15,\n",
    "    n_test: int = 400,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, None]:\n",
    "    onp.random.seed(0)\n",
    "    X = np.linspace(-1, 1, n_train)\n",
    "    Y = X + 0.2 * np.power(X, 3.0) + 0.5 * np.power(0.5 + X, 2.0) * np.sin(4.0 * X)\n",
    "    Y += output_noise * onp.random.randn(n_train)\n",
    "    Y -= np.mean(Y)\n",
    "    Y /= np.std(Y)\n",
    "\n",
    "    X += input_noise * onp.random.randn(n_train)\n",
    "\n",
    "    assert X.shape == (n_train,)\n",
    "    assert Y.shape == (n_train,)\n",
    "\n",
    "    X_test = np.linspace(-1.2, 1.2, n_test)\n",
    "\n",
    "    return X[:, None], Y[:, None], X_test[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "cDm66m0g_jL4",
    "outputId": "190c4b5c-8d85-4b76-b9bc-6b39dede5726"
   },
   "outputs": [],
   "source": [
    "n_train = 60\n",
    "input_noise = 0.0\n",
    "output_noise = 0.1\n",
    "n_test = 100\n",
    "\n",
    "X, Y, Xtest = get_data(\n",
    "    n_train=n_train, input_noise=0.0, output_noise=output_noise, n_test=n_test\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, Y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXa_nHwb3NLL"
   },
   "source": [
    "## Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLMCRQ03w-O-"
   },
   "outputs": [],
   "source": [
    "import objax\n",
    "\n",
    "\n",
    "# squared euclidean distance\n",
    "def sqeuclidean_distance(x: np.array, y: np.array) -> float:\n",
    "    return np.sum((x - y) ** 2)\n",
    "\n",
    "\n",
    "# distance matrix\n",
    "def distmat(func: Callable, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"distance matrix\"\"\"\n",
    "    return jax.vmap(lambda x1: jax.vmap(lambda y1: func(x1, y1))(y))(x)\n",
    "\n",
    "\n",
    "# 1D covariance matrix\n",
    "def rbf_kernel(X, Y, variance, length_scale):\n",
    "    # distance formula\n",
    "    deltaXsq = distmat(sqeuclidean_distance, X / length_scale, Y / length_scale)\n",
    "\n",
    "    # rbf function\n",
    "    K = variance * np.exp(-0.5 * deltaXsq)\n",
    "    return K\n",
    "\n",
    "\n",
    "class ExactGP(objax.Module):\n",
    "    def __init__(self):\n",
    "        self.var = numpyro.param(\n",
    "            \"kernel_var\", init_value=1.0, constraints=dist.constraints.positive\n",
    "        )\n",
    "        self.scale = numpyro.param(\n",
    "            \"kernel_length\", init_value=0.1, constraints=dist.constraints.positive\n",
    "        )\n",
    "        self.sigma = numpyro.param(\n",
    "            \"sigma\", init_value=0.01, onstraints=dist.constraints.positive\n",
    "        )\n",
    "\n",
    "    def model2(self, X, y=None):\n",
    "        # η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.))\n",
    "        # ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2., 1.))\n",
    "        # σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.))\n",
    "\n",
    "        # Compute kernel\n",
    "        K = rbf_kernel(X, X, self.var, self.scale)\n",
    "        K += np.eye(X.shape[0]) * np.power(self.sigma, 2)\n",
    "\n",
    "        # Sample y according to the standard gaussian process formula\n",
    "        return numpyro.sample(\n",
    "            \"y\",\n",
    "            dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "            obs=y,\n",
    "        )\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def model(self, X, y=None):\n",
    "        # η = numpyro.param(\"kernel_var\", init_value=1.0, constraints=dist.constraints.positive)\n",
    "        # ℓ = numpyro.param(\"kernel_length\", init_value=0.1,  constraints=dist.constraints.positive)\n",
    "        # σ = numpyro.param(\"sigma\", init_value=0.01, onstraints=dist.constraints.positive)\n",
    "\n",
    "        η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.0))\n",
    "        ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2.0, 1.0))\n",
    "        σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.0))\n",
    "\n",
    "        # Compute kernel\n",
    "        K = rbf_kernel(X, X, η, ℓ)\n",
    "        K += np.eye(X.shape[0]) * np.power(σ, 2)\n",
    "\n",
    "        # Sample y according to the standard gaussian process formula\n",
    "        return numpyro.sample(\n",
    "            \"y\",\n",
    "            dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "            obs=y,\n",
    "        )\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        pass\n",
    "\n",
    "    # Predictive Mean and Variance\n",
    "    def predict(X, Y, X_test, variance, length_scale, noise):\n",
    "\n",
    "        K = rbf_kernel(X, X, variance, length_scale)\n",
    "        L, alpha = cholesky_factorization(K + noise * np.eye(K.shape[0]), Y)\n",
    "\n",
    "        # Calculate the Mean\n",
    "        K_x = rbf_kernel(X_test, X, variance, length_scale)\n",
    "        mu_y = np.dot(K_x, alpha)\n",
    "\n",
    "        # Calculate the variance\n",
    "        v = jax.scipy.linalg.cho_solve(L, K_x.T)\n",
    "\n",
    "        # Calculate kernel matrix for inputs\n",
    "        K_xx = rbf_kernel(X_test, X_test, variance, length_scale)\n",
    "\n",
    "        cov_y = K_xx - np.dot(K_x, v)\n",
    "        return mu_y, cov_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8BV-rAL3PKG"
   },
   "outputs": [],
   "source": [
    "# GP model.\n",
    "def GP(X, y):\n",
    "    # Set informative log-normal priors on kernel hyperparameters.\n",
    "    # η = pm.HalfCauchy(\"η\", beta=5)\n",
    "    η = numpyro.sample(\"variance\", dist.HalfCauchy(scale=5.0))\n",
    "    ℓ = numpyro.sample(\"length_scale\", dist.Gamma(2.0, 1.0))\n",
    "    σ = numpyro.sample(\"noise\", dist.HalfCauchy(scale=5.0))\n",
    "\n",
    "    # η = numpyro.param(\"kernel_var\", init_value=1.0, constraints=dist.constraints.positive)\n",
    "    # ℓ = numpyro.param(\"kernel_length\", init_value=0.1,  constraints=dist.constraints.positive)\n",
    "    # σ = numpyro.param(\"sigma\", init_value=0.01, onstraints=dist.constraints.positive)\n",
    "\n",
    "    # Compute kernel\n",
    "    K = rbf_kernel(X, X, η, ℓ)\n",
    "    K += np.eye(X.shape[0]) * np.power(σ, 2)\n",
    "\n",
    "    # Sample y according to the standard gaussian process formula\n",
    "    numpyro.sample(\n",
    "        \"y\",\n",
    "        dist.MultivariateNormal(loc=np.zeros(X.shape[0]), covariance_matrix=K),\n",
    "        obs=y,\n",
    "    )\n",
    "\n",
    "\n",
    "def empty_guide(X, y):\n",
    "    pass\n",
    "\n",
    "\n",
    "def cholesky_factorization(K: np.ndarray, Y: np.ndarray) -> Tuple[np.ndarray, bool]:\n",
    "    \"\"\"Cholesky Factorization\"\"\"\n",
    "    # cho factor the cholesky\n",
    "    L = jax.scipy.linalg.cho_factor(K, lower=True)\n",
    "\n",
    "    # weights\n",
    "    weights = jax.scipy.linalg.cho_solve(L, Y)\n",
    "\n",
    "    return L, weights\n",
    "\n",
    "\n",
    "# Predictive Mean and Variance\n",
    "def predict(X, Y, X_test, variance, length_scale, noise):\n",
    "\n",
    "    K = rbf_kernel(X, X, variance, length_scale)\n",
    "    L, alpha = cholesky_factorization(K + noise * np.eye(K.shape[0]), Y)\n",
    "\n",
    "    # Calculate the Mean\n",
    "    K_x = rbf_kernel(X_test, X, variance, length_scale)\n",
    "    mu_y = np.dot(K_x, alpha)\n",
    "\n",
    "    # Calculate the variance\n",
    "    v = jax.scipy.linalg.cho_solve(L, K_x.T)\n",
    "\n",
    "    # Calculate kernel matrix for inputs\n",
    "    K_xx = rbf_kernel(X_test, X_test, variance, length_scale)\n",
    "\n",
    "    cov_y = K_xx - np.dot(K_x, v)\n",
    "    return mu_y, cov_y\n",
    "\n",
    "\n",
    "# Summarize function posterior.\n",
    "def posterior(rng_key, X, Y, X_test, variance, length_scale, noise):\n",
    "    m, cov = predict(X, Y, X_test, variance, length_scale, noise)\n",
    "\n",
    "    return random.multivariate_normal(rng_key, mean=m, cov=cov)\n",
    "\n",
    "\n",
    "def summarize_posterior(preds, ci=96):\n",
    "    ci_lower = (100 - ci) / 2\n",
    "    ci_upper = (100 + ci) / 2\n",
    "    preds_mean = preds.mean(0)\n",
    "    preds_lower = np.percentile(preds, ci_lower, axis=0)\n",
    "    preds_upper = np.percentile(preds, ci_upper, axis=0)\n",
    "    return preds_mean, preds_lower, preds_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmJrGlYS3TuD"
   },
   "outputs": [],
   "source": [
    "K = rbf_kernel(X, X, 1.0, 1.0)\n",
    "\n",
    "# check shape\n",
    "chex.assert_shape(K, (n_train, n_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUaxz503yPy8"
   },
   "source": [
    "## Laplace Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdFMOB8_yRwa"
   },
   "outputs": [],
   "source": [
    "from numpyro.infer.autoguide import AutoLaplaceApproximation\n",
    "from numpyro.infer import TraceMeanField_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUONRmg_ykHI",
    "outputId": "1e56d275-7702-4ab3-eb68-fd77740aeb28"
   },
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "# Setup\n",
    "guide = numpyro.infer.autoguide.AutoLaplaceApproximation(GP)\n",
    "optimizer = numpyro.optim.Adam(step_size=0.01)\n",
    "# optimizer = numpyro.optim.Minimize()\n",
    "# optimizer = optax.adamw(learning_rate=0.1)\n",
    "svi = SVI(GP, guide, optimizer, loss=Trace_ELBO())\n",
    "svi_result = svi.run(random.PRNGKey(1), 1_000, X, Y.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "WIpwm7rvyl3n",
    "outputId": "eccfbdd1-2cf8-438b-859f-38becb372c9d"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(svi_result.losses)\n",
    "ax.set(title=\"Loss\", xlabel=\"Iterations\", ylabel=\"Negative ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQQwvCJfyy4o",
    "outputId": "00c1f019-93f0-481b-cf8e-ff5918405a1a"
   },
   "outputs": [],
   "source": [
    "params = svi_result.params\n",
    "print(params)\n",
    "\n",
    "quantiles = guide.median(params)\n",
    "print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZPdVF5cy1SG"
   },
   "outputs": [],
   "source": [
    "y_pred, y_cov = predict(\n",
    "    X,\n",
    "    Y.squeeze(),\n",
    "    Xtest,\n",
    "    variance=quantiles[\"variance\"],\n",
    "    length_scale=quantiles[\"length_scale\"],\n",
    "    noise=quantiles[\"noise\"],\n",
    ")\n",
    "\n",
    "y_var = np.diagonal(y_cov)\n",
    "y_std = np.sqrt(y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "pFjC1-EuzQwS",
    "outputId": "a78f0700-e3b6-4335-d72d-b75a3a0ecf29"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "ax.scatter(X, Y, label=\"Training Data\", color=\"red\")\n",
    "ax.plot(Xtest, y_pred, label=\"Predictive Mean\", color=\"black\", linewidth=3)\n",
    "ax.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    y_pred - y_std,\n",
    "    y_pred + y_std,\n",
    "    label=\"Confidence Interval\",\n",
    "    alpha=0.3,\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnGVOu0kPp_v"
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "n_samples = 1_000\n",
    "\n",
    "advi_samples = guide.sample_posterior(random.PRNGKey(seed), params, (n_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "VUe_YgpRJbmD",
    "outputId": "360c9350-b587-4dec-a831-f6e0ed3ae65d"
   },
   "outputs": [],
   "source": [
    "# Plot posteriors for the parameers\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12, 3))\n",
    "\n",
    "sns.histplot(\n",
    "    ax=ax[0], x=advi_samples[\"length_scale\"], kde=True, bins=50, stat=\"density\"\n",
    ")\n",
    "sns.histplot(ax=ax[1], x=advi_samples[\"variance\"], kde=True, bins=50, stat=\"density\")\n",
    "sns.histplot(ax=ax[2], x=advi_samples[\"noise\"], kde=True, bins=50, stat=\"density\")\n",
    "\n",
    "ax[0].set(title=\"Kernel Length Scale\")\n",
    "ax[1].set(title=\"Kernel Variance\", ylabel=\"\")\n",
    "ax[2].set(title=\"Likelihood Noise\", ylabel=\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOVPBS8wJ1Yc"
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO37k5jNJ2tl"
   },
   "outputs": [],
   "source": [
    "predictions, _ = jax.vmap(\n",
    "    predict, in_axes=(None, None, None, 0, 0, 0), out_axes=(0, 0)\n",
    ")(\n",
    "    X,\n",
    "    Y.squeeze(),\n",
    "    Xtest,\n",
    "    advi_samples[\"variance\"],\n",
    "    advi_samples[\"length_scale\"],\n",
    "    advi_samples[\"noise\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "cPPA0EooJ0o0",
    "outputId": "87f1ef32-a7c2-4801-ea25-e23471b90d99"
   },
   "outputs": [],
   "source": [
    "plt.plot(predictions.T, color=\"gray\", alpha=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0sQd_2JKFd7"
   },
   "outputs": [],
   "source": [
    "y_pred, y_lb, y_ub = summarize_posterior(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "cbTeCzDdKCz4",
    "outputId": "05e8f66e-34ce-42ed-b533-008129eeb13a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(6, 4))\n",
    "\n",
    "ax.scatter(X, Y, label=\"Training Data\", color=\"red\")\n",
    "ax.plot(Xtest, y_pred, label=\"Predictive Mean\", color=\"black\", linewidth=3)\n",
    "ax.fill_between(\n",
    "    Xtest.squeeze(),\n",
    "    y_lb,\n",
    "    y_ub,\n",
    "    label=\"Confidence Interval\",\n",
    "    alpha=0.3,\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQVIezMfKyAY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOoD2Dqsw62GmytXVTt2Hz1",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "numpyro_gpr_laplace.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
