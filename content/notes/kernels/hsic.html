
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>HSIC &#8212; Research Notebook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Maximum Mean Discrepancy (MMD)" href="mmd.html" />
    <link rel="prev" title="Congruence Coefficient" href="congruence_coeff.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/book_v2.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Notebook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../resources/python/overview.html">
   Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/ides.html">
     Integraded Development Environment (IDE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/stack.html">
     Standard Python Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/earthsci_stack.html">
     Earth Science Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/dl_stack.html">
     Deep Learning Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/scale_stack.html">
     Scaling Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/good_code.html">
     Good Code
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/jax_journey/overview.html">
   My JAX Journey
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">
     Ecosystem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/vmap.html">
     vmap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/jit.html">
     Jit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/classes.html">
     Classes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">
       Bisection search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">
       Kernel Derivatives
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/gfs_with_jax.html">
       Gaussianization Flows
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/remote/overview.html">
   Remote Computing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/ssh.html">
     SSH Configuration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/conda.html">
     Conda 4 Remote Servers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/jlab.html">
     Jupyter Lab 4 Remote Servers
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/notation.html">
   Notation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/quotes.html">
   Quotes
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data/overview.html">
   Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data/representation.html">
     Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data/models.html">
     Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/uncertainty.html">
   Modeling Uncertainty
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../bayesian/overview.html">
   Bayesian
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/intro.html">
     Language of Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/inference.html">
     Inference Schemes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/inference/variational_inference.html">
     Variational Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/inference/cond_vi.html">
     Conditional Variational Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/confidence_intervals.html">
     Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayesian/regression.html">
     Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../concepts/overview.html">
   Sleeper Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/gaussian.html">
     Gaussian Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/change_of_variables.html">
     Change of Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/identity_trick.html">
     Identity Trick
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/inverse_function.html">
     Inverse Function Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/jensens.html">
     Jensens Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/lin_alg.html">
     Linear Algebra Tricks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   Kernel Methods
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="kernel_derivatives.html">
     Kernel Derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="rv.html">
     RV Coefficient
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="congruence_coeff.html">
     Congruence Coefficient
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     HSIC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mmd.html">
     Maximum Mean Discrepancy (MMD)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../gps/intro.html">
   Gaussian Processes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../gps/gps.html">
     Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gps/literature.html">
     Literature Review
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gps/cg.html">
     Conjugate Gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gps/sgps.html">
     Sparse Gaussian Processes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../gps/algorithms.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../gps/gpr_code.html">
       GP from Scratch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../gps/sgp_code.html">
       Sparse GP From Scratch
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/overview.html">
     Input Uncertainty in GPs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../info_theory/similarity.html">
   Similarity
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../info_theory/overview.html">
   Information Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../info_theory/measures.html">
     Measures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/information.html">
       Information Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/entropy.html">
       Entropy &amp; Relative Entropy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/mutual_info.html">
       Mutual Information and Total Correlation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../info_theory/estimators.html">
     Information Theory Measures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/classic.html">
       Classic Methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/histogram.html">
       Entropy Estimator - Histogram
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">
       Experiment - RBIG Sample Consistency
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../normalizing_flows/overview.html">
   Normalizing Flows
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/linear.html">
     Linear Layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/coupling_layers.html">
     Coupling Layers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/conditional.html">
     Conditional Normalizing Flows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normalizing_flows/multiscale.html">
     Multiscale
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../normalizing_flows/lecture_1_ig.html">
     Lecture I - Iterative Gaussianization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/1.0_univariate_gauss.html">
       1.1 - Univariate Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/1.1_marginal_gauss.html">
       1.2 - Marginal Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/1.2_gaussianization.html">
       1.2 - Iterative Gaussianization
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../normalizing_flows/lecture_2_gf.html">
     Lecture II - Gaussianization Flows
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt1_mg.html">
       Parameterized Marginal Gaussianization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt2_rot.html">
       Parameterized Rotations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt3_plane.html">
       Example - 2D Plane
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../inr/overview.html">
   Implicit Neural Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../inr/formulation.html">
     Formulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inr/literature_review.html">
     Literature Review
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../inr/pinns.html">
     Physics-Informed Loss
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../inr/qg.html">
       QG PDE
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data_assimilation/overview.html">
   Data Assimilation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/dynamical_sys.html">
     Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/oi.html">
     Optimal Interpolation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/interp.html">
     Interpolation Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/emu.html">
     Emulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/inv_problems.html">
     Inverse Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data_assimilation/projects.html">
     Projects
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../data_assimilation/algorithms.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/markov_models.html">
       Markov Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/gauss_markov.html">
       Gauss-Markov Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/kf.html">
       Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/nkf.html">
       Normalizing Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/enskf.html">
       Ensemble Kalman Filter
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/dmm.html">
       Deep Markov Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/4dvarnet.html">
       4DVarNet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../data_assimilation/markov_gp.html">
       Markovian Gaussian Processes
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../misc/overview.html">
   Miscellaneous Notes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../misc/generative_models.html">
     Generative Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../misc/diffusion_models.html">
     Diffusion Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../misc/fixed_point.html">
     Fixed-Point Methods
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Cheat Sheets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../cheatsheets/bash.html">
   Bash
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cheatsheets/cli.html">
   Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cheatsheets/python.html">
   Python
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jejjohnson/research_notebook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/kernels/hsic.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/content/notes/kernels/hsic.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recap-summarizing-multivariate-information">
   Recap - Summarizing Multivariate Information
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#samples-versus-features">
   Samples versus Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-trick">
   Kernel Trick
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#proof">
     Proof
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#full-expression">
     Full Expression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#code">
     Code
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#centering">
     Centering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Full Expression
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Code
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlation">
   Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connections">
   Connections
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-mean-discrepency">
     Maximum Mean Discrepency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#information-theory-measures">
     Information Theory Measures
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#future-outlook">
   Future Outlook
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#literature-review">
     Literature Review
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#applications">
     Applications
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#textbooks">
     Textbooks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>HSIC</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recap-summarizing-multivariate-information">
   Recap - Summarizing Multivariate Information
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#samples-versus-features">
   Samples versus Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-trick">
   Kernel Trick
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#proof">
     Proof
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#full-expression">
     Full Expression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#code">
     Code
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#centering">
     Centering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Full Expression
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Code
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlation">
   Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connections">
   Connections
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-mean-discrepency">
     Maximum Mean Discrepency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#information-theory-measures">
     Information Theory Measures
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#future-outlook">
   Future Outlook
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#literature-review">
     Literature Review
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#applications">
     Applications
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#textbooks">
     Textbooks
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="hsic">
<h1>HSIC<a class="headerlink" href="#hsic" title="Permalink to this headline">#</a></h1>
<p>We use the Hilbert-Schmidt Independence Criterion (HSIC) measure independence between two distributions. It involves constructing an appropriate kernel matrix for each dataset and then using the Frobenius Norm as a way to “summarize” the variability of the data. Often times the motivation for this method is lost in the notorious paper of Arthur Gretton (the creator of the method), but actually, this idea was developed long before him with ideas from a covariance matrix perspective. Below are my notes for how to get from a simple covariance matrix to the HSIC method and similar ones.</p>
<hr class="docutils" />
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">#</a></h2>
<p>A very common mechanism to measure the differences between datasets is to measure the variability. The easiest way is the measure the covariance between the two datasets. However, this is limited to datasets with linear relationships and with not many outliers. Anscombe’s classic dataset is an example where we have datasets with the same mean and standard deviation.</p>
<!-- <p align="center">
  <img src=".pics/demo_caseI_reg.png" alt="drawing" width="175"/>
  <img src="./pics/demo_caseII_reg.png" alt="drawing" width="175"/>
  <img src="./pics/demo_caseIII_reg.png" alt="drawing" width="175"/>
  <img src="./pics/demo_caseIV_reg.png" alt="drawing" width="175"/>
</p> -->
<center>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="Case I" src="content/notes/kernels/pics/demo_caseI_reg.png" /></p></td>
<td><p><img alt="Case I" src="content/notes/kernels/pics/demo_caseII_reg.png" /></p></td>
<td><p><img alt="Case I" src="content/notes/kernels/pics/demo_caseIII_reg.png" /></p></td>
<td><p><img alt="Case I" src="content/notes/kernels/pics/demo_caseIV_reg.png" /></p></td>
</tr>
<tr class="row-odd"><td><p>Case I</p></td>
<td><p>Case II</p></td>
<td><p>Case III</p></td>
<td><p>Case IV</p></td>
</tr>
</tbody>
</table>
</center>
<p>This means measures like the covariance and correlation become useless because they will yield the same result. This requires us to have more robust methods that take into account the non-linear relationships that are clearly present within the data. That…or to do some really good preprocessing to make models easier.</p>
</section>
<hr class="docutils" />
<section id="recap-summarizing-multivariate-information">
<h2>Recap - Summarizing Multivariate Information<a class="headerlink" href="#recap-summarizing-multivariate-information" title="Permalink to this headline">#</a></h2>
<p>Let’s have the two distributions <span class="math notranslate nohighlight">\(\mathcal{X} \in \mathbb{R}^{D_x}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Y} \in \mathbb{R}^{D_y}\)</span>. Let’s also assume that we can sample <span class="math notranslate nohighlight">\((x,y)\)</span> from <span class="math notranslate nohighlight">\(\mathbb{P}_{xy}\)</span>. We can capture the second order dependencies between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> by constructing a covariance matrix in the feature space defined as:</p>
<div class="math notranslate nohighlight">
\[
C_{\mathbf{xy}} \in \mathbb{R}^{D \times D}
\]</div>
<p>We can use the Hilbert-Schmidt Norm (HS-Norm) as a statistic to effectively summarize content within this covariance matrix. It’s defined as:</p>
<div class="math notranslate nohighlight">
\[||C_{xy}||_{\mathcal{F}}^2 = \sum_i \lambda_i^2 = \text{tr}\left[ C_{xy}^\top C_{xy} \right]\]</div>
<p>Note that this term is zero iff <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent and greater than zero otherwise. Since the covariance matrix is a second-order measure of the relations, we can only summarize the the second order relation information. But at the very least, we now have a scalar value that summarizes the structure of our data.</p>
<p>And also just like the correlation, we can also do a normalization scheme that allows us to have an interpretable scalar value. This is similar to the correlation coefficient except it can now be applied to multi-dimensional data.</p>
<div class="math notranslate nohighlight">
\[
\rho_\mathbf{xy} = \frac{ ||C_{\mathbf{xy}}||_\mathcal{F}^2}{||C_\mathbf{xx}||_{\mathcal{F}} ||C_\mathbf{yy}||_{\mathcal{F}}}
\]</div>
</section>
<hr class="docutils" />
<section id="samples-versus-features">
<h2>Samples versus Features<a class="headerlink" href="#samples-versus-features" title="Permalink to this headline">#</a></h2>
<p>One interesting connection is that using the HS norm in the feature space is the sample thing as using it in the sample space.</p>
<div class="math notranslate nohighlight">
\[
\langle C_{\mathbf{x^\top y}}, C_{\mathbf{x^\top y}}\rangle_{\mathcal{F}} = \langle C_{\mathbf{xx^\top }}, C_{\mathbf{yy^\top}}\rangle_{\mathcal{F}}
\]</div>
<blockquote>
<div><p>Comparing Features is the same as comparing samples!</p>
</div></blockquote>
<p><strong>Note</strong>: This is very similar to the dual versus sample space that is often mentioned in the kernel literature.</p>
<p>So our equations before will change slightly in notation as we are constructing different matrices. But in the end, they will have the same output. This includes the correlation coefficient <span class="math notranslate nohighlight">\(\rho\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\frac{\langle C_{\mathbf{x^\top y}}, C_{\mathbf{x^\top y}}\rangle_{\mathcal{F}}}{||C_\mathbf{x^\top x}||_{\mathcal{F}} ||C_\mathbf{y^\top y}||_{\mathcal{F}}}
= \frac{ \langle C_{\mathbf{xx^\top }}, C_{\mathbf{yy^\top}}\rangle_{\mathcal{F}}}{||C_\mathbf{xx^\top}||_{\mathcal{F}} ||C_\mathbf{yy^\top}||_{\mathcal{F}}}
\]</div>
</section>
<hr class="docutils" />
<section id="kernel-trick">
<h2>Kernel Trick<a class="headerlink" href="#kernel-trick" title="Permalink to this headline">#</a></h2>
<p>So now, we have only had a linear dot-similarity in the sample space of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. This is good but we can easily extend this to a non-linear transformation where we add an additional function <span class="math notranslate nohighlight">\(\psi\)</span> for each of the kernel functions.</p>
<div class="math notranslate nohighlight">
\[
\langle C_{\mathbf{xx^\top }}, C_{\mathbf{yy^\top}}\rangle_{\mathcal{F}} =
\langle K_{\mathbf{x}}, K_{\mathbf{y}}\rangle_\mathcal{F}
\]</div>
<p>Let’s assume there exists a nonlinear mapping from our data space to the Hilbert space. So <span class="math notranslate nohighlight">\(\phi : \mathcal{X} \rightarrow \mathcal{F}\)</span> and <span class="math notranslate nohighlight">\(\psi : \mathcal{Y} \rightarrow \mathcal{G}\)</span>. We also assume that there is a representation of this mapping via the dot product between the features of the data space; i.e. <span class="math notranslate nohighlight">\(K_x(x,x') = \langle \phi(x), \phi(x') \rangle\)</span> and <span class="math notranslate nohighlight">\(K_y(y,y') = \langle \psi(y), \psi(y') \rangle\)</span>. So now the data matrices are <span class="math notranslate nohighlight">\(\Phi \in \mathbb{R}^{N\times N_\mathcal{F}}\)</span> and <span class="math notranslate nohighlight">\(\Psi \in \mathbb{R}^{N \times N_\mathcal{G}}\)</span>. So we can take the kernelized version of the cross covariance mapping as defined for the covariance matrix:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
||C_{\phi(x)\psi(x)}||_\mathcal{H}^2 
&amp;= ||\Phi^\top \Psi||^2_{\mathcal{F}} 
\end{aligned}
\]</div>
<p>Now after a bit of simplication, we end up with the HSIC-Norm:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{HSIC}(\hat{P}_{XY}, \mathcal{F}, \mathcal{G})
&amp;= \text{Tr}(K_{\mathbf{x}}K_{\mathbf{y}}) \\
\end{aligned}
\end{split}\]</div>
<section id="proof">
<h3>Proof<a class="headerlink" href="#proof" title="Permalink to this headline">#</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
||C_{\phi(x)\psi(x)}||_\mathcal{H}^2 
&amp;= ||\Phi^\top \Psi||^2 \\
&amp;= tr\left[ (\Phi^\top \Psi)^\top (\Phi^\top \Psi)\right] \\
&amp;= tr \left[ \Psi^\top \Phi \Phi^\top \Psi\right] \\
&amp;= tr \left[ \Psi \Psi^\top \Phi \Phi^\top \right] \\
&amp;= tr (K_{\mathbf{x}}K_{\mathbf{x}})
\end{aligned}
\end{split}\]</div>
</section>
<section id="full-expression">
<h3>Full Expression<a class="headerlink" href="#full-expression" title="Permalink to this headline">#</a></h3>
<p>Using the same argument as above, we can also define a cross covariance matrix of the form:</p>
<div class="math notranslate nohighlight">
\[C_{xy} = \mathbb{E}_{xy} \left[  (\phi(x) - \mu_x) \otimes (\psi(y) - \mu_y)\right]\]</div>
<p>where <span class="math notranslate nohighlight">\(\otimes\)</span> is the tensor product, <span class="math notranslate nohighlight">\(\mu_x, \mu_y\)</span> are the expecations of the mappings <span class="math notranslate nohighlight">\(\mathbb{E}_x [\phi (x)]\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E}_y[\psi(y)]\)</span> respectively. The HSIC is the cross-covariance operator described above and can be expressed in terms of kernels.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{HSIC}(\mathcal{F}, \mathcal{G}, \mathbb{P}_{xy})
&amp;= ||C_{xy}||_{\mathcal{H}}^2 \\
&amp;= \mathbb{E}_{xx',yy'} \left[ K_x(x,x')K_y(y,y') \right] \\
&amp;+  \mathbb{E}_{xx'} \left[ K_x(x,x')\right] \mathbb{E}_{yy'} \left[ K_y(y,y')\right] \\
&amp;-  2\mathbb{E}_{xy} \left[ \mathbb{E}_{x'} \left[ K_x(x,x')\right] \mathbb{E}_{y'} \left[ K_y(y,y')\right] \right]
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{E}_{xx'yy'}\)</span> is the expectation over both <span class="math notranslate nohighlight">\((x,y) \sim \mathbb{P}_{xy}\)</span> and we assume that <span class="math notranslate nohighlight">\((x',y')\)</span> can be sampled independently from <span class="math notranslate nohighlight">\(\mathbb{P}_{xy}\)</span>.</p>
</section>
<section id="code">
<h3>Code<a class="headerlink" href="#code" title="Permalink to this headline">#</a></h3>
<p>This is very easy to compute in practice. One just needs to calculate the Frobenius Norm (Hilbert-Schmidt Norm) between two kernel matrics that correctly model your data. This boils down to computing the trace of the matrix multiplication of two matrices: <span class="math notranslate nohighlight">\(tr(K_x^\top K_y)\)</span>. So in algorithmically that is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hsic_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">K_x</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">K_y</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that this is a 3-part operation. So, of course, we can refactor this to be much easier. A faster way to do this is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hsic_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K_x</span> <span class="o">*</span> <span class="n">K_y</span><span class="p">)</span>
</pre></div>
</div>
<p>This can be orders of magnitude faster because it is a much cheaper operation to compute elementwise products than a sum. And for fun, we can even use the <code class="docutils literal notranslate"><span class="pre">einsum</span></code> notation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hsic_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ji,ij-&gt;&quot;</span><span class="p">,</span> <span class="n">K_x</span><span class="p">,</span> <span class="n">K_y</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="centering">
<h3>Centering<a class="headerlink" href="#centering" title="Permalink to this headline">#</a></h3>
<p>A very important but subtle point is that the method with kernels assumes that your data is centered in the kernel space. This isn’t necessarily true. Fortunately it is easy to do so.</p>
<div class="math notranslate nohighlight">
\[HK_xH = \tilde{K}_x\]</div>
<p>where <span class="math notranslate nohighlight">\(H\)</span> is your centering matrix.</p>
<blockquote>
<div><p>Normalizing your inputs does <strong>not</strong> equal centering your kernel matrix.</p>
</div></blockquote>
<section id="id1">
<h4>Full Expression<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h4>
<p>We assume that the kernel function <span class="math notranslate nohighlight">\(\psi(x_i)\)</span> has a zero mean like so:</p>
<div class="math notranslate nohighlight">
\[\psi(x_i) = \psi(x_i) - \frac{1}{N}\sum_{r=1}^N \psi(x_r)\]</div>
<p>This holds if the covariance matrix is computed from <span class="math notranslate nohighlight">\(\psi(x_i)\)</span>. So the kernel matrix <span class="math notranslate nohighlight">\(K_{ij}=\psi(x_i)^\top \psi(x_j)\)</span> needs to be replaced with <span class="math notranslate nohighlight">\(\tilde{K}_{ij}=\psi(x_i)^\top \psi(x_s)\)</span> where <span class="math notranslate nohighlight">\(\tilde{K}_{ij}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\tilde{K}_{ij} &amp;= \psi(x_i)^\top \psi(x_j) - \frac{1}{N} \sum_{r=1}^N - \frac{1}{N} \sum_{r=1}^N \psi(x_r)^\top \psi(x_j) + \frac{1}{N^2} \sum_{r,s=1}^N \psi(x_r)^\top \psi(x_s) \\
&amp;= K_{ij} - \frac{1}{N}\sum_{r=1}^{N}K_{ir} - \frac{1}{N} K_{rj} + \frac{1}{N^2} \sum_{r,s=1}^N K_s
\end{aligned}
\end{split}\]</div>
</section>
<section id="id2">
<h4>Code<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h4>
<p>On a more practical note, this can be done easily by:</p>
<div class="math notranslate nohighlight">
\[H = \mathbf{I}_N - \frac{1}{N} \mathbf{1}_N\mathbf{1}_N^\top\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Refactor</strong></p>
<p>There is also a function in the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> library which does it for you.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KernelCenterer</span>

<span class="n">K_centered</span> <span class="o">=</span> <span class="n">KernelCenterer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<hr class="docutils" />
<section id="correlation">
<h2>Correlation<a class="headerlink" href="#correlation" title="Permalink to this headline">#</a></h2>
<p>So above is the entire motivation behind HSIC as a non-linear covariance measure. But there is the obvious extension that we need to do: as a similarity measure (i.e. a correlation). HSIC suffers from the same issue as a covariance measure: it is difficult to interpret. HSIC’s strongest factor is that it can be used for independence testing. However, as a similarity measure, it violates some key criteria that we need: invariant to scaling and interpretability (bounded between 0-1). Recall the HSIC formula:</p>
<div class="math notranslate nohighlight">
\[
A(K_x, K_y) = 
\left\langle H K_x, H K_y \right\rangle_{F}
\]</div>
<p>Below is the HSIC term that is normalized by the norm of the</p>
<div class="math notranslate nohighlight">
\[\text{cKA}(\mathbf{xy})=\frac{ \langle K_{\mathbf{x}}, K_{\mathbf{y}}\rangle_\mathcal{F}}{||K_\mathbf{x}||_{\mathcal{F}} ||K_\mathbf{y}||_{\mathcal{F}}}\]</div>
<p>This is known as <strong>Centered Kernel Alignment</strong> in the literature. They add a normalization term to deal with some of the shortcomings of the original <strong>Kernel Alignment</strong> algorithm which had some benefits e.g. a way to cancel out unbalanced class effects. In relation to HSICThe improvement over the original algorithm seems minor but there is a critical difference. Without the centering, the alignment does not correlate well to the performance of the learning machine. There is</p>
<p>??? info “Original Kernel Alignment”
The original kernel alignment method had the normalization factor but the matrices were not centered.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$$A(K_x, K_y) = 
\frac{\left\langle K_x, K_y \right\rangle_{F}}{\sqrt{|| K_x||_{F}|| K_y ||_{F}}}
$$

The alignment can be seen as a similarity score based on the cosine of the angle. For arbitrary matrices, this score ranges between -1 and 1. But using positive semidefinite Gram matrices, the score is lower-bounded by 0. This method was introduced **before** the HSIC method was introduced by Gretton. However, because the kernel matrices were not centered, there were some serious problems when trying to use it for measuring similarity: You could literally get any number between 0-1 if with parameters. So for a simple 1D linear dataset which should have a correlation of 1, I could get any number between 0 and 1 if I just change the length scale slightly. The HSIC and the CKA were much more robust than this method so I would avoid it.
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="connections">
<h2>Connections<a class="headerlink" href="#connections" title="Permalink to this headline">#</a></h2>
<hr class="docutils" />
<section id="maximum-mean-discrepency">
<h3>Maximum Mean Discrepency<a class="headerlink" href="#maximum-mean-discrepency" title="Permalink to this headline">#</a></h3>
<p><strong>HSIC</strong></p>
<div class="math notranslate nohighlight">
\[
\text{MMD}^2(\hat{P}_{XY}, \hat{P}_X\hat{P}_Y, \mathcal{H}_k) =
\frac{1}{n^2}\text{tr} \left( K_x H K_y H \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(H\)</span> is the centering matrix <span class="math notranslate nohighlight">\(H=I_n-\frac{1}{n}1_n1_n^\top\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\text{HSIC}^2(\hat{P}_{XY}, \mathcal{F}, \mathcal{G}) = 
\text{MMD}^2(\hat{P}_{XY}, \hat{P}_X\hat{P}_Y, \mathcal{H}_k)
\]</div>
<div class="math notranslate nohighlight">
\[\text{HSIC}_k(\mathbb{P}) = \text{MMD}_k(\mathbb{P}, \otimes_{m=1}^M \mathbb{P}_m)\]</div>
</section>
<hr class="docutils" />
<section id="information-theory-measures">
<h3>Information Theory Measures<a class="headerlink" href="#information-theory-measures" title="Permalink to this headline">#</a></h3>
<p><strong>Kullback-Leibler Divergence</strong></p>
<div class="math notranslate nohighlight">
\[D_{KL}(\mathbb{P}, \mathbb{Q}) = \int_{\mathbb{R}^d} p(x) \log \left[ \frac{p(x)}{q(x)} \right]dx\]</div>
<p><strong>Mutual Information</strong></p>
<div class="math notranslate nohighlight">
\[I(\mathbb{P})=D_{KL}\left( \mathbb{P}, \otimes_{m=1}^{M}\mathbb{P}_m \right)\]</div>
</section>
</section>
<hr class="docutils" />
<section id="future-outlook">
<h2>Future Outlook<a class="headerlink" href="#future-outlook" title="Permalink to this headline">#</a></h2>
<p><strong>Advantages</strong></p>
<ul class="simple">
<li><p>Sample Space - Nice for High Dimensional Problems w/ a low number of samples</p></li>
<li><p>HSIC can estimate dependence between variables of different dimensions</p></li>
<li><p>Very flexible: lots of ways to create kernel matices</p></li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul class="simple">
<li><p>Computationally demanding for large scale problems</p></li>
<li><p>Non-iid samples, e.g. speech or images</p></li>
<li><p>Tuning Kernel parameters</p></li>
<li><p>Why the HS norm?</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">#</a></h2>
<p><strong>Presentations</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.cmap.polytechnique.fr/~zoltan.szabo/talks/invited_talk/Zoltan_Szabo_invited_talk_EPFL_LIONS_28_02_2018_slides.pdf">HSIC, A Measure of Independence</a> - Szabo (2018)</p></li>
<li><p><a class="reference external" href="https://harpo.uv.es/wiki/_media/dspg-ipl:gcamps_hsic.pdf">Measuring Independence with Kernels</a> - Gustau</p></li>
</ul>
<section id="literature-review">
<h3>Literature Review<a class="headerlink" href="#literature-review" title="Permalink to this headline">#</a></h3>
<p><strong>An Overview of Kernel Alignment and its Applications</strong> - Wang et al (2012) - <a class="reference external" href="https://link.springer.com/content/pdf/10.1007/s10462-012-9369-4.pdf">PDF</a></p>
<p>This goes over the literature of the kernel alignment method as well as some applications it has been used it.</p>
</section>
<section id="applications">
<h3>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Kerneel Target Alignment Parameter: A New Modelability for Regression Tasks - Marcou et al (2016) - <a class="reference external" href="https://pubs.acs.org/doi/full/10.1021/acs.jcim.5b00539">Paper</a></p></li>
<li><p>Brain Activity Patterns - <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fnins.2017.00550/full">Paper</a></p></li>
<li><p>Scaling - <a class="reference external" href="https://link.springer.com/article/10.1007/s11222-016-9721-7">Paper</a></p></li>
</ul>
</section>
<section id="textbooks">
<h3>Textbooks<a class="headerlink" href="#textbooks" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Kernel Methods for Digital Processing - <a class="reference external" href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118705810">Book</a></p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/notes/kernels"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="congruence_coeff.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Congruence Coefficient</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="mmd.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Maximum Mean Discrepancy (MMD)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By J. Emmanuel Johnson<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>