
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Gaussian Processes &#8212; Research Notebook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/notes/gps/intro';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Basics" href="gps.html" />
    <link rel="prev" title="Maximum Mean Discrepancy (MMD)" href="../kernels/mmd.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../intro.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../resources/python/overview.html">
                        Python
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/jax_journey/overview.html">
                        My JAX Journey
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/remote/overview.html">
                        Remote Computing
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../gmt/overview.html">
                        GMT of Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../concepts/uncertainty.html">
                        Modeling Uncertainty
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../bayesian/overview.html">
                        Bayesian
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../concepts/overview.html">
                        Sleeper Concepts
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../kernels/overview.html">
                        Kernel Methods
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Gaussian Processes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../info_theory/similarity.html">
                        Similarity
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../info_theory/overview.html">
                        Information Theory
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../normalizing_flows/overview.html">
                        Normalizing Flows
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../inr/overview.html">
                        Implicit Neural Representations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../data_assimilation/overview.html">
                        Data Assimilation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../misc/overview.html">
                        Miscellaneous Notes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cheatsheets/bash.html">
                        Bash
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cheatsheets/cli.html">
                        Command Line
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cheatsheets/python.html">
                        Python
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../resources/python/overview.html">
                        Python
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/jax_journey/overview.html">
                        My JAX Journey
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../tutorials/remote/overview.html">
                        Remote Computing
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../gmt/overview.html">
                        GMT of Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../concepts/uncertainty.html">
                        Modeling Uncertainty
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../bayesian/overview.html">
                        Bayesian
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../concepts/overview.html">
                        Sleeper Concepts
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../kernels/overview.html">
                        Kernel Methods
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Gaussian Processes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../info_theory/similarity.html">
                        Similarity
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../info_theory/overview.html">
                        Information Theory
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../normalizing_flows/overview.html">
                        Normalizing Flows
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../inr/overview.html">
                        Implicit Neural Representations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../data_assimilation/overview.html">
                        Data Assimilation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../misc/overview.html">
                        Miscellaneous Notes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cheatsheets/bash.html">
                        Bash
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cheatsheets/cli.html">
                        Command Line
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cheatsheets/python.html">
                        Python
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../../../intro.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../resources/python/overview.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/ides.html">Integraded Development Environment (IDE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/stack.html">Standard Python Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/earthsci_stack.html">Earth Science Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/dl_stack.html">Deep Learning Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/scale_stack.html">Scaling Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/good_code.html">Good Code</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/jax_journey/overview.html">My JAX Journey</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">Ecosystem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/vmap.html">vmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/jit.html">Jit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/classes.html">Classes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">Bisection search</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/gfs_with_jax.html">Gaussianization Flows</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/remote/overview.html">Remote Computing</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/ssh.html">SSH Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/conda.html">Conda 4 Remote Servers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/jlab.html">Jupyter Lab 4 Remote Servers</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../gmt/overview.html">GMT of Learning</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gmt/hierarchical_rep.html">Hierarchical Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/functa.html">Functa</a></li>








<li class="toctree-l2"><a class="reference internal" href="../gmt/discretization.html">Discretization</a></li>



<li class="toctree-l2"><a class="reference internal" href="../gmt/learning.html">Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../concepts/uncertainty.html">Modeling Uncertainty</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bayesian/overview.html">Bayesian</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/intro.html">Language of Uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/models.html">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference.html">Inference Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/variational_inference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/cond_vi.html">Conditional Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/confidence_intervals.html">Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/regression.html">Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../concepts/overview.html">Sleeper Concepts</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../concepts/gaussian.html">Gaussian Distributions</a></li>

<li class="toctree-l2"><a class="reference internal" href="../concepts/change_of_variables.html">Change of Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/identity_trick.html">Identity Trick</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/inverse_function.html">Inverse Function Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/jensens.html">Jensens Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/lin_alg.html">Linear Algebra Tricks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kernels/overview.html">Kernel Methods</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../kernels/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/rv.html">RV Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/congruence_coeff.html">Congruence Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/hsic.html">HSIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/mmd.html">Maximum Mean Discrepancy (MMD)</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Gaussian Processes</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="gps.html">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="literature.html">Literature Review</a></li>
<li class="toctree-l2"><a class="reference internal" href="cg.html">Conjugate Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="sgps.html">Sparse Gaussian Processes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="gpr_code.html">GP from Scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="sgp_code.html">Sparse GP From Scratch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../egps/overview.html">Input Uncertainty in GPs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../info_theory/similarity.html">Similarity</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../info_theory/overview.html">Information Theory</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/measures.html">Measures</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/information.html">Information Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/entropy.html">Entropy &amp; Relative Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/mutual_info.html">Mutual Information and Total Correlation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/estimators.html">Information Theory Measures</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/classic.html">Classic Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/histogram.html">Entropy Estimator - Histogram</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">Experiment - RBIG Sample Consistency</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../normalizing_flows/overview.html">Normalizing Flows</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/linear.html">Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/coupling_layers.html">Coupling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/conditional.html">Conditional Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/multiscale.html">Multiscale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/inverse.html">Minimization Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/losses.html">Losses</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_1_ig.html">Lecture I - Iterative Gaussianization</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.0_univariate_gauss.html">1.1 - Univariate Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.1_marginal_gauss.html">1.2 - Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.2_gaussianization.html">1.2 - Iterative Gaussianization</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_2_gf.html">Lecture II - Gaussianization Flows</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt1_mg.html">Parameterized Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt2_rot.html">Parameterized Rotations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt3_plane.html">Example - 2D Plane</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inr/overview.html">Implicit Neural Representations</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../inr/formulation.html">Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inr/literature_review.html">Literature Review</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../inr/pinns.html">Physics-Informed Loss</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../inr/qg.html">QG PDE</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_assimilation/overview.html">Data Assimilation</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/dynamical_sys.html">Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/oi.html">Optimal Interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/interp.html">Interpolation Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/emu.html">Emulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/inv_problems.html">Inverse Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/projects.html">Projects</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../data_assimilation/algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/markov_models.html">Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/gauss_markov.html">Gauss-Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/kf.html">Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/nkf.html">Normalizing Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/enskf.html">Ensemble Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/dmm.html">Deep Markov Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/4dvarnet.html">4DVarNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/markov_gp.html">Markovian Gaussian Processes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../data_assimilation/nbs/notebooks.html">Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../misc/overview.html">Miscellaneous Notes</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../misc/generative_models.html">Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diffusion_models.html">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/fixed_point.html">Fixed-Point Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/bilevel_opt.html">Bi-Level Optimization</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cheat Sheets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/bash.html">Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/cli.html">Command Line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/python.html">Python</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/jejjohnson/research_notebook" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/gps/intro.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../../../_sources/content/notes/gps/intro.md" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Gaussian Processes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objective">
   Objective
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quantities-of-interest">
   Quantities of Interest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Gaussian Processes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-setting">
   Problem Setting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-assumptions">
   Model Assumptions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exact-gp-inference">
     Exact GP Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimal-solution">
     Optimal Solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bottleneck">
   Bottleneck
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predictive-uncertainty">
     Predictive Uncertainty
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conditional-sampling">
     Conditional Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling">
   Scaling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ski-inference">
     SKI Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivations">
     Derivations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#predictive-mean">
       Predictive Mean
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression">
   Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-process">
     Gaussian Process
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference">
     Inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-functions">
   Kernel Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strengths-and-limitations">
   Strengths and Limitations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations">
     Limitations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conjugate-case">
   Conjugate Case
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-conjugate-case">
   Non-Conjugate Case
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section id="gaussian-processes">
<h1>Gaussian Processes<a class="headerlink" href="#gaussian-processes" title="Permalink to this heading">#</a></h1>
<hr class="docutils" />
<section id="objective">
<h2>Objective<a class="headerlink" href="#objective" title="Permalink to this heading">#</a></h2>
<p>We have a set of sparsely distributed observations from satellite altimetry data. For each observation, there is an associated latitude and longitude spatial coordinate as well as a temporal coordinate. The objective is to interpolate the missing observations for the remaining spatio-temporal coordinates.</p>
</section>
<hr class="docutils" />
<section id="quantities-of-interest">
<h2>Quantities of Interest<a class="headerlink" href="#quantities-of-interest" title="Permalink to this heading">#</a></h2>
<p><strong>Inputs</strong>: We assume that the inputs are a vector of coordinates: latitude, longitude and time, i.e. $\mathbf{x} = [\text{lat, lon, time}]$. So a single data point is a 3-dimensional vector, $\mathbf{x}\in \mathbb{R}^{D_\phi}$. It is important to note that we are free to do any coordinate transform that we want in order to better represent the data. For example, the temporal coordinates can be converted to spherical coordinates to represent the curvature of the earth. Another example is to convert the temporal coordinates into cyclic coordinates where each hour, day, month, year, etc are converted into a sine and cosine. We will see later that this can be encoded within the kernel function for the Gaussian process which will allow us to capture the assumed dynamics. However, many times physical knowledge of your system can be encoded a priori which can lead to better results.</p>
<p><strong>Outputs</strong>: The outputs are a vector of quantities of interest. For example, we could have a variable which describes the state of the ocean such as sea surface height (SSH) and or sea surface temperature (SST). These variables are then stacked together which gives us a p-dimensional vector, $\mathbf{y} \in \mathbb{R}^{D_p}$.</p>
</section>
<hr class="docutils" />
<section id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this heading">#</a></h2>
<p>We assume that we have some set of input and output data points, $\mathcal{D} = \left{ \mathbf{x}_n, \mathbf{y}<em>n \right}</em>{n=1}^N$. This dataset, $\mathcal{D}$, will be used for training to find the parameters of interest, $\boldsymbol{\theta}$.</p>
</section>
<hr class="docutils" />
<section id="id1">
<h2>Gaussian Processes<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
</section>
<hr class="docutils" />
<section id="problem-setting">
<h2>Problem Setting<a class="headerlink" href="#problem-setting" title="Permalink to this heading">#</a></h2>
<p>We are interested in the regression problem where we have some quantity of interest, $\mathbf{y}$, given some inputs, $\mathbf{x}$. We also assume that there exists some function, $\boldsymbol{f}$, parameterized by, $\boldsymbol{\theta}$, that provides us with a mapping between the inputs, $\mathbf{x}$, and the outputs, $\mathbf{y}$. And lastly, we assume that it is corrupted by some identically independently distributed noise, i.e. Gaussian noise. This can be written as:</p>
<p>$$
\mathbf{y}_n = \boldsymbol{f}(\mathbf{x}_n; \boldsymbol{\theta}) + \boldsymbol{\epsilon}_n, \hspace{10mm} \boldsymbol{\epsilon} \sim \mathcal{N}(0, \sigma^2)
$$</p>
<p>We are interested in finding a distribution over the functions, $\boldsymbol{f}$, that can explain the data, ${\mathbf{x},\mathbf{y}}$. In other words, we are not interested in the best set of parameters, $\boldsymbol{\theta}$ that give us the best fit. Instead we want the best set of parameters, $\boldsymbol{\theta}$, which will give us a distribution of functions, $\boldsymbol{f} \sim P$ that could possibly describe the data.</p>
</section>
<hr class="docutils" />
<section id="model-assumptions">
<h2>Model Assumptions<a class="headerlink" href="#model-assumptions" title="Permalink to this heading">#</a></h2>
<p>We follow the Bayesian formulation but in functional space. Bayes formula can be written as follows:</p>
<p>$$
p(\boldsymbol{f}(\cdot) | \mathbf{X,Y}) = \frac{p(\mathbf{y}|\boldsymbol{f}(\cdot));p(\boldsymbol{f}(\cdot))}{p(\mathbf{Y}|\mathbf{X})}
$$</p>
<p><strong>Prior</strong></p>
<p>The prior, $p(\boldsymbol{f}(\cdot))$ is a Gaussian process prior which is specified by its mean function, $\boldsymbol{m}$, and covariance function, $\boldsymbol{k}$. So we have</p>
<p>$$
\boldsymbol{f}(\mathbf{x}) \sim \mathcal{GP}\left(\boldsymbol{f} | \boldsymbol{m}<em>\psi (\mathbf{x}), \boldsymbol{k}</em>\phi(\mathbf{x},\mathbf{x}’)\right)
$$</p>
<p><strong>Prior Parameters</strong></p>
<p>The mean function, $\boldsymbol{m}$, is a mapping from the coordinates, $\mathbf{x}$, to the coordinates of interest, $\mathbf{y}$. It represents our prior knowledge of the relationship. This is often assumed to be zero if we don’t have any prior knowledge. However, it can be a parameterized by some hyper-parameters, $\boldsymbol{\psi}$, which can also be learned through the Gaussian process regression algorithm. The kernel function, $\boldsymbol{k} : \mathbb{R}^{D_\phi} \times \mathbb{R}^{D_\phi} \rightarrow \mathbb{R}^{}$ is a mapping representing the correlations between all of the inputs. This is also has some set of parameters, $\boldsymbol{\phi}$, which are very important. It represents the correlations is the mean function and $\mathbf{K}$ is the kernel matrix.</p>
<p><strong>Likelihood</strong></p>
<p>This is the noise model which is assumed to be a Gaussian.</p>
<p>$$
p(\mathbf{y}|\boldsymbol{f}(\mathbf{X})) = \mathcal{N}(\boldsymbol{f}(\mathbf{X}), \sigma^2 \mathbf{I})
$$</p>
<p>The advantage of this assumption is that it allows us to have keep everything Gaussian because the both the prior and the likelihood are Gaussian distributed. However, many times there is no reason to believe that the likelihood is Gaussian. For example we could have a noise model which is dependent upon the observations or we could have a classification or Log-Cox process scenario whereby we would need a Bernoulli or Poisson distribution respectively. Nevertheless, non-Gaussian likelihoods are out of scope for this work.</p>
<p><strong>Marginal Likelihood</strong></p>
<p>The marginal likelihood is typically the most difficult quantity to calculate.</p>
<p>$$
p(\mathbf{y}|\mathbf{X},\boldsymbol{\theta}) = \int_{\boldsymbol{f}}p(\mathbf{y}|\boldsymbol{f})p(\boldsymbol{f}|\mathbf{X},\boldsymbol{\theta}) d\boldsymbol{f}
$$</p>
<p>Because the prior, likelihood are Gaussian, we can utilize the conjugacy property which ensures that the marginal likelihood is also Gaussian distributed. So this integral becomes simple because we can calculate this quantity analytically. The formula is given by:</p>
<p>$$
p(\mathbf{y}|\mathbf{X},\boldsymbol{\theta}) = \mathcal{N}\left(\mathbf{y}|\boldsymbol{m}(\mathbf{X}), \mathbf{K}_{\mathbf{XX}} + \sigma^2\mathbf{I}\right)
$$</p>
<p><strong>Posterior</strong></p>
<p>The posterior of a Gaussian Process is also a Gaussian process which is normally distributed given predictive mean and predictive covariance.</p>
<p>$$
p(\boldsymbol{f}(\mathbf{x})|\mathcal{D}) = \mathcal{N}\left(\boldsymbol{\mu}<em>{\mathcal{GP}}(\mathbf{x}), \boldsymbol{\sigma}^2</em>\mathcal{GP}(\mathbf{x}, \mathbf{x}’)\right)
$$</p>
<p>where we have the analytical formulas for the predictive mean and covariance:</p>
<p>$$
\begin{aligned}
\boldsymbol{\mu}<em>{\mathcal{GP}}(\mathbf{x}) &amp;= \boldsymbol{m}(\mathbf{x}) + \boldsymbol{k}</em>\mathbf{X}(\mathbf{x}) \boldsymbol{\alpha} \
\boldsymbol{\sigma}^2_\mathcal{GP}(\mathbf{x}, \mathbf{x}’) &amp;= \boldsymbol{k}(\mathbf{x}, \mathbf{x}’) + \boldsymbol{k}<em>\mathbf{X}(\mathbf{x})\left( \mathbf{K}</em>{\mathbf{XX}} + \sigma^2\mathbf{I} \right)^{-1}\boldsymbol{k}_\mathbf{X}(\mathbf{x})^\top
\end{aligned}
$$</p>
<hr class="docutils" />
<p><strong>Predictive Density</strong></p>
<p>$$
p(\boldsymbol{f}_*|\boldsymbol{f})
$$</p>
<p>Because the prior, likelihood, and the marginal likelihood are all Gaussian, we have a predictive density that is characterized as a multivariate Gaussian distribution.</p>
<p>$$
p(\boldsymbol{f}(\mathbf{x}<em>*)|\mathcal{D}) = \mathcal{N}\left(\boldsymbol{\mu}</em>{\mathcal{GP}}(\mathbf{x}<em>*), \boldsymbol{\sigma}^2</em>\mathcal{GP}(\mathbf{x}<em>*, \mathbf{x}</em>{*}’)\right)
$$</p>
<p>where we have the predictive mean and covariance:</p>
<p>$$
\begin{aligned}
\boldsymbol{\mu}<em>{\mathcal{GP}}(\mathbf{x}</em><em>) &amp;= \boldsymbol{m}(\mathbf{x}_</em>) + \boldsymbol{k}<em>*(\mathbf{x}</em><em>) \boldsymbol{\alpha} \
\boldsymbol{\sigma}^2_\mathcal{GP}(\mathbf{x}_</em>, \mathbf{x}<em>{*}’) &amp;= \boldsymbol{k}(\mathbf{x}</em><em>, \mathbf{x}_{</em>}’) + \boldsymbol{k}<em>\mathbf{X}(\mathbf{x}</em><em>)\left( \mathbf{K}<em>{\mathbf{XX}} + \sigma^2\mathbf{I} \right)^{-1}\boldsymbol{k}</em>\mathbf{X}(\mathbf{x}_</em>)^\top
\end{aligned}
$$</p>
<p>where $\boldsymbol{\alpha} = \left( \mathbf{K}_{\mathbf{XX}} + \sigma^2\mathbf{I} \right)^{-1}(\mathbf{y} - \boldsymbol{m}(\mathbf{X}))$ is a fixed parameter that can be trained via some inference method, e.g. Maximum Likelihood, Maximum A Posteriori, Variational Inference, MCMC, etc.</p>
</section>
<hr class="docutils" />
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this heading">#</a></h2>
<p>As is very typically in the Bayesian formulation, we can maximize the m
$$
\boldsymbol{\theta}^* = \argmin_{\boldsymbol{\theta}} - \mathcal{L}(\boldsymbol{\theta})
$$</p>
<p>$$
\mathcal{L}(\boldsymbol{\theta}) := \log p(\mathbf{y}|\mathbf{X}, \boldsymbol{\theta})
$$</p>
<section id="exact-gp-inference">
<h3>Exact GP Inference<a class="headerlink" href="#exact-gp-inference" title="Permalink to this heading">#</a></h3>
<p>$$
\log p(\mathbf{y}|\mathbf{X}, \boldsymbol{\theta}) = - \frac{N}{2} \log 2 \pi - \frac{1}{2} \log |\mathbf{K}<em>{\mathbf{XX}} + \sigma^2\mathbf{I}| - \frac{1}{2} (\mathbf{y} - \boldsymbol{m}(\mathbf{X}))^\top\left( \mathbf{K}</em>{\mathbf{XX}} + \sigma^2\mathbf{I} \right)^{-1}(\mathbf{y} - \boldsymbol{m}(\mathbf{X}))
$$</p>
<p>We introduce some new notation to simplify the equations a little bit.</p>
<p>$$
\mathbf{K}<em>{\boldsymbol{\phi}} := \mathbf{K</em>{XX}} + \sigma^2\mathbf{I}
$$</p>
<p>$$
\bar{\mathbf{Y}}_{\boldsymbol{\psi}} := \mathbf{Y} - \boldsymbol{m}(\mathbf{X};\boldsymbol{\psi})
$$</p>
<p>We can rewrite the cost function to reflect the new notation.</p>
<p>$$
\log p(\mathbf{y}|\mathbf{X}, \boldsymbol{\theta}) = - \frac{N}{2} \log 2 \pi - \frac{1}{2} \log |\mathbf{K}<em>{\boldsymbol{\phi}}| - \frac{1}{2} \bar{\mathbf{Y}}</em>{\boldsymbol{\psi}}^\top;\mathbf{K}<em>{\boldsymbol{\phi}}^{-1};\bar{\mathbf{Y}}</em>{\boldsymbol{\psi}}
$$</p>
<p>where the parameters are the hyper-parameters of the mean function, the noise likelihood and the kernel function respectively. $\boldsymbol{\theta} = \left{ \boldsymbol{\psi}, \sigma, \boldsymbol{\phi} \right}$.</p>
</section>
<section id="optimal-solution">
<h3>Optimal Solution<a class="headerlink" href="#optimal-solution" title="Permalink to this heading">#</a></h3>
<p>$$
\boldsymbol{\alpha} := (\mathbf{K_{XX}} + \sigma^2\mathbf{I})^{-1}(\mathbf{Y} - \boldsymbol{m}(\mathbf{X}))
$$</p>
</section>
</section>
<hr class="docutils" />
<section id="bottleneck">
<h2>Bottleneck<a class="headerlink" href="#bottleneck" title="Permalink to this heading">#</a></h2>
<p><strong>Training</strong></p>
<p>$$
\mathcal{O}(N^3)
$$</p>
<p><strong>Testing</strong></p>
<p>$$
\mathcal{O}(N^2)
$$</p>
<hr class="docutils" />
<section id="predictive-uncertainty">
<h3>Predictive Uncertainty<a class="headerlink" href="#predictive-uncertainty" title="Permalink to this heading">#</a></h3>
</section>
<hr class="docutils" />
<section id="conditional-sampling">
<h3>Conditional Sampling<a class="headerlink" href="#conditional-sampling" title="Permalink to this heading">#</a></h3>
</section>
</section>
<hr class="docutils" />
<section id="scaling">
<h2>Scaling<a class="headerlink" href="#scaling" title="Permalink to this heading">#</a></h2>
<section id="ski-inference">
<h3>SKI Inference<a class="headerlink" href="#ski-inference" title="Permalink to this heading">#</a></h3>
<p>$$
\log p(\mathbf{y}|\mathbf{X},\boldsymbol{\theta}) \approx - \frac{1}{2} \log \left|\det \tilde{\mathbf{K}}<em>{\mathbf{XX}} + \sigma^2 \mathbf{I}\right| - \frac{1}{2}(\mathbf{y} - \boldsymbol{m}(\mathbf{X}))\left( \tilde{\mathbf{K}}</em>{\mathbf{XX}} + \sigma^2 \mathbf{I} \right)^{-1} -\frac{N}{2} \log 2\pi
$$</p>
</section>
<section id="derivations">
<h3>Derivations<a class="headerlink" href="#derivations" title="Permalink to this heading">#</a></h3>
<section id="predictive-mean">
<h4>Predictive Mean<a class="headerlink" href="#predictive-mean" title="Permalink to this heading">#</a></h4>
<p>$$
\begin{aligned}
\boldsymbol{\mu}<em>{\text{KISS-GP}}(\mathbf{x}</em><em>) &amp;= \boldsymbol{w}(\mathbf{x}_</em>)^\top \mathbf{K_{UU}} \mathbf{}
\end{aligned}
$$</p>
<hr class="docutils" />
<p><strong>Training</strong></p>
<ul class="simple">
<li><p>(Naive) Exact GP - $\mathcal{O}(N^3)$</p></li>
<li><p>Conjugate Gradient - $\mathcal{O}(N^2)$</p></li>
<li><p>KISS-GP - $\approx\mathcal{O}(N)$</p></li>
<li><p>Inducing Points - $\mathcal{O}(NM^3)$</p></li>
<li><p>Variational Stochastic - $\mathcal{O}(M^3)$</p></li>
</ul>
<p><strong>Predictions</strong></p>
<ul class="simple">
<li><p>(Naive) Exact GP - $\mathcal{O}(N^2)$</p></li>
<li><p>Conjugate Gradient - $\mathcal{O}(N)$</p></li>
<li><p>KISS-GP - $\approx\mathcal{O}(N)$</p></li>
<li><p>Inducing Points - $\mathcal{O}(NM^2)$</p></li>
<li><p>Variational Stochastic - $\mathcal{O}(M^2)$</p></li>
</ul>
</section>
</section>
</section>
<section id="regression">
<h2>Regression<a class="headerlink" href="#regression" title="Permalink to this heading">#</a></h2>
<p>Let’s assume we have $N$ input data points with $D$ dimensions, $\mathbf{X} = {\mathbf{x}<em>i}^N</em>{i=1} \in \mathbb{R}^{N \times D}$ and noisy outputs, $\mathbf{y} = { y_i }^{N}<em>{i=1} \in \mathbb{R}^{N}$. We want to compute the predictive distribution of $y</em><em>$ at a test location $\mathbf{x}_</em>$. So:</p>
<p>$$
y_i = f(\mathbf{x}_i) + \epsilon_i
$$</p>
<p>where $f$ is an unknown latent function that is corrupted by Gaussian observation noise $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$.</p>
<section id="gaussian-process">
<h3>Gaussian Process<a class="headerlink" href="#gaussian-process" title="Permalink to this heading">#</a></h3>
<p>A Gaussian process is a probability distribution over functions. It places a non-parametric Bayesian model which places a GP prior over a latent function $f$ as</p>
<p>$$
f(\mathbf{x}) \sim \mathcal{GP}\left( m(\mathbf{x}), k(\mathbf{x},\mathbf{x}’) \right).
$$</p>
<p>where we see it is characterized by a mean function, $m(\mathbf{x})$ and kernel function $k(\mathbf{x,x}’)$:</p>
<p>$$
\begin{aligned}
m(\mathbf{x}) &amp;= \mathbb{E}[f(\mathbf{x})] \
k(\mathbf{x,x}’) &amp;= \mathbb{E}\left[ (f(\mathbf{x}) - m(\mathbf{x}))(f(\mathbf{x}’) - m(\mathbf{x}))  \right]
\end{aligned}
$$</p>
<p>The mean function $m(\mathbf{x})$ is typically zero (for easier computations) and the kernel function typically characterizes the smoothness, scale and … of the GP. Given the training data $\mathcal{D}={\mathbf{X},\mathbf{y}}$,</p>
<p>mean function GP prior, $m_\mathcal{GP}$, (typically zero) and a covariance function $k(\mathbf{x}, \mathbf{x}’)$ on $f$.</p>
<p><strong>Prior</strong></p>
<p><strong>Likelihood</strong> A GP regression model assumes that the outputs can be modeled as</p>
<p>$$
p(\mathbf{y}|f, \mathbf{X}) \sim \mathcal{N}(y|f, \sigma_y^2\mathbf{I})
$$</p>
<p><strong>Posterior</strong></p>
<hr class="docutils" />
<p>We can obtain a marginal likelihood (model evidence) since any finite set of GPs follows a multivariate Gaussian distribution</p>
<p>$$
p(\mathbf{y}|\theta) = \int p(\mathbf{y}|f)p(f)df = \mathcal{N}(\mathbf{y}|m_\phi, \mathbf{K}_{GP})
$$</p>
<p>In the simple model (conjugate case due to the Gaussian likelihood), the posterior over $f, p(f|y)$ can be computed analytically.</p>
<p>$$
p(\mathbf{y}|\theta) = \mathcal{N}(\mathbf{y}|m_\phi, \mathbf{K}_{GP})
$$</p>
<p>where $\mathbf{K}<em>{GP}=\mathbf{K}</em>{ff}+ \sigma^2 \mathbf{I}$ and $\theta$ comprises of the hyperparameters found on the mean function and covariance function. We would then maximize the hyperparameters $\theta$ via, log marginal-likelihood (see below).</p>
<p>The prediction of $y_<em>$ for a test point $\mathbf{x}_</em>$ is what we’re really interested in. We can consider the joint distribution of our training data, $\mathbf{y}$ and test data, $y_*$:</p>
<p>$$
\begin{bmatrix}
\mathbf{y} \
y_*
\end{bmatrix} \sim
\mathcal{N}\left(
\begin{bmatrix}
\mathbf{K}<em>{GP} &amp; k</em><em>^\top\
k_</em> &amp; k_{**}+\sigma^2
\end{bmatrix}   \right)
$$</p>
<p>$k_{<em>}=\left[ k(\mathbf{x}<em>1, \mathbf{x}</em></em>), \ldots, k(\mathbf{x}<em>N, \mathbf{x}</em><em>)  \right]^\top$ is the projection kernel and $k_{**}=k(\mathbf{x}_</em>, \mathbf{x}<em>*)$ is the test kernel. By way of normally distributed variables, we can obtain the predictive distribution of $y</em>*$ conditioned on the training data $\mathbf{y}$:</p>
<p>$$
p(y_*|\mathbf{y}) = \mathcal{N}(\mu_\mathcal{GP}, \sigma^2_\mathcal{GP})
$$</p>
<p>and subsequently closed-form predictive mean and variance equations:</p>
<p>$$
\begin{aligned}
\mu_\mathcal{GP}(\mathbf{x}<em>*) &amp;= k</em>{<em>}^\top \mathbf{K}<em>{GP}^{-1} \mathbf{y} = k</em>{</em>}^\top \alpha  \
\sigma^2_\mathcal{GP}(\mathbf{x}<em>*) &amp;= \sigma^2 + k</em>{**} - k_{<em>}^\top \mathbf{K}<em>{GP}^{-1}k</em>{</em>}
\end{aligned}
$$</p>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this heading">#</a></h3>
<p>The covariance function $k(\mathbf{x}, \mathbf{x}
)$ depends on hyperparameters are usually learned by maximizing the log marginal likelihood.</p>
<p>$$
\theta^* = \underset{\theta}{\text{argmax}} \log p(\mathbf{y}|\mathbf{X},\theta) = \log \mathcal{N}(\mathbf{y}; 0, \mathbf{K}_\mathcal{GP})
$$</p>
<p>Using the log pdf of a multivariate distribution, we have</p>
<p>$$
\begin{aligned}
\log \mathcal{N}(\mathbf{y}; 0, \mathbf{K}<em>\mathcal{GP}) &amp;= - \frac{1}{2} \mathbf{y}^\top \mathbf{K}</em>\mathcal{GP}^{-1}\mathbf{y} - \frac{1}{2} \log \left| \mathbf{K}_\mathcal{GP} \right| - \frac{N}{2} \log 2 \pi
\end{aligned}
$$</p>
<p>This optimization is done by differentiating the above equation with respect to the hyperparameters. This maximization automatically embodies Occam’s razor as it is a trade-off between the model complexity and overfitting. Typically we do the Cholesky decomposition to efficiently calculate the inversion and determinant measures.</p>
<p>$$
\begin{aligned}
\log p(\mathbf{y}) &amp;= - \frac{1}{2} \mathbf{y}^\top \mathbf{K}<em>\mathcal{GP}^{-1}\mathbf{y} - \frac{1}{2} \log \left| \mathbf{K}</em>\mathcal{GP} \right| - \frac{N}{2} \log 2 \pi \
&amp;= -\frac{1}{2} ||\mathbf{L}^{-1}\mathbf{y}||^2  - \sum_i\log \mathbf{L}_{ii} - \frac{N}{2} \log 2 \pi
\end{aligned}
$$</p>
<p>where the $\mathbf{L}$ is the Cholesky decomposition $\mathbf{L}= \text{chol}(\mathbf{K}_\mathcal{GP})$. This gives us a computational complexity of $\mathcal{O}(N^3 + N^2 + N)$ which is overal $\mathcal{O}(N^3)$. So this GPR method is really only suited for ~2K-5K problems maximum.</p>
</section>
</section>
<hr class="docutils" />
<section id="kernel-functions">
<h2>Kernel Functions<a class="headerlink" href="#kernel-functions" title="Permalink to this heading">#</a></h2>
<p><strong>Composition Kernels</strong>. Kernels can be combined using sums and products to obtain more expressive formations. Additive kernels (<strong>cite</strong>: Duvenaud)</p>
<p><strong>Input Warping</strong>. This is also the choice for many kernel methods where another model is used instead.</p>
</section>
<hr class="docutils" />
<section id="strengths-and-limitations">
<h2>Strengths and Limitations<a class="headerlink" href="#strengths-and-limitations" title="Permalink to this heading">#</a></h2>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this heading">#</a></h3>
<blockquote class="epigraph">
<div><p>“It is important to keep in mind that Gaussian processes are not appropriate priors for all problems”.</p>
<p class="attribution">—Neal, 1998</p>
</div></blockquote>
<p>It is important to note that although the GP algorithm is one of the most trusted and reliable algorithms, it is not always the best algorithm to use for all problems. Below we mention a few drawbacks that the standard GP algorithm has along with some of the standard approaches to overcoming these drawbacks.</p>
<p><strong>Gaussian Marginals</strong>: GPs have problems modeling heavy-tailed, asymmetric or multi-modal marginal distributions. There are some methods that change the likelihood so that it is heavy tailed~\citep{GPTSTUDENT2011,GPTSTUDENT2014} but this would remove the conjugacy of the likelihood term which would incur difficulties during fitting. Deep GPs and latent covariate models are an improvement to this limitation. A very popular approach is to construct a fully Bayesian model. This entails hyperpriors over the kernel parameters and Monte carlo sampling methods such as Gibbs sampling~\citep{GPGIBBS08}, slice sampling~\citep{GPSLICE2010}, Hamiltonian Monte Carlo~\citep{GPHMC2018}, and Sequential Monte Carlo~\citep{GPSMC15}. These techniques will capture more complex distributions. With the advent of better software~\citep{PYMC16,NUMPYRO2019} and more advanced sampling techniques like a differentiable iterative NUTS implementation~\citep{NUMPYRO2019}, the usefulness of MC schemes is resurfacing.</p>
<p><strong>Limited Number of Moments</strong>. This is related to the previous limitation: the idea that an entire function can be captured in terms of two moments: a mean and a covariance. There are some relationships which are difficult to capture without an adequate description, e.g. discontinuities~\citep{Neal96} and non-stationary processes, and thus is a limitation of the GP priors we choose. The advent of warping the inputs or outputs of a GP has becoming a very popular technique to deal with the limited expressivity of kernels. Input warping is popular in methods such as deep kernel learning whereby a Neural network is used to capture the features and are used as inputs to the kernel function output warping is common in chained~\citep{GPCHAINED2016} and heteroscedastic methods where the function output is warped by another GP to capture the noise model of the data. Deep Gaussian processes~\citep{Damianou2015} can be thought of input and output warping methods due the multi-layer composition of function inputs and outputs.</p>
<p><strong>Linearity of Predictive Mean</strong>. The predictive mean of a GP is linear to the observations, i.e. $\mu_{GP}=\mathbf{K}\alpha$. This essentially is a smoother which can be very powerful but also will miss key features. If there is some complex structured embedded within the dataset, then a GP model can never really capture this irregardless of the covariance function found.</p>
<p><strong>Predictive Covariance</strong>. The GP predictive variance is a function of the training inputs and it is independent of the observed inputs. This is important if the input data has some information which could be used to help determine the regions of uncertainty, e.g. the gradient. An example would be data on a spatial grid whereby some regions points would have more certainty than others which could be obtained by knowing the input location and not necessarily the expected output.</p>
</section>
</section>
<section id="conjugate-case">
<h2>Conjugate Case<a class="headerlink" href="#conjugate-case" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<section id="id2">
<h3>Inference<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>After specifying the prior distributions, we need to infer the posterior distributions of the parameters $\theta,\phi,f$.</p>
<p>We represent this as the</p>
<p>We can optimize this function using the negative log-likelihood of $\mathbf{y}$:</p>
<p>$$
\mathcal{L}(\Theta) = \frac{1}{2} \left| \mathbf{K}_\mathcal{GP}+ \sigma^2 \mathbf{I} \right| + \frac{1}{2}\mathbf{y}^\top
$$</p>
</section>
</section>
<section id="non-conjugate-case">
<h2>Non-Conjugate Case<a class="headerlink" href="#non-conjugate-case" title="Permalink to this heading">#</a></h2>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/notes/gps"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="../kernels/mmd.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Maximum Mean Discrepancy (MMD)</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="gps.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Basics</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objective">
   Objective
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quantities-of-interest">
   Quantities of Interest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Gaussian Processes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-setting">
   Problem Setting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-assumptions">
   Model Assumptions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exact-gp-inference">
     Exact GP Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimal-solution">
     Optimal Solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bottleneck">
   Bottleneck
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predictive-uncertainty">
     Predictive Uncertainty
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conditional-sampling">
     Conditional Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling">
   Scaling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ski-inference">
     SKI Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivations">
     Derivations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#predictive-mean">
       Predictive Mean
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression">
   Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-process">
     Gaussian Process
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference">
     Inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-functions">
   Kernel Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strengths-and-limitations">
   Strengths and Limitations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations">
     Limitations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conjugate-case">
   Conjugate Case
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-conjugate-case">
   Non-Conjugate Case
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By J. Emmanuel Johnson
</p>

  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2023.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>