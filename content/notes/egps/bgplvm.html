

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Bayesian GPLVM &#8212; Research Notebook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/notes/egps/bgplvm';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/book_v2.jpeg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/book_v2.jpeg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../resources/python/overview.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/ides.html">Integraded Development Environment (IDE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/stack.html">Standard Python Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/earthsci_stack.html">Earth Science Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/dl_stack.html">Deep Learning Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/scale_stack.html">Scaling Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../resources/python/good_code.html">Good Code</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/jax_journey/overview.html">My JAX Journey</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">Ecosystem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/vmap.html">vmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/jit.html">Jit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/jax_journey/classes.html">Classes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">Bisection search</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/jax_journey/gfs_with_jax.html">Gaussianization Flows</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/twelve_steps_ns/overview.html">12 Steps to Navier-Stokes</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/twelve_steps_ns/1.1_linear_advection.html">1D Linear Convection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/remote/overview.html">Remote Computing</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/ssh.html">SSH Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/conda.html">Conda 4 Remote Servers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/remote/jlab.html">Jupyter Lab 4 Remote Servers</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../gmt/overview.html">GMT of Learning</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gmt/hierarchical_rep.html">Hierarchical Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/functa.html">Functa</a></li>








<li class="toctree-l2"><a class="reference internal" href="../gmt/discretize_space.html">Spatial Discretization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gmt/discretize_time.html">Temporal Discretization</a></li>


<li class="toctree-l2"><a class="reference internal" href="../gmt/learning.html">Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../concepts/uncertainty.html">Modeling Uncertainty</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bayesian/overview.html">Bayesian</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/intro.html">Language of Uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/models.html">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference.html">Inference Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/variational_inference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/inference/cond_vi.html">Conditional Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/confidence_intervals.html">Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bayesian/regression.html">Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../concepts/overview.html">Sleeper Concepts</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../concepts/gaussian.html">Gaussian Distributions</a></li>

<li class="toctree-l2"><a class="reference internal" href="../concepts/change_of_variables.html">Change of Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/identity_trick.html">Identity Trick</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/inverse_function.html">Inverse Function Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/jensens.html">Jensens Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/lin_alg.html">Linear Algebra Tricks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kernels/overview.html">Kernel Methods</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../kernels/kernel_derivatives.html">Kernel Derivatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/rv.html">RV Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/congruence_coeff.html">Congruence Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/hsic.html">HSIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernels/mmd.html">Maximum Mean Discrepancy (MMD)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gps/intro.html">Gaussian Processes</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gps/gps.html">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/literature.html">Literature Review</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/cg.html">Conjugate Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gps/sgps.html">Sparse Gaussian Processes</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../gps/algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../gps/gpr_code.html">GP from Scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gps/sgp_code.html">Sparse GP From Scratch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="overview.html">Input Uncertainty in GPs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../info_theory/similarity.html">Similarity</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../info_theory/overview.html">Information Theory</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/measures.html">Measures</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/information.html">Information Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/entropy.html">Entropy &amp; Relative Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/mutual_info.html">Mutual Information and Total Correlation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../info_theory/estimators.html">Information Theory Measures</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/classic.html">Classic Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/histogram.html">Entropy Estimator - Histogram</a></li>
<li class="toctree-l3"><a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">Experiment - RBIG Sample Consistency</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../normalizing_flows/overview.html">Normalizing Flows</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/linear.html">Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/coupling_layers.html">Coupling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/conditional.html">Conditional Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/multiscale.html">Multiscale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/inverse.html">Minimization Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalizing_flows/losses.html">Losses</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_1_ig.html">Lecture I - Iterative Gaussianization</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.0_univariate_gauss.html">1.1 - Univariate Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.1_marginal_gauss.html">1.2 - Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/1.2_gaussianization.html">1.2 - Iterative Gaussianization</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../normalizing_flows/lecture_2_gf.html">Lecture II - Gaussianization Flows</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt1_mg.html">Parameterized Marginal Gaussianization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt2_rot.html">Parameterized Rotations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../normalizing_flows/lecture_3_gfs_pt3_plane.html">Example - 2D Plane</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nerfs/overview.html">Neural Fields</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nerfs/formulation.html">Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nerfs/literature_review.html">Literature Review</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../nerfs/pinns.html">Physics-Informed Loss</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_assimilation/overview.html">Data Assimilation</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/dynamical_sys.html">Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/oi.html">Optimal Interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/interp.html">Interpolation Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/emu.html">Emulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/inv_problems.html">Inverse Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_assimilation/projects.html">Projects</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../data_assimilation/algorithms.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/markov_models.html">Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/gauss_markov.html">Gauss-Markov Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/kf.html">Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/nkf.html">Normalizing Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/enskf.html">Ensemble Kalman Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/dmm.html">Deep Markov Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/4dvarnet.html">4DVarNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data_assimilation/markov_gp.html">Markovian Gaussian Processes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../data_assimilation/nbs/notebooks.html">Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../misc/overview.html">Miscellaneous Notes</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../misc/generative_models.html">Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diffusion_models.html">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/fixed_point.html">Fixed-Point Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/bilevel_opt.html">Bi-Level Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/diff_operators.html">Differential Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/qg.html">QG Formulations</a></li>


<li class="toctree-l2"><a class="reference internal" href="../misc/elliptical_pde_solver.html">Elliptical PDE Solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../misc/inverse_probs.html">Inverse Problems</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cheat Sheets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/bash.html">Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/cli.html">Command Line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cheatsheets/python.html">Python</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/jejjohnson/research_notebook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/jejjohnson/research_notebook/issues/new?title=Issue%20on%20page%20%2Fcontent/notes/egps/bgplvm.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/notes/egps/bgplvm.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayesian GPLVM</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-approximations">Posterior Approximations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-gp-model-with-latent-inputs">Variational GP Model with Latent Inputs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evidence-lower-bound-elbo">Evidence Lower Bound (ELBO)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uncertain-inputs">Uncertain Inputs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-i-strong-prior">Case I - Strong Prior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-ii-regularized-strong-prior">Case II - Regularized Strong Prior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-iii-prior-with-openness">Case III - Prior with Openness</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-iv-bonus-conservative-freedom">Case IV - Bonus, Conservative Freedom</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resources">Resources</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#important-papers">Important Papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-thesis">Summary Thesis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#talks">Talks</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bayesian-gplvm">
<h1>Bayesian GPLVM<a class="headerlink" href="#bayesian-gplvm" title="Permalink to this heading">#</a></h1>
<section id="posterior-approximations">
<h2>Posterior Approximations<a class="headerlink" href="#posterior-approximations" title="Permalink to this heading">#</a></h2>
<p>What links all of the strategies from uncertain GPs is how they approach the problem of uncertain inputs: approximating the posterior distribution. The methods that use moment matching on stochastic trial points are all using various strategies to construct some posterior approximation. They define their GP model first and then approximate the posterior by using some approximate scheme to account for uncertainty. The NIGP however does change the model which is a product of the Taylor series expansion employed. From there, the resulting posterior is either evaluated or further approximated. My method actually is related because I also avoid changing the model and just attempt to approximate the posterior predictive distribution by augmenting the predictive variance function only (<strong>???</strong>).</p>
<p>This approach has similar strategies that stem from the wave of methods that appeared using variational inference (VI). VI consists of creating a variational approximation of the posterior distribution <span class="math notranslate nohighlight">\(q(\mathbf u)\approx \mathcal{p}(\mathbf x)\)</span>. Under some assumptions and a baseline distribution for <span class="math notranslate nohighlight">\(q(\mathbf u)\)</span>,  we can try to approximate the complex distribution <span class="math notranslate nohighlight">\(\mathcal{p}(\mathbf x)\)</span> by minimizing the distance between the two distributions, <span class="math notranslate nohighlight">\(D\left[q(\mathbf u)||\mathcal{p}(\mathbf x)\right]\)</span>. Many practioners believe that approximating the posterior and not the model is the better option when doing Bayesian inference; especially for large data (<a class="reference external" href="https://www.prowler.io/blog/sparse-gps-approximate-the-posterior-not-the-model">example blog</a>, <span class="xref myst">VFE paper</span>). The variational family of methods that are common for GPs use the Kullback-Leibler (KL) divergence criteria between the GP posterior approximation <span class="math notranslate nohighlight">\(q(\mathbf u)\)</span> and the true GP posterior <span class="math notranslate nohighlight">\(\mathcal{p}(\mathbf x)\)</span>. From the literature, this has been extended to many different problems related to GPs for regression, classification, dimensionality reduction and more.</p>
<hr class="docutils" />
<section id="variational-gp-model-with-latent-inputs">
<h3>Variational GP Model with Latent Inputs<a class="headerlink" href="#variational-gp-model-with-latent-inputs" title="Permalink to this heading">#</a></h3>
<p><strong>Posterior Distribution:</strong>
$<span class="math notranslate nohighlight">\(p(Y) = \int_{\mathcal X} p(Y|X) P(X) dX\)</span>$</p>
<p><strong>Derive the Lower Bound</strong> (w/ Jensens Inequality):</p>
<div class="math notranslate nohighlight">
\[\log p(Y) = \log \int_{\mathcal X} p(Y|X) P(X) dX\]</div>
<p><strong>importance sampling/identity trick</strong></p>
<div class="math notranslate nohighlight">
\[ = \log \int_{\mathcal F} p(Y|X) P(X) \frac{q(X)}{q(X)}dF\]</div>
<p><strong>rearrange to isolate</strong>: <span class="math notranslate nohighlight">\(p(Y|X)\)</span> and shorten notation to <span class="math notranslate nohighlight">\(\langle \cdot \rangle_{q(X)}\)</span>.</p>
<div class="math notranslate nohighlight">
\[= \log \left\langle  \frac{p(Y|X)p(X)}{q(X)} \right\rangle_{q(X)}\]</div>
<p><strong>Jensens inequality</strong></p>
<div class="math notranslate nohighlight">
\[\geq \left\langle \log \frac{p(Y|X)p(X)}{q(X)} \right\rangle_{q(X)}\]</div>
<p><strong>Split the logs</strong></p>
<div class="math notranslate nohighlight">
\[\geq \left\langle \log p(Y|X) + \log \frac{p(X)}{q(X)} \right\rangle_{q(X)}\]</div>
<p><strong>collect terms</strong></p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{2}(q)=\left\langle \log p(Y|X)\right\rangle_{q(F)} - D_{KL} \left( q(X) || p(X)\right) \]</div>
<p><strong>plug in other bound</strong></p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{2}(q)=\left\langle \mathcal{L}_{1}(q)\right\rangle_{q(F)} - D_{KL} \left( q(X) || p(X)\right) \]</div>
</section>
<hr class="docutils" />
<section id="evidence-lower-bound-elbo">
<h3>Evidence Lower Bound (ELBO)<a class="headerlink" href="#evidence-lower-bound-elbo" title="Permalink to this heading">#</a></h3>
<p>In VI strategies, we never get an explicit function that will lead us to the best variational approximation but we can come close; we can come up with an upper bound.
Traditional marginal likelhood (evidence) function that we’re given is given by:</p>
<div class="math notranslate nohighlight">
\[\underbrace{\mathcal{p}(y|\mathbf x, \theta)}_{\text{Evidence}}=\int_f \underbrace{\mathcal{p}(y|f, \mathbf x, 
\theta)}_{\text{Likelihood}} \cdot \underbrace{\mathcal{p}(f|\mathbf x, \theta)}_{\text{GP Prior}}df\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{p}(y|f, \mathbf x, \theta)=\mathcal{N}(y|f, \sigma_n^2\mathbf{I})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{p}(f|\mathbf x, \theta)=\mathcal{N}(f|\mu, K_\theta)\)</span></p></li>
</ul>
<p>In this case we are marginalizing by the latent functions <span class="math notranslate nohighlight">\(f\)</span>’s. But we no longer consider <span class="math notranslate nohighlight">\(\mathbf x\)</span> to be uncertain with some probability distribution. Also, we do not want some MAP estimation; we want a fully Bayesian approach. So the only thing to do is marginalize out the <span class="math notranslate nohighlight">\(\mathbf x\)</span>’s. In doing so we get:</p>
<div class="math notranslate nohighlight">
\[\mathcal{p}(y| \theta)=\int_f\int_\mathcal{X} \mathcal{p}(y|f, \mathbf x, 
\theta)\cdot\mathcal{p}(f|\mathbf x, \theta) \cdot \mathcal{p}(\mathbf x)\cdot df \cdot d\mathbf{x}\]</div>
<p>We can rearrange this equation to change notation:</p>
<div class="math notranslate nohighlight">
\[\mathcal{p}(y| \theta)=\int_\mathcal{X} 
\underbrace{\left[ \int_f \mathcal{p}(y|f, \mathbf x, 
\theta)\cdot\mathcal{p}(f|\mathbf x, \theta)\cdot df\right]}_{\text{Evidence}}
\cdot \underbrace{\mathcal{p}(\mathbf x)}_{\text{Prior}} \cdot d\mathbf{x}\]</div>
<p>where we find that that term is simply the same term as the original likelihood, <span class="math notranslate nohighlight">\(\mathcal{p}(y|\mathbf x, \theta)\)</span>. So our new simplified equation is:</p>
<div class="math notranslate nohighlight">
\[\mathcal{p}(y| \theta)=\int_\mathcal{X} \mathcal{p}(y|\mathbf x, \theta) \cdot \mathcal{p}(\mathbf x) \cdot d\mathbf{x}\]</div>
<p>where we have effectively marginalized out the <span class="math notranslate nohighlight">\(f\)</span>’s. We already know that it’s difficult to propagate the <span class="math notranslate nohighlight">\(\mathbf x\)</span>’s through the nonlinear functions <span class="math notranslate nohighlight">\(\mathbf K^{-1}\)</span> and <span class="math notranslate nohighlight">\(|\)</span>det <span class="math notranslate nohighlight">\(\mathbf K|\)</span> (see previous doc for examples). So using the VI strategy, we introduce a new variational distribution <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span> to approximate the posterior distribution <span class="math notranslate nohighlight">\(\mathcal{p}(\mathbf x| y)\)</span>. The distribution is normally chosen to be Gaussian:</p>
<div class="math notranslate nohighlight">
\[q(\mathbf x) = \prod_{i=1}^{N}\mathcal{N}(\mathbf x|\mathbf \mu_z, \mathbf \Sigma_z)\]</div>
<p>So at this point, we are interested in trying to find a way to measure the difference between the approximate distribution <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span> and the true posterior distribution <span class="math notranslate nohighlight">\(\mathcal{p} (\mathbf x)\)</span>. Using the standard derivation for the ELBO, we arrive at the final formula:</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}(q)=\mathbb{E}_{q(\mathbf x)}\left[ \log \mathcal{p}(y|\mathbf x, \theta) \right] - \text{D}_\text{KL}\left[ q(\mathbf x) || \mathcal{p}(\mathbf x) \right]\]</div>
<p>If we optimize <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> with respect to <span class="math notranslate nohighlight">\(q(\mathbf x)\)</span>, the KL is minimized and we just get the likelihood. As we’ve seen before, the likelihood term is still problematic as it still has the nonlinear portion to propagate the <span class="math notranslate nohighlight">\(\mathbf x\)</span>’s through. So that’s nothing new and we’ve done nothing useful. If we introduce some special structure in <span class="math notranslate nohighlight">\(q(f)\)</span> by introducing sparsity, then we can achieve something useful with this formulation.
But through augmentation of the variable space with <span class="math notranslate nohighlight">\(\mathbf u\)</span> and <span class="math notranslate nohighlight">\(\mathbf Z\)</span> we can bypass this problem. The second term is simple to calculate because they’re both chosen to be Gaussian.</p>
</section>
</section>
<hr class="docutils" />
<section id="uncertain-inputs">
<h2>Uncertain Inputs<a class="headerlink" href="#uncertain-inputs" title="Permalink to this heading">#</a></h2>
<p>So how does this relate to uncertain inputs exactly? Let’s look again at our problem setting.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y &amp;= f(x) + \epsilon_y \\
x &amp;\sim \mathcal{N}(\mu_x, \Sigma_x) \\
\end{aligned}\end{split}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y\)</span> - noise-corrupted outputs which have a noise parameter characterized by <span class="math notranslate nohighlight">\(\epsilon_y \sim \mathcal{N}(0, \sigma^2_y)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> - is the standard GP function</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> - “latent variables” but we assume that the come from a normal distribution, <span class="math notranslate nohighlight">\(x \sim \mathcal{N}(\mu_x, \Sigma_x)\)</span> where you have some observations <span class="math notranslate nohighlight">\(\mu_x\)</span> but you also have some prior uncertainty <span class="math notranslate nohighlight">\(\Sigma_x\)</span> that you would like to incorporate.</p></li>
</ul>
<p>Now the ELBO that we want to minimize has the following form:</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}(q)=\mathbb{E}_{q(\mathbf x | m_{p_z}, S_{p_z})}\left[ \log \mathcal{p}(y|\mathbf x, \theta) \right] - \text{D}_\text{KL}\left[ q(\mathbf x | m_{p_z}, S_{p_z}) || \mathcal{p}(\mathbf x | m_{p_x}, S_{p_x}) \right]\]</div>
<p>Notice that I have expanded the parameters for <span class="math notranslate nohighlight">\(p(X)\)</span> and <span class="math notranslate nohighlight">\(q(X)\)</span> so that we are clear about where the parameters. We would like to figure out a way to incorporate our uncertainties in the <span class="math notranslate nohighlight">\(m_{p_x}\)</span>, <span class="math notranslate nohighlight">\(S_{p_x}\)</span>, <span class="math notranslate nohighlight">\(m_{p_z}\)</span>, and <span class="math notranslate nohighlight">\(S_{p_z}\)</span>. The author had two suggestions about how to account for noise in the inputs but the original formulation assumed that these parameters were unknown. In my problem setting, we know that there is noise in the inputs so the problems that the original formulations had will change. I will outline the formulations below for both known and unknown uncertainties.</p>
<hr class="docutils" />
<section id="case-i-strong-prior">
<h3>Case I - Strong Prior<a class="headerlink" href="#case-i-strong-prior" title="Permalink to this heading">#</a></h3>
<p><strong>Prior</strong>, <span class="math notranslate nohighlight">\(p(X)\)</span></p>
<p>We can directly assume that we know the parameters for the prior distribution. So we let <span class="math notranslate nohighlight">\(\mu_x\)</span> be our noisy observations and we let <span class="math notranslate nohighlight">\(\Sigma_x\)</span> be our known covariance matrix for <span class="math notranslate nohighlight">\(X\)</span>. These parameters are fixed as we assume we know them and we would like this to be our prior. This seems to be the most natural as is where we have information and we would like to use it. So now our prior is in the form of:</p>
<div class="math notranslate nohighlight">
\[\mathcal{p}(\mathbf X|\mu_x, \Sigma_x) = \prod_{i=1}^{N}\mathcal{N}(\mathbf{x}_i |\mathbf \mu_{\mathbf{x}_i},\mathbf \Sigma_\mathbf{x_i})\]</div>
<p>and this will be our regularization that we use for the KL divergence term.</p>
<p><strong>Variational</strong>, <span class="math notranslate nohighlight">\(q(X)\)</span></p>
<p>However, the variational parameters <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(S\)</span> are also important because that is being directly evaluated with the KL divergence term and the likelihood function <span class="math notranslate nohighlight">\(\log p(y|X, \theta)\)</span>. So ideally we would also like to constrain this as well if we know something. The first thing to do would be to fix them as well to what we know about our data, <span class="math notranslate nohighlight">\(m=\mu_x\)</span> and <span class="math notranslate nohighlight">\(S_{p_z} = \Sigma_x\)</span>. So our prior for our variational distribution will be:</p>
<div class="math notranslate nohighlight">
\[q(\mathbf X|\mu_x, \Sigma_x) = \prod_{i=1}^{N}\mathcal{N}(\mathbf{x}_i |\mathbf \mu_{\mathbf{x}_i},\mathbf \Sigma_\mathbf{x_i})\]</div>
<p>We now have our variational bound with the assumed parameters:</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}=\langle \log \mathcal{p}(\mathbf{Y|X}) \rangle_{q(\mathbf X|\mu_x, \Sigma_x)} - \text{KL}\left( q(\mathbf X|\mu_x, \Sigma_x) || p(\mathbf X|\mu_x, \Sigma_x)  \right)\]</div>
<p><strong>Assessment</strong></p>
<p>So this is a very strong belief over our parameters. The KL divergence term will be zero because the distributions will be the same and we would have probably done some extra computations for no reason; we do need this in order to make the likelihood tractable but it doesn’t make sense if we’re not learning anything. But this is absolute because we have no reason to change anything. It’s worth testing to see how this goes.</p>
</section>
<hr class="docutils" />
<section id="case-ii-regularized-strong-prior">
<h3>Case II - Regularized Strong Prior<a class="headerlink" href="#case-ii-regularized-strong-prior" title="Permalink to this heading">#</a></h3>
<p>This is similar to the above statement, however we would be reducing the prior parameters to a standard 0 mean and 1 standard deviation. So our prior function will look like this</p>
<div class="math notranslate nohighlight">
\[\mathcal{p}(\mathbf X|0, 1) = \prod_{i=1}^{N}\mathcal{N}(\mathbf{x}_i |0, 1)\]</div>
<p>This would allow the KL-Divergence criteria extra penalization for the loss function. It might change some of the parameters learned for the other regions of the ELBO. So our final loss function is:</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}=\langle \log \mathcal{p}(\mathbf{Y|X}) \rangle_{q(\mathbf X|\mu_x, \Sigma_x)} - \text{KL}\left( q(\mathbf X|\mu_x, \Sigma_x) || p(\mathbf X|0, 1)  \right)\]</div>
</section>
<hr class="docutils" />
<section id="case-iii-prior-with-openness">
<h3>Case III - Prior with Openness<a class="headerlink" href="#case-iii-prior-with-openness" title="Permalink to this heading">#</a></h3>
<p>The last option I think is the most interesting. It seems to incorporate the prior but also allow for some flexibility. In this option,</p>
<p>We can pivot off of what the factor that the KL divergence term is simply a regularizer. So we could also go with a more conservative approach where we</p>
<p>We will introduce a variational constraint to encode the input uncertainty directly into the approximate posterior.</p>
<div class="math notranslate nohighlight">
\[q(\mathbf X|\mathbf Z) = \prod_{i=1}^{N}\mathcal{N}(\mathbf{x}_i |\mathbf z_i,\mathbf \Sigma_\mathbf{z_i})\]</div>
<p>We will have a new variational bound now:</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}=\langle \log \mathcal{p}(\mathbf{Y|X}) \rangle_{q(\mathbf X|\mu_x, S)} - \text{KL}\left( q(\mathbf X|\mu_x, S) || p(\mathbf X|\mu_x, \Sigma_x)  \right)\]</div>
<p>So the only free parameter in the variational bound is the actual variance of our inputs <span class="math notranslate nohighlight">\(S\)</span> that stems from our variational distribution <span class="math notranslate nohighlight">\(q(X)\)</span>. Again, this seems like a nice balanced approach where we can incorporate prior information within our model but at the same time allow for some freedom to maybe find a better distribution to represent the noise.</p>
</section>
<hr class="docutils" />
<section id="case-iv-bonus-conservative-freedom">
<h3>Case IV - Bonus, Conservative Freedom<a class="headerlink" href="#case-iv-bonus-conservative-freedom" title="Permalink to this heading">#</a></h3>
<p>Ok, so the true last option would be to try and see how the algorithm thinks the results should be. We</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}=\langle \log \mathcal{p}(\mathbf{Y|X}) \rangle_{q(\mathbf{X|Z})} - \text{KL}\left( q(\mathbf{X|Z}) || \mathcal{p}(\mathbf{X}) \right)\]</div>
<center>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Options</p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(m_{p_x}\)</span></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(S_{p_x}\)</span></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(m_{p_z}\)</span></p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(S_{p_z}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>No Prior</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p>S_z</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Strong Conservative Prior</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p>1</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\Sigma_x\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Strong Prior</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\Sigma_x\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\Sigma_x\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Bayesian Prior</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\Sigma_x\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_x\)</span></p></td>
<td class="text-center"><p>S_z</p></td>
</tr>
</tbody>
</table>
</center>
<p><strong>Caption</strong>: Summary of Options</p>
</section>
</section>
<hr class="docutils" />
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Permalink to this heading">#</a></h2>
<section id="important-papers">
<h3>Important Papers<a class="headerlink" href="#important-papers" title="Permalink to this heading">#</a></h3>
<p>These are the important papers that helped me understand what was going on throughout the learning process.</p>
</section>
<section id="summary-thesis">
<h3>Summary Thesis<a class="headerlink" href="#summary-thesis" title="Permalink to this heading">#</a></h3>
<p>Often times the papers that people publish in conferences in Journals don’t have enough information in them. Sometimes it’s really difficult to go through some of the mathematics that people put  in their articles especially with cryptic explanations like “it’s easy to show that…” or “trivially it can be shown that…”. For most of us it’s not easy nor is it trivial. So I’ve included a few thesis that help to explain some of the finer details. I’ve arranged them in order starting from the easiest to the most difficult.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://lib.ugent.be/fulltxt/RUG01/002/367/115/RUG01-002367115_2017_0001_AC.pdf">Non-Stationary Surrogate Modeling with Deep Gaussian Processes</a> - Dutordoir (2016)</p>
<ul>
<li><p>Chapter IV - Finding Uncertain Patterns in GPs</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://etheses.whiterose.ac.uk/18492/1/MaxZwiesseleThesis.pdf">Bringing Models to the Domain: Deploying Gaussian Processes in the Biological Sciences</a> - Zwießele (2017)</p>
<ul>
<li><p>Chapter II (2.4, 2.5) - Sparse GPs, Variational Bayesian GPLVM</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://etheses.whiterose.ac.uk/9968/1/Damianou_Thesis.pdf">Deep GPs and Variational Propagation of Uncertainty</a> - Damianou (2015)</p>
<ul>
<li><p>Chapter IV - Uncertain Inputs in Variational GPs</p></li>
<li><p>Chapter II (2.1) - Lit Review</p></li>
</ul>
</li>
</ul>
</section>
<section id="talks">
<h3>Talks<a class="headerlink" href="#talks" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Damianou - Bayesian LVM with GPs - <a class="reference external" href="http://gpss.cc/gpss15/talks/gpss_BGPLVMs.pdf">MLSS2015</a></p></li>
<li><p>Lawrence - Deep GPs - <span class="xref myst">MLSS2019</span></p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/notes/egps"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-approximations">Posterior Approximations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-gp-model-with-latent-inputs">Variational GP Model with Latent Inputs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evidence-lower-bound-elbo">Evidence Lower Bound (ELBO)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#uncertain-inputs">Uncertain Inputs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-i-strong-prior">Case I - Strong Prior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-ii-regularized-strong-prior">Case II - Regularized Strong Prior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-iii-prior-with-openness">Case III - Prior with Openness</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-iv-bonus-conservative-freedom">Case IV - Bonus, Conservative Freedom</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resources">Resources</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#important-papers">Important Papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-thesis">Summary Thesis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#talks">Talks</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By J. Emmanuel Johnson
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>