
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Confidence Intervals &#8212; Research Notebook</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Sleeper Concepts" href="../concepts/overview.html" />
    <link rel="prev" title="Variational Inference" href="inference/variational_inference.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/book.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Notebook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Overview
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../resources/python/overview.html">
   Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/ides.html">
     Integraded Development Environment (IDE)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/stack.html">
     Standard Python Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/earthsci_stack.html">
     Earth Science Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/dl_stack.html">
     Deep Learning Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/scale_stack.html">
     Scaling Stack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../resources/python/good_code.html">
     Good Code
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/jax_journey/overview.html">
   My JAX Journey
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/ecosystem.html">
     Ecosystem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/vmap.html">
     vmap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/jit.html">
     Jit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/jax_journey/classes.html">
     Classes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/jax_journey/algorithms/overview.html">
     Algorithms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/bisection.html">
       Bisection search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/kernel_derivatives.html">
       Kernel Derivatives
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/jax_journey/algorithms/gpr.html">
       GP from Scratch
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/remote/overview.html">
   Remote Computing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/remote/vscode_jlab.html">
     JupyterLab + VSCode
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   Bayesian
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="intro.html">
     Bayesian: Language of Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gaussian.html">
     Gaussian Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="regression.html">
     Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inference/inference.html">
     Solving Hard Integral Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inference/variational_inference.html">
     Variational Inference
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Confidence Intervals
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../concepts/overview.html">
   Sleeper Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/change_of_variables.html">
     Change of Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/identity_trick.html">
     Identity Trick
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/inverse_function.html">
     Inverse Function Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/jensens.html">
     Jensens Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/lin_alg.html">
     Linear Algebra Tricks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../kernels/overview.html">
   Kernel Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernels/kernel_derivatives.html">
     Kernel Derivatives
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../egps/overview.html">
   Uncertain Gaussian Processes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/predictions.html">
     Uncertain Predictions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/gauss_approx.html">
     Gaussian Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/mcmc.html">
     Monte Carlo Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/taylor.html">
     Taylor Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../egps/moment_matching.html">
     Moment Matching
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../info_theory/overview.html">
   Information Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../info_theory/histogram.html">
     Entropy Estimator - Histogram
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../info_theory/experiments/rbig_sample_consistency.html">
     Experiment - RBIG Sample Consistency
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/content/notes/bayesian/confidence_intervals.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods">
   Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tldr">
     TLDR
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-processes">
     Gaussian Processes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#standard">
       Standard
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fully-bayesian">
       Fully Bayesian
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparse">
       Sparse
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#deep-kernel-learning">
       Deep Kernel Learning
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neural-networks">
     Neural Networks
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dropout">
       DropOut
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic">
       Probabilistic
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-neural-networks">
       Bayesian Neural Networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrapping">
     Bootstrapping
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensembles">
     Ensembles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantile-regression">
     Quantile Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluating-uncertainties">
   Evaluating Uncertainties
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-resources">
   Other Resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="confidence-intervals">
<h1>Confidence Intervals<a class="headerlink" href="#confidence-intervals" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Last Update: 19-April-2021</p></li>
</ul>
<blockquote>
<div><p>My notes on how one can obtain confidence intervals using Machine learning methods.</p>
</div></blockquote>
<hr class="docutils" />
<div class="section" id="methods">
<h2>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<div class="section" id="tldr">
<h3>TLDR<a class="headerlink" href="#tldr" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A lot of these methods are common within the <strong>machine learning</strong> literature, not the <strong>scientific literature</strong>. There is a huge difference between the fields regarding what’s popular for research and what’s popular for practical applications. A lot of the more complex methods are because people are using giant models trying to fit large and very complex datasets. Many times, smaller data problems (&lt;10K data points) don’t require so much difficult stuff.</p>
</div>
<p><strong>Bootstrapping</strong> - A very simple way to obtain confidence intervals is to using bootstrapping. This works by taking random permutations of your dataset and then training multiple models given this subset of data. This is advantageous because we can use any model we want, we just have to find ways of permuting the data effectively. For small data problems, we do run the risk of using so few data points that it becomes ill-advised. However, in general, it’s a very trustworthy method.</p>
<p><strong>Ensembles</strong> - This method is analagous to the above approach but instead of many models using different permutations of the data, we train multiple models using different initial conditions. It follows the idea that combinations many smaller “weak learners” can result in a robust learner. Random forests are a notoriously good example of this. With a few modifications, one can get confidence intervals. This method is also very popular with neural networks because they tend to have a lot of local minima. This can get more expensive and more because it requires training, storing and predicting these huge models; essentially a lot of plumbing. However, these are currently the state-of-the-art methods right now.</p>
<p><strong>Gaussian Processes</strong> - The best thing to use is a Gaussian process (GP). They come equipped with confidence intervals already. They work by using a mean function and a kernel function defined by hyperparameters to obtain a function approximation conditioned on your data. For small data problems (&lt; 2,000 points) you’re not going to find a better method. Scaling is an issue after 10K points but there are many sparse methods which compensate this with approximations. There are studies that show the confidence intervals can deteriorate with these approximations but there are other methods investigating ways to compensate this.</p>
<p><strong>Bayesian Methods</strong> - Alternatively, there are many parametric methods available. These work by strict adherence to the Bayesian rule whereby we define a prior over the parameters, a likelihood describing the data generating process and we try to obtain a posterior which gives us the parameters given the data. Simpler to GPs, they also come equipped with confidence intervals because we inherently have to marginalize over the distribution of parameters given the data. For simple linear problems, it’s highly recommended to try these first before attempting anything more difficult. For more non-linear, difficult problems, the issue of finding the best parameterization becomes an issue. And we also find that the uncertainty estimation starts to become an issue with larger models (e.g. Bayesian Neural Networks).</p>
<p><strong>Quantile Regression</strong> - This method works by augmenting the loss function such that you find a model that predicts the quantile instead of just the mean. Recall that standard ML models attempt to predict the mean and others attempt to predict the distribution. With quantile regression methods, you decide which quantile you want to predict, e.g. the 50th quantile (the mean/median) and 5th quantile (the lower confidence interval) and/or the 95th quantile (the uppter confidence interval). It the most popular method you find in the literature and I have no idea why. It’s a very simple method and possibly preferable with linear methods. But there are some good examples for non-linear methods (like <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html">Gradient Boosting</a>). Some downsides I’ve observed are that the confidence intervals tend to look a bit rigid compared to many other methods (e.g. GPs). Also sometimes the quantiles are a lot higher than I would have expected.</p>
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="gaussian-processes">
<h3>Gaussian Processes<a class="headerlink" href="#gaussian-processes" title="Permalink to this headline">¶</a></h3>
<div class="section" id="standard">
<h4>Standard<a class="headerlink" href="#standard" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="fully-bayesian">
<h4>Fully Bayesian<a class="headerlink" href="#fully-bayesian" title="Permalink to this headline">¶</a></h4>
<p>These put priors on everything and they solve the inference problem using sampling such as Monte Carlo estimation.</p>
</div>
<div class="section" id="sparse">
<h4>Sparse<a class="headerlink" href="#sparse" title="Permalink to this headline">¶</a></h4>
<p>The problem with standard GPs is that they are very slow after about 10K samples (on a beefy machine). So most people resort to sparse methods. This works by conditioning the best subset of points (inducing points) in order to reduce the computation cost of <span class="math notranslate nohighlight">\(\mathcal{O}(N^3)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{O}(NM^2)\)</span> which is significantly less expensive. There are quite a few standard methods out there including:</p>
<ul class="simple">
<li><p>Fully Independent Training Conditional (FITC)</p></li>
<li><p>Variational Free Energy (VFE)</p></li>
<li><p>Stochastic Variational Inference (SVI)</p></li>
</ul>
<p>These methods all work really well with SVI being the most flexible and FITC being the most restrictive.</p>
</div>
<div class="section" id="deep-kernel-learning">
<h4>Deep Kernel Learning<a class="headerlink" href="#deep-kernel-learning" title="Permalink to this headline">¶</a></h4>
<p>One of the biggest limiations of Gaussian processes is the expressivity of the kernel function. There are just some datasets that are hard to fit. So one augmentation is to use something called Deep Kernel Learning (DKL) <span id="id1">[<a class="reference internal" href="../../../markdown.html#id6">Wilson <em>et al.</em>, 2016</a>, <a class="reference internal" href="../../../markdown.html#id7">Wilson <em>et al.</em>, 2016</a>]</span>.This works by attaching a neural network before the kernel. So instead of the inputs going directly into the kernel function, they go through a neural network first (kind of like an encoder) and then they are passed through to the kernel function.</p>
<p>However, because DKL are using neural networks, standard training procedures (i.e. maximum likelihood estimation) tend to exhibit the same pathologies that we see in standard neural networks <span id="id2">[<a class="reference internal" href="../../../markdown.html#id5">Ober <em>et al.</em>, 2021</a>]</span>.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="neural-networks">
<h3>Neural Networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">¶</a></h3>
<div class="section" id="dropout">
<h4>DropOut<a class="headerlink" href="#dropout" title="Permalink to this headline">¶</a></h4>
<p>Dropout is probably the most common method <span id="id3">[<a class="reference internal" href="../../../markdown.html#id4">Gal and Ghahramani, 2016</a>]</span>. Dropout works by randomly removing neurons during the training <strong>and</strong> testing phase. This works as an approximate method to Bayesian neural networks. The advantage of this is that it’s very simple and it’s relatively fast. If you’re already using a neural network, chances are you’re already using dropout as a regularization technique. So there will be minimum changes to your code. The downside is there there have been studies showing that it the confidence intervals aren’t the best quality.</p>
</div>
<div class="section" id="probabilistic">
<h4>Probabilistic<a class="headerlink" href="#probabilistic" title="Permalink to this headline">¶</a></h4>
<p>This method is a nice trade-off between the standard neural network and the Bayesian neural network. Basically, one would just tack on a stochastic layer at the end of the neural network and voila, uncertainty.</p>
</div>
<div class="section" id="bayesian-neural-networks">
<h4>Bayesian Neural Networks<a class="headerlink" href="#bayesian-neural-networks" title="Permalink to this headline">¶</a></h4>
<p><strong>Warning</strong>: Training BNNs is very difficult. Especially for high dimensional, large sample problems. If you have the time and computational power, then go for it, why not. Otherwise, I would sit tight and</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="bootstrapping">
<h3>Bootstrapping<a class="headerlink" href="#bootstrapping" title="Permalink to this headline">¶</a></h3>
</div>
<hr class="docutils" />
<div class="section" id="ensembles">
<h3>Ensembles<a class="headerlink" href="#ensembles" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1311.4555">Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife</a> - Wager et al (2013) | <a class="reference external" href="https://github.com/scikit-learn-contrib/forest-confidence-interval">Software</a></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="quantile-regression">
<h3>Quantile Regression<a class="headerlink" href="#quantile-regression" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<hr class="docutils" />
<div class="section" id="evaluating-uncertainties">
<h2>Evaluating Uncertainties<a class="headerlink" href="#evaluating-uncertainties" title="Permalink to this headline">¶</a></h2>
</div>
<hr class="docutils" />
<div class="section" id="other-resources">
<h2>Other Resources<a class="headerlink" href="#other-resources" title="Permalink to this headline">¶</a></h2>
<p><strong>Practical Uncertainty Estimation and Out-of-Distribution Robustness in Deep Learning</strong> - <a class="reference external" href="https://nips.cc/virtual/2020/public/tutorial_0f190e6e164eafe66f011073b4486975.html">NeuRIPS 2020 Tutorial</a></p>
<blockquote>
<div><p>The best tutorial I’ve seen for uncertainty in Neural networks. They focus almost exclusively on Neural networks (aka not small data problems).</p>
</div></blockquote>
<p><strong>A Regression Master Class with Aboleth</strong> - <a class="reference external" href="https://aboleth.readthedocs.io/en/stable/tutorials/some_regressors.html">Blog</a></p>
<blockquote>
<div><p>Probably the best tutorial I’ve seen for regression methods.</p>
</div></blockquote>
<p><strong>Probabilistic Layers Regression</strong> - <a class="reference external" href="https://www.tensorflow.org/probability/examples/Probabilistic_Layers_Regression">TensorFlow Probability</a> | <a class="reference external" href="https://keras.io/examples/keras_recipes/bayesian_neural_networks/">Keras</a></p>
<blockquote>
<div><p>Another great tutorial showcasing how to get uncertainty using the TensorFlow probability package.</p>
</div></blockquote>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/notes/bayesian"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="inference/variational_inference.html" title="previous page">Variational Inference</a>
    <a class='right-next' id="next-link" href="../concepts/overview.html" title="next page">Sleeper Concepts</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By J. Emmanuel Johnson<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>